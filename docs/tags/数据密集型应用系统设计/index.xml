<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>数据密集型应用系统设计 on 凌桓&#39;s BLOG</title>
        <link>https://blog.orekilee.top/tags/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
        <description>Recent content in 数据密集型应用系统设计 on 凌桓&#39;s BLOG</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 10 Jul 2022 10:11:13 +0800</lastBuildDate><atom:link href="https://blog.orekilee.top/tags/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>数据密集型应用系统设计 学习笔记（十一）：流处理</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%80%E6%B5%81%E5%A4%84%E7%90%86/</link>
        <pubDate>Sun, 10 Jul 2022 10:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%80%E6%B5%81%E5%A4%84%E7%90%86/</guid>
        <description>&lt;h1 id=&#34;流处理&#34;&gt;流处理&lt;/h1&gt;
&lt;p&gt;在批处理中，输入数据是有界的（已知和有限的大小），所以批处理系统能直到它何时完成输入的读取。但事实上，很多场景下数据都是无界的，数据会随着时间的推移不断到来，并且这个过程永远不会结束，所以我们没有办法能掌握数据的大小以及它该何时结束。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，批处理程序以时间来划分数据块，但这也就导致了一个问题：&lt;strong&gt;划分的时间越长，则延迟越长&lt;/strong&gt;。倘若我们的服务一天更新一次数据，这会使得用户的体验直线下降，为了减少延迟，我们就需要将这个时间缩短，更加频繁的处理数据，这也就是流处理的原理。&lt;/p&gt;
&lt;h2 id=&#34;发送事件流&#34;&gt;发送事件流&lt;/h2&gt;
&lt;p&gt;在批处理中任务的输入和输出都是文件，而在流处理领域中，输入则变成了一系列的&lt;strong&gt;事件&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;事件&lt;/strong&gt;：一个小的、自包含的、不可变的对象，包含某个时间点发生的某件事情的细节。一个事件通常包含一个来自日历时钟的时间戳，以指明事件发生的时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在批处理中，文件只被写入一次，然后可能被多个作业读取。类似地，在流处理领域中，一个事件由生产者（producer）生成一次，然后可能由多个消费者（consumer）进行处理。在文件系统中，文件名标识一组相关记录；在流式系统中，相关的事件通常被聚合为一个主题（topic） 。&lt;/p&gt;
&lt;h3 id=&#34;消息传递系统&#34;&gt;消息传递系统&lt;/h3&gt;
&lt;p&gt;向消费者通知新事件的常用方式是使用&lt;strong&gt;消息传递系统（messaging system）&lt;/strong&gt;：生产者发送包含事件的消息，然后将消息推送给消费者。&lt;/p&gt;
&lt;p&gt;不同的消息传递系统可能会采取不同的实现方案，我们可以借助下面两个问题来区分这些系统：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果生产者发送消息的速度比消费者能够处理的速度快会发生什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;解决方案主要有三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;丢弃这些来不及处理的消息。&lt;/li&gt;
&lt;li&gt;将消息放入缓冲队列，延迟处理。&lt;/li&gt;
&lt;li&gt;采取背压（backpressure）机制，阻塞生产者，以免其发送更多的消息。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;如果节点崩溃或暂时脱机，会发生什么情况？是否会有消息丢失？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果要想保证持久性，就必须定期写入磁盘和复制数据。而如果允许一定程序的消息丢失，则可以获得更高的吞吐量和更低的延迟。&lt;/p&gt;
&lt;h4 id=&#34;直接消息传递系统&#34;&gt;直接消息传递系统&lt;/h4&gt;
&lt;p&gt;许多消息传递系统使用生产者和消费者之间的直接网络通信，而不通过中间节点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UDP 组播广泛应用于金融行业，因为这些常见需要保证低延时（虽然 UDP 本身是不可靠的，但应用层的协议可以恢复丢失的数据包）。&lt;/li&gt;
&lt;li&gt;无代理的消息库，如 ZeroMQ 和 nanomsg 采取类似的方法，通过 TCP 或 IP 多播实现发布 / 订阅消息传递。&lt;/li&gt;
&lt;li&gt;StatsD 和 Brubeck 使用不可靠的 UDP 消息传递来收集网络中所有机器的指标并对其进行监控（在 StatsD 协议中，只有接收到所有消息，才认为计数器指标是正确的；使用 UDP 将使得指标处在一种最佳近似状态）。&lt;/li&gt;
&lt;li&gt;如果消费者在网络上公开了服务，生产者可以直接发送 HTTP 或 RPC 请求消息推送给使用者。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然这些系统的性能很好，但是它们的容错程度极为有限。即使协议检测到并重传在网络中丢失的数据包，它们通常也只是假设生产者和消费者始终在线。&lt;/p&gt;
&lt;p&gt;如果消费者处于脱机状态，则可能会丢失其不可达时发送的消息。一些协议允许生产者重试失败的消息传递，但当生产者崩溃时，它可能会丢失消息缓冲区及其本应发送的消息，这种方法可能就没用了。&lt;/p&gt;
&lt;h4 id=&#34;消息代理&#34;&gt;消息代理&lt;/h4&gt;
&lt;p&gt;目前的主流方案则是使用消息代理（也称为消息队列）来发送消息。消息代理实质上是一种针对处理消息流而优化的数据库。它作为服务器运行，生产者和消费者作为客户端连接到服务器。生产者将消息写入代理，消费者通过从代理那里读取来接收消息。&lt;/p&gt;
&lt;p&gt;通过将数据集中在代理上，这些系统可以更容易地容忍来来去去的客户端（连接，断开连接和崩溃），而持久性问题则转移到代理的身上。一些消息代理只将消息保存在内存中，而另一些消息代理（取决于配置）将其写入磁盘，以便在代理崩溃的情况下不会丢失。&lt;/p&gt;
&lt;h4 id=&#34;消息代理-vs-数据库&#34;&gt;消息代理 VS 数据库&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;数据库通常保留数据直至显式删除，而大多数消息代理在消息成功递送给消费者时会自动删除消息。这样的消息代理不适合长期的数据存储。&lt;/li&gt;
&lt;li&gt;数据库通常支持次级索引和各种搜索数据的方式，而消息代理通常支持按照某种模式匹配主题，订阅其子集。&lt;/li&gt;
&lt;li&gt;由于它们很快就能删除消息，因此大多数消息代理的队列很短。如果代理需要缓冲很多消息，比如因为消费者速度较慢（如果内存装不下消息，可能会溢出到磁盘），每个消息需要更长的处理时间，整体吞吐量可能会恶化。&lt;/li&gt;
&lt;li&gt;查询数据库时，结果通常基于某个时间点的数据快照；如果另一个客户端随后向数据库写入一些改变了查询结果的内容，则第一个客户端不会发现其先前结果现已过期（除非它重复查询或轮询变更）。相比之下，消息代理不支持任意查询，但是当数据发生变化时（即新消息可用时），它们会通知客户端。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;多个消费者&#34;&gt;多个消费者&lt;/h4&gt;
&lt;p&gt;当多个消费者从同一主题中读取消息时，有两种主要的消息传递模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;负载均衡（load balancing）&lt;/strong&gt;：每条消息都被传递给消费者&lt;strong&gt;之一&lt;/strong&gt;，所以处理该主题下消息的工作能被多个消费者共享。代理可以为消费者任意分配消息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扇出（fan-out）&lt;/strong&gt;：每条消息都被传递给&lt;strong&gt;所有&lt;/strong&gt;消费者。扇出允许几个独立的消费者各自监听相同的消息广播，而不会相互影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia28.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;两种模式可以组合使用：例如，两个独立的消费者组可以每组各订阅同一个主题，每一组都共同收到所有消息，但在每一组内部，每条消息仅由单个节点处理。&lt;/p&gt;
&lt;h4 id=&#34;确认与重传&#34;&gt;确认与重传&lt;/h4&gt;
&lt;p&gt;由于消费者随时可能会崩溃，所以可能会存在这么一个场景：代理向消费者递送消息，但消费者没有处理，或者在消费者崩溃之前只进行了部分处理。为了确保消息不会丢失，消息代理引入了**确认（acknowledgments）**机制，即客户端必须显式告知代理消息处理完毕的时间，以便代理能将消息从队列中移除。&lt;/p&gt;
&lt;p&gt;如果与客户端的连接关闭，或者代理超出一段时间未收到确认，代理则认为消息没有被处理，因此它将消息再递送给另一个消费者。&lt;/p&gt;
&lt;p&gt;当结合上文提到的负载均衡时，这种重传行为会对消息的顺序产生影响。如下图，当某个消费者在处理消息时崩溃了，此时这个未处理的消息就会被重传到其他消费者手中，这也就可能导致消息的交付顺序（那个消费者可能正在处理别的消息）与生产者的发送顺序不一致。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;即使消息代理试图保留消息的顺序，负载均衡与重传的组合也不可避免地导致消息被重新排序。为了避免此问题，可以让每个消费者使用单独的队列（即不使用负载均衡功能）。&lt;/p&gt;
&lt;h3 id=&#34;分区日志&#34;&gt;分区日志&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;有没有一种方法既有数据库的持久存储，又能保证消息传递的低延迟？这时就需要提到&lt;strong&gt;基于日志的消息代理&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;使用日志进行消息存储&#34;&gt;使用日志进行消息存储&lt;/h4&gt;
&lt;p&gt;基于日志的消息代理的实现原理如下：&lt;strong&gt;生产者通过将消息追加到日志末尾来发送消息，而消费者通过依次读取日志来接收消息。如果消费者读到日志末尾，则会等待新消息追加的通知。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了伸缩超出单个磁盘所能提供的更高吞吐量，可以对日志进行&lt;strong&gt;分区&lt;/strong&gt;。不同的分区可以托管在不同的机器上，使得每个分区都有一份能独立于其他分区进行读写的日志。一个主题可以定义为一组携带相同类型消息的分区。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia30.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;在每个分区内，代理为每个消息分配一个单调递增的序列号或偏移量（因为是追加写入，保证了单分区的完全有序，但无法保证不同分区有序）。&lt;/p&gt;
&lt;h4 id=&#34;日志-vs-消息传递&#34;&gt;日志 VS 消息传递&lt;/h4&gt;
&lt;p&gt;在消息处理代价高昂，希望逐条并行处理，以及消息的顺序并没有那么重要的情况下，基于队列的消息代理是可取的。另一方面，在消息吞吐量很高，处理迅速，顺序很重要的情况下，基于日志的方法表现得非常好。&lt;/p&gt;
&lt;h4 id=&#34;消费者偏移量&#34;&gt;消费者偏移量&lt;/h4&gt;
&lt;p&gt;由于日志是追加写入的，因此仅仅需要通过偏移量就可以判断消息是否已被处理：**所有偏移量小于消费者的当前偏移量的消息已经被处理，而具有更大偏移量的消息还没有被看到。**因此，代理不需要跟踪确认每条消息，只需要定期记录消费者的偏移即可。&lt;/p&gt;
&lt;h4 id=&#34;磁盘空间使用&#34;&gt;磁盘空间使用&lt;/h4&gt;
&lt;p&gt;为了避免数据不断写入而导致磁盘空间耗尽，通常日志会被分为多个段，并不定时将旧段删除或归档存储。为了避免生产者写入过快，导致消费者读取到被删除的数据，从而丢失数据，日志通常会实现一个循环缓冲区，当缓冲区填满后再丢弃数据。&lt;/p&gt;
&lt;h4 id=&#34;重播旧消息&#34;&gt;重播旧消息&lt;/h4&gt;
&lt;p&gt;在基于队列的消息代理中，处理和确认消息后会导致该消息被删除。而在基于日志的代理中，则仅仅是读取日志，并不会做任何的修改操作。这也就使得我们能够重放数据，即从之前的偏移量开始重新读取。&lt;/p&gt;
&lt;h2 id=&#34;数据库与流&#34;&gt;数据库与流&lt;/h2&gt;
&lt;h3 id=&#34;保持系统同步&#34;&gt;保持系统同步&lt;/h3&gt;
&lt;p&gt;通常情况下，没有一个系统能够满足所有的存储需求，这就要求当一个数据发生变动时，这个变更应该同步到所有的相关系统中。&lt;/p&gt;
&lt;p&gt;对于数据仓库而言，通常的作法是&lt;strong&gt;转储数据库&lt;/strong&gt;——取得数据库的完整副本，然后执行 ETL 将数据加载到数据仓库中。但是由于这样做的效率过低，有时人们又会采取&lt;strong&gt;双写&lt;/strong&gt;来进行替代——代码在写入数据库的同时写入到每个系统中。&lt;/p&gt;
&lt;p&gt;但是双写在改善效率的同时，又带来了一系列的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据竞争&lt;/strong&gt;：在并发写入的时候，一台机器可能会覆盖掉另一个机器的写入结果，并且双方都无法感知这个过程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子提交&lt;/strong&gt;：双写需要保证写入操作是原子的，否则一个写入成功、一个写入失败时就会导致数据的不一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;变更数据捕获&#34;&gt;变更数据捕获&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;变更数据捕获（change data capture, CDC）&lt;/strong&gt; 指的是记录是写入数据库的所有数据变更，将其提取并转换为可以复制到其他系统中的形式的过程。&lt;/p&gt;
&lt;p&gt;如下图，我们可以捕获数据中的变更，并将变更日志以相同的顺序应用于其他系统中，则能够保证多个系统中的数据与数据库一致。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;通常的实现方案有如下两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据库触发器&lt;/strong&gt;：注册观察所有变更的触发器，并将相应的变更项写入变更日志表中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解析复制日志&lt;/strong&gt;：解析数据库的日志，将解析出来的修改传递给下游。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;事件溯源&#34;&gt;事件溯源&lt;/h3&gt;
&lt;p&gt;事件溯源是一种强大的数据建模技术：从应用的角度来看，将用户的行为记录为不可变的事件更有意义，而不是在可变数据库中记录这些行为的影响。事件溯源使得应用随时间演化更为容易，通过更容易理解事情发生的原因来帮助调试的进行，并有利于防止应用 Bug。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;事件溯源和变更数据捕获都将所有对应用状态的变更存储为变更事件日志，那么它们有什么区别呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;在变更数据捕获中，应用以&lt;strong&gt;可变方式&lt;/strong&gt;使用数据库，可以任意更新和删除记录。变更日志是从数据库的底层提取的（例如，通过解析复制日志），从而确保从数据库中提取的写入顺序与实际写入的顺序相匹配。&lt;/li&gt;
&lt;li&gt;在事件溯源中，应用逻辑显式构建在写入事件日志的不可变事件之上。在这种情况下，事件存储是仅追加写入的，更新与删除是不鼓励的或禁止的。事件被设计为旨在反映应用层面发生的事情，而不是底层的状态变更。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;事件溯源的核心是区分&lt;strong&gt;事件（event）&lt;strong&gt;和&lt;/strong&gt;命令（command）&lt;/strong&gt;。当来自用户的请求刚到达时，它一开始是一个命令：在这个时间点上它仍然可能可能失败，比如，因为违反了一些完整性条件。应用必须首先验证它是否可以执行该命令。如果验证成功并且命令被接受，则它变为一个持久化且不可变的事件。&lt;/p&gt;
&lt;p&gt;在事件生成的时刻，它就成为 &lt;strong&gt;事实（fact）&lt;/strong&gt;。即使用户对其进行删除或者修改，也只是在后续单独添加了删除、修改事件。&lt;/p&gt;
&lt;h2 id=&#34;流处理-1&#34;&gt;流处理&lt;/h2&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;p&gt;除了传统的监控（欺诈检测、机器状态检测、金融交易等），流处理还有以下这些应用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;复合事件处理（CEP）&lt;/li&gt;
&lt;li&gt;数据分析&lt;/li&gt;
&lt;li&gt;物化视图&lt;/li&gt;
&lt;li&gt;搜索引擎&lt;/li&gt;
&lt;li&gt;消息传递和 PRC&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;时间推理&#34;&gt;时间推理&lt;/h3&gt;
&lt;h4 id=&#34;事件时间和处理时间&#34;&gt;事件时间和处理时间&lt;/h4&gt;
&lt;p&gt;在流处理中有事件时间和处理时间的概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件时间&lt;/strong&gt;：事件发生的时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;处理时间&lt;/strong&gt;：机器接收到事件时，对其进行处理的时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果我们以处理时间作为标准，则可能会出现逻辑上的紊乱（与时间实际发生的顺序不同），而如果是事件时间作为标准，则考虑到延迟、排队、网络故障等因素，则可能会出现某些事件延迟很久才会到来，甚至丢失的情况。&lt;/p&gt;
&lt;h4 id=&#34;知道什么时候准备好了&#34;&gt;知道什么时候准备好了&lt;/h4&gt;
&lt;p&gt;当我们使用事件时间定义窗口时，就会遇到上面说的问题，我们无法判断当前这个窗口的事件有没有完整的到来。&lt;/p&gt;
&lt;p&gt;通常情况下，我们会设定一个超时时间，当到达这个时间后我们就认为当前窗口已经就绪，开始聚合计算。倘若后续有延迟的数据到来，此时可以采用两种方案进行处理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;丢弃数据&lt;/strong&gt;：丢弃这些延迟的数据。为了防止丢失的数据过多，可以设定一个监控的阈值，当丢弃数据过多时发出警报，重放数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修正数据&lt;/strong&gt;：将该数据放入旧窗口中，同时需要回撤以前的输出，确保数据的正确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;时钟&#34;&gt;时钟&lt;/h4&gt;
&lt;p&gt;考虑到各个机器的物理时钟可能会存在误差（客户端的时间可能因为用户的错误设置，出现明显的错误），通常需要记录三个时间戳来校准时间：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事件发生的时间（依赖于客户端时钟）。&lt;/li&gt;
&lt;li&gt;事件发送给服务器的时间（依赖于客户端时钟）&lt;/li&gt;
&lt;li&gt;服务器接收事件的时间（依赖于服务器时钟）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过从第三个时间戳中减去第二个时间戳，可以估算设备时钟和服务器时钟之间的偏移（假设网络延迟与所需的时间戳精度相比可忽略不计）。然后可以将该偏移应用于事件时间戳，从而估计事件实际发生的真实时间（假设设备时钟偏移在事件发生时与送往服务器之间没有变化）。&lt;/p&gt;
&lt;h4 id=&#34;窗口类型&#34;&gt;窗口类型&lt;/h4&gt;
&lt;p&gt;常见的窗口类型有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;滚动窗口（Tumbling Window）&lt;/strong&gt;：滚动窗口有着固定的长度，每个事件都仅能属于一个窗口。例如，假设你有一个 1 分钟的滚动窗口，则所有时间戳在 &lt;code&gt;10:03:00&lt;/code&gt; 和 &lt;code&gt;10:03:59&lt;/code&gt; 之间的事件会被分组到一个窗口中，&lt;code&gt;10:04:00&lt;/code&gt; 和 &lt;code&gt;10:04:59&lt;/code&gt; 之间的事件被分组到下一个窗口，依此类推。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跳动窗口（Hopping Window）&lt;/strong&gt;：跳动窗口也有着固定的长度，但允许窗口重叠以提供一些平滑。例如，一个带有 1 分钟跳跃步长的 5 分钟窗口将包含 &lt;code&gt;10:03:00&lt;/code&gt; 至 &lt;code&gt;10:07:59&lt;/code&gt; 之间的事件，而下一个窗口将覆盖 &lt;code&gt;10:04:00&lt;/code&gt; 至 &lt;code&gt;10:08:59&lt;/code&gt; 之间的事件，等等。通过首先计算 1 分钟的滚动窗口（tunmbling window），然后在几个相邻窗口上进行聚合，可以实现这种跳动窗口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;滑动窗口（Sliding Window）&lt;/strong&gt;：滑动窗口包含了彼此间距在特定时长内的所有事件。例如，一个 5 分钟的滑动窗口应当覆盖 &lt;code&gt;10:03:39&lt;/code&gt; 和 &lt;code&gt;10:08:12&lt;/code&gt; 的事件，因为它们相距不超过 5 分钟。通过维护一个按时间排序的事件缓冲区，并不断从窗口中移除过期的旧事件，可以实现滑动窗口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;会话窗口（Session window）&lt;/strong&gt;：与其他窗口类型不同，会话窗口没有固定的持续时间，它将同一用户出现时间相近的所有事件分组在一起，而当用户一段时间没有活动时结束窗口。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;流连接&#34;&gt;流连接&lt;/h3&gt;
&lt;p&gt;在流处理中主要有以下三种连接类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;流流连接（窗口连接）&lt;/strong&gt;：两个输入流都由活动事件组成，而连接算子在某个时间窗口内搜索相关的事件。如果你想要找出一个流内的相关事件，连接的两侧输入可能实际上都是同一个流（自连接）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;流表连接（流扩充）&lt;/strong&gt;：一个输入流由活动事件组成，另一个输入流是数据库变更日志。变更日志保证了数据库的本地副本是最新的。对于每个活动事件，连接算子将查询数据库，并输出一个扩展的活动事件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;表表连接（维护物化视图）&lt;/strong&gt;：两个输入流都是数据库变更日志。在这种情况下，一侧的每一个变化都与另一侧的最新状态相连接。结果是两表连接所得物化视图的变更流。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;容错&#34;&gt;容错&lt;/h3&gt;
&lt;h4 id=&#34;微批量与存档点&#34;&gt;微批量与存档点&lt;/h4&gt;
&lt;p&gt;考虑到流处理没有边界，数据永远不会停止，为了尽可能的减少延迟，Spark Streaming 将流分解为一个个小块，并像微型批处理一样处理每个块。这种方法被称为&lt;strong&gt;微批（microbatching）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而 Flink 则采取了另一种方案，它会定期生成状态的滚动存档点并将其写入持久存储。如果流算子崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出。&lt;/p&gt;
&lt;p&gt;在流处理中，这两种方法都满足于&lt;strong&gt;恰好一次语义（exactly-once semantics）&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;原子提交&#34;&gt;原子提交&lt;/h4&gt;
&lt;p&gt;为了在出现故障时满足 exactly-once ，我们需要确保事件处理的所有输出和副作用当且仅当处理成功时才会生效。这些事情要么都原子地发生，要么都不发生，但是它们不应当失去同步。&lt;/p&gt;
&lt;h4 id=&#34;幂等性&#34;&gt;幂等性&lt;/h4&gt;
&lt;p&gt;我们的目标是丢弃任何失败任务的部分输出，以便能安全地重试，而不会生效两次。分布式事务是实现这个目标的一种方式，而另一种方式是依 &lt;strong&gt;幂等性（idempotence）&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;幂等操作指的是是多次重复执行与单次执行效果相同的操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;那么如何实现幂等呢？可以参考 Kafka 的解决方案，即为每个消息附带一个持久的、单调递增的偏移量，通过这个偏移量就可以判断这个消息是否被执行过，从而避免重复执行。&lt;/p&gt;
&lt;h4 id=&#34;失败后重建状态&#34;&gt;失败后重建状态&lt;/h4&gt;
&lt;p&gt;任何需要状态的流处理以及任何用于连接的表和索引，都必须确保在失败之后能恢复其状态。通常会采用如下解决方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将状态保存在远程数据存储中，并进行复制。&lt;/li&gt;
&lt;li&gt;在流处理器本地保存状态，并定期复制。当流处理器从故障中恢复时，新任务可以读取状态副本，恢复处理而不丢失数据。&lt;/li&gt;
&lt;li&gt;不需要复制状态，直接从输入流中重建状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至于要选择哪个方案，需要根据业务场景、底层架构的性能来进行分析。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（十）：批处理</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%8D%81%E6%89%B9%E5%A4%84%E7%90%86/</link>
        <pubDate>Sun, 10 Jul 2022 09:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%8D%81%E6%89%B9%E5%A4%84%E7%90%86/</guid>
        <description>&lt;h1 id=&#34;批处理&#34;&gt;批处理&lt;/h1&gt;
&lt;p&gt;从高层次来看，存储和处理数据的系统可以分为两大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;记录系统&lt;/strong&gt;：其持有数据的权威版本。当新的数据进入时首先会记录在这里。每个记录在系统中只表示一次。如果其他系统和记录系统之间存在任何差异，那么此时将以记录系统中的值为准。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;派生数据系统&lt;/strong&gt;：派生数据系统中的数据通常是另一个系统中的现有数据以某种方式进行转换或处理的结果。如果丢失派生数据，可以从原始数据源中重新创建。典型的例子是&lt;strong&gt;缓存（cache）&lt;/strong&gt;：如果数据在缓存中，则可以从缓存中读取；如果缓存不包含所需数据，则降级由底层数据库提供。非规范化的值，索引和物化视图亦属此类。在推荐系统中，预测汇总数据通常衍生自用户日志。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;派生数据是&lt;strong&gt;冗余的（redundant）&lt;/strong&gt;，因为它重复了已有的信息。但是派生数据对于获得良好的只读查询性能通常是至关重要的。它通常是非规范化的。可以从单个源头衍生出多个不同的数据集，使我们能从不同的视角观察数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据&lt;strong&gt;响应时间&lt;/strong&gt;的不同，数据处理系统通常分为以下三种类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;在线服务（在线系统）&lt;/strong&gt;：服务等待客户的请求或指令到达。每收到一个，服务会试图尽快处理它，并发回一个响应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批处理系统（离线系统）&lt;/strong&gt;：一个批处理系统有大量的输入数据，通过运行一个 job 来处理这些数据，并生成一些输出数据，这往往需要一段时间（从几分钟到几天），所以通常不会有用户等待 job 完成。相反，批量作业通常会定期运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流处理系统（准实时系统）&lt;/strong&gt;：处于在线和离线系统之间。像批处理系统一样，流处理消费输入并产生输出（并不需要响应请求）。但是，流式作业在事件发生后不久就会对事件进行操作，而批处理作业则需等待固定的一组输入数据。这种差异使流处理系统比起批处理系统具有更低的延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基于-unix-工具的批处理&#34;&gt;基于 UNIX 工具的批处理&lt;/h2&gt;
&lt;p&gt;最简便的批处理方案是基于 UNIX 工具实现的，例如我们需要在一个网站中找出访问最高频的五个网页：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 原始数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;216.58.210.78 - - &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;27/Feb/2015:17:55:11 +0000&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;GET /css/typography.css HTTP/1.1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3377&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://martin.kleppmann.com/&amp;#34;&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 处理方案&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat /var/log/nginx/access.log &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  awk &lt;span class=&#34;s1&#34;&gt;&amp;#39;{print $7}&amp;#39;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  sort             &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  uniq -c          &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#4&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  sort -r -n       &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  head -n &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;          &lt;span class=&#34;c1&#34;&gt;#6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cat&lt;/code&gt; 读取日志文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;awk&lt;/code&gt; 每行只获取第七个字段，恰好是 URL 的那个。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort&lt;/code&gt; 按照字段序排列 URL。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uniq -c&lt;/code&gt; 计算出每一个 URL 重复的次数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort -r -n&lt;/code&gt; 按照每一个 URL 出现的次数降序排序。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;head -n 5&lt;/code&gt; 取出现次数最高的五个 URL。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用 &lt;code&gt;awk&lt;/code&gt;、&lt;code&gt;sed&lt;/code&gt;、&lt;code&gt;grep&lt;/code&gt;、&lt;code&gt;sort&lt;/code&gt;、&lt;code&gt;uniq&lt;/code&gt; 和 &lt;code&gt;xargs&lt;/code&gt; 的组合，可以在几分钟内完成许多数据分析，并且它们的性能也相当不错。&lt;/p&gt;
&lt;p&gt;然而这些 Unix 工具有一个致命的缺陷，它们只能在一台机器上运行。为了解决这个问题，MapReduce 诞生了。&lt;/p&gt;
&lt;h2 id=&#34;mapreduce&#34;&gt;MapReduce&lt;/h2&gt;
&lt;h3 id=&#34;mapreduce-作业执行&#34;&gt;MapReduce 作业执行&lt;/h3&gt;
&lt;p&gt;MapReduce 是一个编程框架，你可以使用它编写代码来处理 HDFS 等分布式文件系统中的大型数据集。其数据处理流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读取一组输入文件，并将其分解成&lt;strong&gt;记录（records）&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;Mapper&lt;/code&gt; 函数，从每条输入记录中提取一对键值。&lt;/li&gt;
&lt;li&gt;按键排序所有的键值对。&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;Reducer&lt;/code&gt; 函数遍历排序后的键值对。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这四个步骤可以作为一个 MapReduce 作业执行。由于步骤 1（将文件分解成记录）由输入格式解析器处理，而步骤 3 中的排序步骤隐含在 MapReduce，因此我们去需要自己去实现 &lt;code&gt;Mapper&lt;/code&gt; 和 &lt;code&gt;Reducer&lt;/code&gt; 函数即可：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mapper&lt;/strong&gt;：Mapper 会在每条输入记录上调用一次，其工作是从输入记录中提取键值。对于每个输入，它可以生成任意数量的键值对。它不会保留从一个输入记录到下一个记录的任何状态，因此每个记录都是独立处理的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reducer&lt;/strong&gt;：MapReduce 框架拉取由 Mapper 生成的键值对，收集属于同一个键的所有值，并在这组值上迭代调用 Reducer。 Reducer 可以产生输出记录。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;分布式执行-mapreduce&#34;&gt;分布式执行 MapReduce&lt;/h4&gt;
&lt;p&gt;MapReduce 与 Unix 命令管道的主要区别在于：&lt;strong&gt;MapReduce 可以在多台机器上并行执行计算，而无需编写代码来显式处理并行问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下图即为 Hadoop MapReduce 作业中的数据流，其并行化基于&lt;strong&gt;分区&lt;/strong&gt;实现：作业的输入通常是 HDFS 中的一个目录，输入目录中的每个文件或文件块都被认为是一个单独的分区，可以单独处理 &lt;code&gt;map&lt;/code&gt; 任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;只要有足够的空闲内存和 CPU 资源，MapReduce 调度器就会尝试在其中一台存储输入文件副本的机器上运行 Mapper 任务。这个原则被称为&lt;strong&gt;将计算放在数据附近&lt;/strong&gt;：它节省了通过网络复制输入文件的开销，减少网络负载并增加局部性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia32.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图，MapReduce 的完整执行流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MapReduce 框架首先将代码复制到适当的机器。然后启动 &lt;code&gt;Map&lt;/code&gt; 任务并开始读取输入文件，一次将一条记录传入 &lt;code&gt;Mapper&lt;/code&gt; 回调函数。&lt;/li&gt;
&lt;li&gt;键值对必须进行排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序。因此每个 &lt;code&gt;Map&lt;/code&gt; 任务都按照 &lt;code&gt;Reducer&lt;/code&gt; 对输出进行分区。每个分区都被写入 &lt;code&gt;Mapper&lt;/code&gt; 程序的本地磁盘&lt;/li&gt;
&lt;li&gt;当 &lt;code&gt;Mapper&lt;/code&gt; 读取完输入文件，并写完排序后的输出文件后，MapReduce 调度器就会通知 &lt;code&gt;Reducer&lt;/code&gt; 可以从该 &lt;code&gt;Mapper&lt;/code&gt; 中获取输出文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Reducer&lt;/code&gt; 连接到每个 &lt;code&gt;Mapper&lt;/code&gt;，并下载自己相应分区的有序键值对文件。按 &lt;code&gt;Reducer&lt;/code&gt; 分区，排序，从 &lt;code&gt;Mapper &lt;/code&gt;向 &lt;code&gt;Reducer&lt;/code&gt; 复制分区数据，这一整个过程被称为 &lt;code&gt;shuffle&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Reduce&lt;/code&gt; 任务从 &lt;code&gt;Mapper&lt;/code&gt; 获取文件，并将它们 &lt;code&gt;merge&lt;/code&gt; 在一起，并保留有序特性。因此，如果不同的 &lt;code&gt;Mapper&lt;/code&gt; 生成了键相同的记录，则在 &lt;code&gt;Reducer&lt;/code&gt; 的输入中，这些记录将会相邻。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Reducer&lt;/code&gt; 调用时会收到一个键，和一个迭代器作为参数，迭代器会顺序地扫过所有具有该键的记录。&lt;code&gt;Reducer&lt;/code&gt; 可以使用任意逻辑来处理这些记录，并且可以生成任意数量的输出记录。这些输出记录会写入分布式文件系统上的文件中。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;考虑到单个 MapReduce 作业可以解决的问题范围很有限，因此我们可以将 MapReduce 作业链接成一个工作流，即一个作业的输出成为下一个作业的输入。&lt;/p&gt;
&lt;p&gt;只有当作业成功完成后，批处理作业的输出才会被视为有效的。因此，工作流中的一项作业只有在先前的作业成功完成后才能开始。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;reduce-侧-join-与分组&#34;&gt;Reduce 侧 join 与分组&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;在许多数据集中，一条记录与另一条记录存在关联是很常见的，例如关系模型中的&lt;strong&gt;外键&lt;/strong&gt;、文档模型中的&lt;strong&gt;文档引用&lt;/strong&gt;、图模型中的&lt;strong&gt;边&lt;/strong&gt;。当你需要同时访问这一关联的两侧时，就必须进行 join。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;排序合并-join&#34;&gt;排序合并 join&lt;/h4&gt;
&lt;p&gt;在 Reducer 中执行实际的 join 逻辑，被称为 Reduce 侧 join 。&lt;/p&gt;
&lt;p&gt;通常我们会采用排序合并 join，其原理如下：&lt;strong&gt;每个参与 join 的输入都会由一个提取 join 键的 Mapper 进行处理。通过分区、排序和合并，具有相同键的所有记录最终都会进入相同的 Reducer 调用，然后这个函数输出 join 好的记录。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;分组&#34;&gt;分组&lt;/h4&gt;
&lt;p&gt;除了 join 之外，还有另一种方法能将相关数据放在一起，即按某个键对记录分组（如 SQL 中的 &lt;code&gt;GROUP BY&lt;/code&gt; ）。&lt;/p&gt;
&lt;p&gt;使用 MapReduce 实现这种分组操作的最简单方法是设置 Mapper，使它们生成的键值对使用所需的分组键。然后在分区和排序过程将所有具有相同分区键的记录导向同一个 Reducer。（因此在 MapReduce 之上实现分组和 join 看上去非常相似。）&lt;/p&gt;
&lt;h4 id=&#34;数据倾斜&#34;&gt;数据倾斜&lt;/h4&gt;
&lt;p&gt;如果存在与单个键关联的大量数据，则将具有相同键的所有记录放到相同的位置这种模式就会产生问题：大量的数据放到一台机器上，从而导致负载不均衡。这种情况也被称为数据倾斜，而这种数据被称为热点数据（热键）。&lt;/p&gt;
&lt;p&gt;为了处理这种情况，当 join 的输入存在热键的时候，可以采取一些补偿机制，例如下面几种方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pig 的解决方案&lt;/strong&gt;：首先运行一个抽样作业来确定哪些键是热键。join 实际执行时，Mapper 会将热键的关联记录随机发送到几个 Reducer 之一。对于另外一侧的 join 输入，与热键相关的记录需要被复制所有处理该键的 Reducer 上。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hive 的解决方案&lt;/strong&gt;：在表格元数据中显式指定热键，并将与这些键相关的记录单独存放，与其它文件分开。当在该表上执行连接时，对于热键，它会使用 Map 端 join。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;map-侧-join&#34;&gt;Map 侧 join&lt;/h3&gt;
&lt;p&gt;Reduce 侧 join 的优点是不需要对输入数据做任何假设：无论其属性和结构如何，Mapper 都可以对其预处理以备连接。然而不利的一面是，排序，复制至 Reducer，以及合并 Reducer 输入，所有这些操作可能开销巨大。当数据通过 MapReduce 阶段时，数据可能需要落盘好几次（次数取决于可用的内存缓冲区）。&lt;/p&gt;
&lt;p&gt;倘若我们能够对输入数据做一些假设，我们就可以使用 Map 侧 join 来加快我们的 join 速度。&lt;/p&gt;
&lt;h4 id=&#34;广播哈希-join&#34;&gt;广播哈希 join&lt;/h4&gt;
&lt;p&gt;适用于执行 Map 端连接的最简单场景是大数据集与小数据集连接的情况。&lt;/p&gt;
&lt;p&gt;其要求小数据集需要足够小，不需要进行分区，以便可以将其完全加载进一个哈希表中。因此，你可以为连接输入大端的每个分区启动一个 Mapper，将输入小端的哈希表加载到每个 Mapper 中，然后扫描大端，一次一条记录，并为每条记录查询哈希表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;除了将较小的连接输入加载到内存哈希表中，另一种方法是将较小输入存储在本地磁盘上的只读索引中。索引中经常使用的部分将保留在操作系统的页面缓存中，因而这种方法可以提供与内存哈希表几乎一样快的随机查找性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;分区哈希-join&#34;&gt;分区哈希 join&lt;/h4&gt;
&lt;p&gt;如果两个连接输入以相同的方式分区（使用相同的键，相同的哈希函数和相同数量的分区），则可以独立地对每个分区应用哈希表方法。&lt;/p&gt;
&lt;h4 id=&#34;map-侧合并-join&#34;&gt;Map 侧合并 join&lt;/h4&gt;
&lt;p&gt;如果输入数据集不仅以相同的方式进行分区，而且还基于相同的键进行排序，则可适用另一种 Map 侧连接的变体。&lt;/p&gt;
&lt;p&gt;在这种情况下，输入是否小到能放入内存并不重要，因为这时候 Mapper 同样可以执行归并操作（通常由 Reducer 执行）：按键递增的顺序依次读取两个输入文件，将具有相同键的记录配对。&lt;/p&gt;
&lt;h4 id=&#34;mapreduce-工作流与-map-侧-join&#34;&gt;Mapreduce 工作流与 Map 侧 join&lt;/h4&gt;
&lt;p&gt;当下游作业使用 MapReduce join 的输出时，选择 Map 侧 join 或 Reduce 侧 join 会影响输出的结构。Reduce 侧 join 的输出是按照 join 键进行分区和排序的，而 Map 端 join 的输出则按照与较大输入相同的方式进行分区和排序。&lt;/p&gt;
&lt;h3 id=&#34;批处理的应用场景&#34;&gt;批处理的应用场景&lt;/h3&gt;
&lt;p&gt;批处理有以下几种常见的使用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建搜索引擎。&lt;/li&gt;
&lt;li&gt;构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，图像识别）与推荐系统（例如，你可能认识的人，你可能感兴趣的产品或相关的搜索）。&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mapreduce-之后&#34;&gt;MapReduce 之后&lt;/h2&gt;
&lt;h3 id=&#34;物化中间状态&#34;&gt;物化中间状态&lt;/h3&gt;
&lt;p&gt;在很多情况下，一个作业的输出只能用作另一个作业的输入。在这种情况下，分布式文件系统上的文件只是简单的&lt;strong&gt;中间状态（intermediate state）&lt;/strong&gt;：一种将数据从一个作业传递到下一个作业的方式。将这个中间状态写入文件的过程称为&lt;strong&gt;物化（materialization）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在之前的例子中，Unix 利用管道将一个命令的输出与另一个命令的输入连接起来。管道并没有完全物化中间状态，而是只使用一个小的内存缓冲区，将输出增量地&lt;strong&gt;流（stream）&lt;/strong&gt; 向输入。与 Unix 管道相比，MapReduce 完全物化中间状态的方法存在以下不足之处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MapReduce 作业只有在前驱作业中的所有任务都完成时才能启动，而由 Unix 管道连接的进程会同时启动，输出一旦生成就会被消费。不同机器上的数据偏斜或负载不均意味着一个作业往往会有一些掉队的任务，比其他任务要慢得多才能完成，拖慢了整个工作流程的执行。&lt;/li&gt;
&lt;li&gt;Mapper 通常是多余的：它们仅仅是读取刚刚由 Reducer 写入的同样文件，为下一个阶段的分区和排序做准备。在许多情况下，Mapper 代码可能是前驱 Reducer 的一部分：如果 Reducer 和 Mapper 的输出有着相同的分区与排序方式，那么 Reducer 就可以直接串在一起，而不用与 Mapper 相互交织。&lt;/li&gt;
&lt;li&gt;将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，对这些临时数据来说显得有些浪费。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据流引擎&#34;&gt;数据流引擎&lt;/h4&gt;
&lt;p&gt;为了解决 MapReduce 的这些问题，几种用于分布式批处理的新执行引擎被开发出来（如 Spark、Flink 等）。它们的设计方式有一个共同点：&lt;strong&gt;把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于它们将工作流显式建模为数据从几个处理阶段穿过，所以这些系统被称为&lt;strong&gt;数据流引擎（dataflow engines）&lt;/strong&gt;。像 MapReduce 一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，它们通过输入分区来并行化载荷，它们通过网络将一个函数的输出复制到另一个函数的输入。&lt;/p&gt;
&lt;p&gt;与 MapReduce 不同，这些函数不需要严格扮演交织的 Map 与 Reduce 的角色，而是可以以更灵活的方式进行组合。我们称这些函数为&lt;strong&gt;算子（operators）&lt;/strong&gt;，数据流引擎提供了几种不同的选项来将一个算子的输出连接到另一个算子的输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对记录按键重新分区并排序，就像在 MapReduce 的 shuffle 阶段一样。&lt;/li&gt;
&lt;li&gt;接受多个输入，并以相同的方式进行分区，但跳过排序。&lt;/li&gt;
&lt;li&gt;将一个算子的输出，发送到连接算子的所有分区。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与 MapReduce 模型相比，它有几个优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;排序等昂贵的工作只需要在实际需要的地方执行，而不是默认地在每个 Map 和 Reduce 阶段之间出现。&lt;/li&gt;
&lt;li&gt;没有不必要的 Map 任务，因为 Mapper 所做的工作通常可以合并到前面的 Reduce 算子中。&lt;/li&gt;
&lt;li&gt;由于工作流中的所有连接和数据依赖都是显式声明的，因此调度程序能够总览全局，知道哪里需要哪些数据，因而能够利用局部性进行优化。&lt;/li&gt;
&lt;li&gt;算子间的中间状态足以保存在内存中或写入本地磁盘，这比写入 HDFS 需要更少的 I/O（必须将其复制到多台机器，并将每个副本写入磁盘）。&lt;/li&gt;
&lt;li&gt;算子可以在输入就绪后立即开始执行；后续阶段无需等待前驱阶段整个完成后再开始。&lt;/li&gt;
&lt;li&gt;与 MapReduce（为每个任务启动一个新的 JVM）相比，现有JVM 进程可以重用来运行新算子，从而减少启动开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;容错&#34;&gt;容错&lt;/h4&gt;
&lt;p&gt;完全物化中间状态至 HDFS 的一个优点是，它具有持久性，这使得 MapReduce 中的容错相当容易：如果一个任务失败，它可以在另一台机器上重新启动，并从文件系统重新读取相同的输入。&lt;/p&gt;
&lt;p&gt;Spark、Flink 和 Tez 避免将中间状态写入 HDFS，因此它们采取了不同的方法来容错：如果一台机器发生故障，并且该机器上的中间状态丢失，则它会从其他仍然可用的数据重新计算（在可行的情况下是先前的中间状态，要么就只能是原始输入数据，通常在 HDFS 上）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为了实现重新计算，框架需要获取一个数据的计算信息（输入分区、算子等）。 Spark 使用**弹性分布式数据集（RDD，Resilient Distributed Dataset）**的抽象来跟踪数据的谱系，而 Flink 对算子状态存档，允许恢复运行在执行过程中遇到错误的算子。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;图与迭代处理&#34;&gt;图与迭代处理&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;像 Spark、Flink 和 Tez 这样的数据流引擎通常将算子作为**有向无环图（DAG）**的一部分安排在作业中。这与图处理不一样：在数据流引擎中，&lt;strong&gt;从一个算子到另一个算子的数据流&lt;/strong&gt;被构造成一个图，而数据本身通常由关系型元组构成。在图处理中，数据本身具有图的形式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;许多图算法是通过一次遍历一条边来表示的，将一个顶点与近邻的顶点连接起来，以传播一些信息，并不断重复，直到满足一些条件为止（例如，直到没有更多的边要跟进，或直到一些指标收敛）。&lt;/p&gt;
&lt;p&gt;可以在分布式文件系统中存储图（包含顶点和边的列表的文件），但是这种重复至完成的想法不能用普通的 MapReduce 来表示，因为它只扫过一趟数据。这种算法因此经常以&lt;strong&gt;迭代&lt;/strong&gt;的风格实现：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;外部调度程序运行批处理来计算算法的一个步骤。&lt;/li&gt;
&lt;li&gt;当批处理过程完成时，调度器检查它是否完成（基于完成条件 —— 例如，没有更多的边要跟进，或者与上次迭代相比的变化低于某个阈值）。&lt;/li&gt;
&lt;li&gt;如果尚未完成，则调度程序返回到步骤 1 并运行另一轮批处理。&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（九）：一致性与共识</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%9D%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%85%B1%E8%AF%86/</link>
        <pubDate>Sun, 10 Jul 2022 08:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%9D%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%85%B1%E8%AF%86/</guid>
        <description>&lt;h1 id=&#34;一致性与共识&#34;&gt;一致性与共识&lt;/h1&gt;
&lt;h2 id=&#34;可线性化强一致性&#34;&gt;可线性化（强一致性）&lt;/h2&gt;
&lt;p&gt;在最终一致性数据库中，同时查询两个不同的副本可能会得到两个不同的答案。这会 使应用层感到困惑。如果数据库能够对上提供只有单个副本的假象，情况会不会大为简化呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这样让每个客户端都拥有相同的数据视图，而不必担心复制滞后的思想&lt;/strong&gt;，就是&lt;strong&gt;可线性化（强一致性）&lt;/strong&gt;。&lt;strong&gt;其基本的想法是让一个系统看起来好像只有一个数据副本，且所有的操作都是原子的。&lt;/strong&gt; 有了这个保证，应用程序就不需要关心系统内部的多个副本。&lt;/p&gt;
&lt;p&gt;在一个可线性化的系统中，一旦某个客户端成功提交写请求，所有客户端的读请求一定都能看到刚刚写入的值。这种看似单一副本的假象意味着&lt;strong&gt;它可以保证读取最近最新值，而不是过期的缓存&lt;/strong&gt;。换句话说，&lt;strong&gt;可线性化是一种就近的保证。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;可线性化与可串行化&#34;&gt;可线性化与可串行化&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可串行化&lt;/strong&gt;：可串行化是事务的隔离级别，其中每个事务可以读写多个对象。它用来确保事务执行的结果与串行执行（即每次执行一个事务）的结果完全相同，即使串行执行的顺序可能与事务实际执行顺序不同。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可线性化&lt;/strong&gt;：可线性化是读写寄存器（单个对象）的最新值保证。它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数据库可以同时支持可串行化与线性化，这种组合又被称为严格的可串行化或者强的单副本可串行化。基于两阶段加锁或者实际以串行执行都是典型的可线性化。&lt;/p&gt;
&lt;h3 id=&#34;使用场景&#34;&gt;使用场景&lt;/h3&gt;
&lt;p&gt;在有些场景下，线性化对于保证系统正确工作至关重要。&lt;/p&gt;
&lt;h4 id=&#34;加锁与主节点选举&#34;&gt;加锁与主节点选举&lt;/h4&gt;
&lt;p&gt;主从复制的系统需要确保有且只有一个主节点，否则会产生脑裂。选举新的主节点常见的方法是使用锁，即每个启动的节点都试图获得锁，其中只有一个可以成功即成为主节点。不管锁具体如何实现，它都必须满足可线性化，即所有节点都必须同意哪个节点持有锁，否则就会出现问题。&lt;/p&gt;
&lt;h4 id=&#34;约束与唯一性保证&#34;&gt;约束与唯一性保证&lt;/h4&gt;
&lt;p&gt;唯一性约束在数据库中很常见。例如，用户名或电子邮件地址必须唯一标识一个用户、文件存储服务中两个文件不能具有相同的路径和文件名。如果要在写入数据时强制执行这些约束（例如，如果两个人试图同时创建具有相同名称的用户或文件，其中一个必须返回错误），则也需要线性化。&lt;/p&gt;
&lt;p&gt;这种情况本质上与加锁非常类似，用户注册等同于试图对用户名进行加锁操作。该操作也类似于原子比较和设置，如果当前用户名尚未被使用，就设置用户名与客户 ID 进行关联。&lt;/p&gt;
&lt;h4 id=&#34;跨通道的时间依赖&#34;&gt;跨通道的时间依赖&lt;/h4&gt;
&lt;p&gt;如果某个系统存在多个通信通道（如消息队列、文件存储），如果没有线性化的就近性保证，这两个通道之间就会产生竞争（如消息队列比存储服务内部复制更快），在这种情况下就会导致数据的不一致出现。&lt;/p&gt;
&lt;h3 id=&#34;实现&#34;&gt;实现&lt;/h3&gt;
&lt;p&gt;由于线性化本质上意味着&lt;strong&gt;表现得好像只有一个数据副本，且其上的所有操作都是原子的&lt;/strong&gt;，所以最简单的方案自然是只用一个数据副本。但显然，该方法无法容错。如果仅有的副本所在的节点发生故障，就会导致数据丢失，或者至少在重启之前都无法访问服务。&lt;/p&gt;
&lt;p&gt;系统容错最常见的方法就是采用&lt;strong&gt;复制&lt;/strong&gt;机制，那就来分析以下各个复制方案能否满足可线性化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;主从复制（部分支持线性化）&lt;/strong&gt;：在主从复制的系统中，只有主节点承担数据写入，从节点则在各自节点上维护数据的备份副本。如果从主节点或者同步更新的从节点上读取，则可以满足线性化。但并非每个主从复制的具体数据库示例都是可线性化的，主要是因为它们可能采用了快照隔离的设计，或者实现时存在并发方面的 bug（例如异步复制后数据丢失、从节点自认为是主节点等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;共识算法（可线性化）&lt;/strong&gt;：共识算法通常内置一些措施来防止脑裂和副本过期。正是由于这些专门的设计，共识算法可以安全地实现线性化存储。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多主复制（不可线性化）&lt;/strong&gt;：具有多主节点复制的系统通常无法线性化的，主要由于它们同时在多个节点上执行并发写入，并将数据异步复制到其他节点 。因此它们可能会产生冲突的写入，需要额外的解决方案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无主复制（可能不可线性化）&lt;/strong&gt;：对于无主节点复制的系统，有些人认为只要配置法定读取和写入满足 &lt;code&gt;w+r&amp;gt;n&lt;/code&gt; 就可以获得强一致性。但这完全取决于具体的 quorum 的配置，以及如何定义强一致性，它可能并不保证线性化。例如最后写入获胜几乎肯定是非线性化，因为这种时间戳无法保证与实际事件顺序一致（例如由于时钟偏移）不规范的 quorum 也会破坏线性化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;顺序保证&#34;&gt;顺序保证&lt;/h2&gt;
&lt;h3 id=&#34;顺序与因果关系&#34;&gt;顺序与因果关系&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;如果系统服从因果关系所规定的顺序，我们称之为因果一致性。&lt;/strong&gt; 例如，快照隔离提供了因果一致性，当从数据库中读数据时，如果查询到了某些数据，一定能看到触发该数据的前序事件（ 假设期间没有发生删除操作）。&lt;/p&gt;
&lt;h4 id=&#34;因果顺序并非全序&#34;&gt;因果顺序并非全序&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;全序关系支持任何两个元素之间进行比较&lt;/strong&gt;，即对于任意两个元素，总是可以指出哪个更大，哪个更小。但是，有些集合并不符合全序，因为它们都不是对方的子集，所以无法直接比较它们。&lt;strong&gt;我们称之为不可比较&lt;/strong&gt;，数学集合只能是&lt;strong&gt;偏序&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;全序和偏序的差异也会体现在不同的数据库一致性模型中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可线性化&lt;/strong&gt;：在一个可线性化的系统中，存在全序操作关系。系统的行为就好像只有一个数据副本，且每个操作都是原子的，这意味着对于任何两个操作，我们总是可以指出哪个操作在先。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;因果关系&lt;/strong&gt;：如果两个操作都没有发生在对方之前，那么这两个操作是并发关系。换言之，如果两个事件是因果关系（一个发生在另一个之前），那么这两个事件可以被排序。而并发的事件则无法排序比较。这表明因果关系至少可以定义为偏序，而非全序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，根据这个定义，在可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行。可能存在多个请求处于等待处理的状态，但是数据存储保证了在特定的时间点执行特定的操作，所以是单个时间轴，单个数据副本，没有并发。&lt;/p&gt;
&lt;h4 id=&#34;可线性化强于因果一致性&#34;&gt;可线性化强于因果一致性&lt;/h4&gt;
&lt;p&gt;那么因果序和可线性化之间是什么关系呢？&lt;/p&gt;
&lt;p&gt;答案是&lt;strong&gt;可线性化一定意味着因果关系，任何可线性化的系统都将正确地保证因果关系。&lt;/strong&gt; 特别是，如果系统存在多个通信通道，可线性化确保了因果关系会自动全部保留，而不需要额外的工作（比如在不同组件之间的传递时间戳）。&lt;/p&gt;
&lt;p&gt;可线性化虽然可以确保因果性，但其会显著降低性能和可用性，尤其是在严重网络延迟的情况下。正因如此，一些分布式数据系统已经放弃了线性化，以换来更好的性能，但也存在可能无法正确工作的风险。好消息是线性化并非是保证因果关系的唯一途径 ，还有其他方法使得系统可以满足因果一致性而免于线性化所带来的性能问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因果一致性可以认为是，不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强的一致性模型。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;捕获因果依赖关系&#34;&gt;捕获因果依赖关系&lt;/h4&gt;
&lt;p&gt;为保持因果关系，需要知道哪个操作发生在前。这里只需偏序关系，或并发操作会以任意顺序执行，但如果一个操作发生在另一个操作之前，那么每个副本都应该按照相同的顺序处理。&lt;strong&gt;因此，当某个副本在处理一个请求时，必须确保所有因果在前的请求都已完成处理，否则，后面的请求必须等待直到前序操作处理完毕。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了确定请求的因果依赖关系，它需要&lt;strong&gt;跟踪整个数据库请求的因果关系&lt;/strong&gt;，而不仅仅针对某个主键。&lt;strong&gt;版本向量&lt;/strong&gt;技术可以推广为一种通用的解决方案。&lt;/p&gt;
&lt;h3 id=&#34;序列号排序&#34;&gt;序列号排序&lt;/h3&gt;
&lt;p&gt;虽然因果关系很重要，但实际上跟踪所有的因果关系不切实际 。在许多应用程序中，客户端在写入之前会先读取大量数据，系统无法了解之后的写入究竟是依赖于全部读取内容， 还是仅仅是一小部分。但很明显，显式跟踪所有已读数据意味着巨大的运行开销。&lt;/p&gt;
&lt;p&gt;这里还有一个更好的方法，我们可以使用&lt;strong&gt;序列号&lt;/strong&gt;或&lt;strong&gt;时间戳&lt;/strong&gt;来排序事件。这样的序列号或时间戳非常紧凑（只有几字节大小），但它保证了全序关系。也就是说，每一个操作都有唯一的顺序号，并且总是可以通过比较来确定哪个更大（即操作发生在后）。这样的全局排序可以捕获所有的因果信息，但也强加了比因果关系更为严格的顺序性。&lt;/p&gt;
&lt;h4 id=&#34;非因果序列发生器&#34;&gt;非因果序列发生器&lt;/h4&gt;
&lt;p&gt;如果系统不存在这样唯一的主节点（例如可能是多主或者无主类型的数据库，或者数据库本身是分区的），产生序列号就不是那么简单了。实践中可以采用以下方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;每个节点都独立产生自己的一组序列号。&lt;/strong&gt; 例如，如果有两个节点，则一个节点只生成奇数，而另一个节点只生成偶数。还可以在序列号中保留一些位用于嵌入所属节点的唯一标识符，确保不同的节点永远不会生成相同的序列号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可以把日历时钟信息（物理时钟）附加到每个操作上。&lt;/strong&gt; 时间戳可能是不连续的，但是只要它们有足够高的分辨率，就可以用来区分操作。最后写获胜的冲突解决方案也使用类似的方法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可以预先分配序列号的区间范围。&lt;/strong&gt; 例如，节点 A 负责区间 1~1000 的序列号，节点 B 负责 1001~2000。然后每个节点独立地从区间中分配序列号，当序列号出现紧张时就分配更多的区间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述三种思路都可行，相比于把所有请求全部压给唯一的主节点具有更好的扩展性。它们为每个操作生成一个唯 一的、近似增加的序列号。不过，它们也都存在一个问题，&lt;strong&gt;即所产生的序列号与因果关系井不严格一致。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有这些序列号发生器都无法保证正确捕获跨节点操作的顺序，因而存在因果关系方面的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个节点可能有不同的处理速度，如每秒请求数。因此，某个节点产生偶数而另一个产生奇数，偶数的计数器产生速度可能落后于奇数的计数器，反之亦然。这样就无法准确地知道哪个操作在先。&lt;/li&gt;
&lt;li&gt;物理时钟的时间戳会受到时钟偏移的影响，也可能导致与实际因果关系不一致。&lt;/li&gt;
&lt;li&gt;对于区间分配器，一个操作可能被赋予从 1001~2000 之间的某个序列号，而后发生的操作则路由到另一个节点，拿到了某个 1~1000 之间的序列号，导致与因果序不一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;lamport-时间戳&#34;&gt;Lamport 时间戳&lt;/h4&gt;
&lt;p&gt;刚才所描述的三个序列号发生器可能与因果关系存在不一致，但还有一个简单的方法可以产生与因果关系一致的序列号，即 &lt;strong&gt;Lamport 时间戳&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;首先每个节点都有一个唯一的标识符，且每个节点都有一个计数器来记录各自已处理的请求总数。 Lamport 时间戳是一个键值对（计数器，节点 ID）。&lt;strong&gt;两个节点可能会有相同的计数器值，但时间戳中还包含节点 ID 信息，因此可以确保每个时间戳都是唯一的。&lt;/strong&gt; 原理如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia23.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Lamport 时间戳与物理时钟并不存在直接对应关系，但它可以保证全序。给定两个 Lamport 时间戳，计数器较大那个时间戳大，而如果计数器值正好相同，则节点 ID 越大，时间戳越大。&lt;/p&gt;
&lt;p&gt;上面的描述看起来和前面提过的奇偶发生器类似，那它是如何保证因果一致性的呢？每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器值，井在每个请求中附带该最大计数器值。&lt;strong&gt;当节点收到某个请求（或者回复）时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则它立即把自己的计数器修改为该最大值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Lamport 时间戳有时会与版本向量发生混淆。虽然存在一些相似之处，但它们的目的不同：&lt;strong&gt;版本向量用以区分两个操作是并发还是因果依赖，而 Lamport 时间戳则主要用于确保全序关系。&lt;/strong&gt; 即使 Lamport 时间戳与因果序一致，但根据其全序关系却无法区分两个操作属于并发关系，还是因果依赖关系。Lamport 时间戳优于版本向量之处在于它更加紧凑和高效。&lt;/p&gt;
&lt;h3 id=&#34;全序关系广播&#34;&gt;全序关系广播&lt;/h3&gt;
&lt;p&gt;如果程序只运行在 CPU 单核上，可以非常简单地定义出操作的全序关系，即在单核上执行的顺序。但是，在分布式系统中，让所有的节点就全序关系达成一致就面临巨大挑战。&lt;/p&gt;
&lt;p&gt;如前所述，主从复制首先确定某个节点作为主节点，然后在主节点上顺序执行操作。接下来的主要挑战在于，如何扩展系统的吞吐量使之突破单主节点的限制，以及如何处理主节点失效时的故障切换。在分布式系统中，这些问题被称为&lt;strong&gt;全序关系广播&lt;/strong&gt;或者&lt;strong&gt;原子广播&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全序关系广播通常指节点之间交换消息的某种协议。&lt;/strong&gt; 下面是个非正式的定义，它要求满足两个基本安全属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可靠发送&lt;/strong&gt;：没有消息丢失，如果消息发送到了某一个节点，则一定要发送到所有节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;严格有序&lt;/strong&gt;：消息总是以相同的顺序发送给每个节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;即使节点或网络出现了故障，全序关系广播算法的正确实现也必须保证上述两条。当然，网络中断时是不可能发送成功的，但算法要继续重试，直到最终网络修复，消息发送成功（且必须以正确的顺序发送）。&lt;/p&gt;
&lt;h4 id=&#34;使用场景-1&#34;&gt;使用场景&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据库复制&lt;/strong&gt;：如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些写请求，那么所有副本可以保持一致（或许有些滞后）。该原则也被称为状态机复制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可串行化事务&lt;/strong&gt;：如果每条消息表示一个确定性事务井且作为存储过程来执行，且每个节点都遵从相同的执行顺序，那么可以保证数据库各分区以及各副本之间的一致性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分布式锁&lt;/strong&gt;：每个获取锁的请求都作为消息附加到日志中，所有消息按照日志中的顺序依次编号。序列号还可以作为令牌，它符合单调递增要求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;复制日志、事务日志、预写日志&lt;/strong&gt;：传递消息就像追加方式更新日志。由于所有节点必须以相同的顺序发送消息，因此所有节点都可以读取日志并看到相同的消息序列。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;全序关系广播实现线性化存储&#34;&gt;全序关系广播实现线性化存储&lt;/h4&gt;
&lt;p&gt;如果有了全序关系广播，就可以在其上构建线性化的存储系统。例如，确保用户名唯一标识一个用户。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可以通过使用全序关系广播以追加日志的方式来实现线性化的原子比较-设置操作&lt;/strong&gt;，步骤如下所示：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在日志中追加一条消息，并指明想要的用户名。&lt;/li&gt;
&lt;li&gt;读取日志，将其广播给所有节点，并等待回复。&lt;/li&gt;
&lt;li&gt;检查是否有任何消息声称该用户名已被占用。 如果第一条这样的回复来自于当前节点，那么就成功获得该用户名，可以提交该获取声明（也许附加另一条消息到日志）并返回给客户端。反之，如果声称占用的第一条回复消息来自其他节点，则中止操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于日志条目以相同的顺序发送到所有节点，而如果存在多个并发写入， 则所有节点将首先决定哪个请求在先。选择第一个写请求作为获胜者，并终止其他请求，以确保所有节点同意一个写请求最终要么提交成功要么终止。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;虽然此过程可确保线性化写入，但它却无法保证线性化读取，即从异步日志更新的存储中读取数据时，可能是旧值。&lt;/strong&gt; 具体来说，这里只提供了顺序一致性，有时也称为时间线一致性，它弱于线性化保证。为了同时满足线性化读取，有以下几个方案：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以采用追加的方式把读请求排序、广播，然后各个节点获取该日志，当本节点收到消息时才执行真正的读操作。消息在日志中的位置已经决定了读取发生的时间点。&lt;/li&gt;
&lt;li&gt;如果可以用线性化的方式获取当前最新日志中消息的位置，则查询位置，等待直到该位置之前的所有条目都 经发送给你，接下来再执行读取。&lt;/li&gt;
&lt;li&gt;可以从同步更新的副本上进行读取，这样确保总是读取最新值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;线性化存储实现全序关系广播&#34;&gt;线性化存储实现全序关系广播&lt;/h4&gt;
&lt;p&gt;假设我们已经有了线性化的存储，那么如何在其上构建全序关系广播呢？&lt;strong&gt;最简单的方法是假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增-读取操作 或者原子比较-设置操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;算法思路很简单，&lt;strong&gt;对于每个要通过全序关系广播的消息，原子递增井读取该线性化的计数，然后将其作为序列号附加到消息中。接下来，将消息广播到所有节点（如果发生丢失， 重新发送），而接受者 严格按照序列化来发送回复消息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;与 Lamport 时间戳不同，通过递增线性化寄存器获得的数字不会存在任何间隙。&lt;/strong&gt; 因此，如果节点完成了消息 4 的发送，且接收到了序列化 6 的消息，那么在它对消息 6 回复之前必须等待消息 5。而 Lamport 时间戳则不是这样，而这也是区别全序关系广播与基于时间戳排序的关键。&lt;/p&gt;
&lt;h2 id=&#34;分布式事务与共识&#34;&gt;分布式事务与共识&lt;/h2&gt;
&lt;p&gt;有很多重要的场景都需要集群节点达成某种一致，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;主节点选举&lt;/strong&gt;：对于主从复制的数据库，所有节点需要就谁来充当主节点达成一致。如果由于网络故障原因出现节点之间无法通信，就很容易出现争议。此时，共识对于避免错误的故障切换非常重要，后者会导致两个节点都自认为是主节点即脑裂。如果集群中存在两个这样的主节点，每个都在接受写请求，最终会导致数据产生分歧、不一致甚至数据丢失。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;原子事务提交&lt;/strong&gt;：对于支持跨节点或跨分区事务的数据库，会面临这样的问题：某个事务可能在一些节点上执行成功，但在其他节点却不幸发生了失败。为了维护事务的原子性，所有节点必须对事务的结果达成一致：要么全部成功提交，要么中止/回滚。这个共识的例子被称为原子提交问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;原子提交与两阶段提交&#34;&gt;原子提交与两阶段提交&lt;/h3&gt;
&lt;h4 id=&#34;单节点原子提交&#34;&gt;单节点原子提交&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;对于在单个数据库节点上执行的事务，原子性通常由存储引擎来负责。&lt;/strong&gt; 当客户端请求数据库节点提交事务时，数据库首先使事务的写入持久化（通常保存在预写日志中），然后把提交记录追加写入到磁盘的日志文件中。如果数据库在该过程中间发生了崩溃，那么当节点重启后，事务可从日志中恢复：如果在崩溃之前提交记录已成功写入磁盘，则认为事务己安全提交；否则，回滚该事务的所有写入。&lt;/p&gt;
&lt;p&gt;因此，在单节点上，&lt;strong&gt;事务提交非常依赖于数据持久写入磁盘的顺序关系：先写入数据，然后再提交记录&lt;/strong&gt;。 &lt;strong&gt;事务提交（或中止）的关键点在于磁盘完成日志记录的时刻&lt;/strong&gt;：在完成日志记录写之前如果发生了崩溃，则事务需要中止；如果在日志写入完成之后，即使发生崩溃，事务也会被安全提交。这就是在单一设备上上实现原子提交的核心思路。&lt;/p&gt;
&lt;h4 id=&#34;两阶段提交&#34;&gt;两阶段提交&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;两阶段提交（two-phase commit，2PC）&lt;/strong&gt; 是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么 部提交，要么全部中止。&lt;/p&gt;
&lt;p&gt;2PC 中的提交/中止过程分为两个阶段（因此而得名），而不是单节点事务中的单个提交请求。2PC 的基本流程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia24.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;2PC 引入了单节点事务所没有的一个新组件——&lt;strong&gt;协调者（又称为事务管理器）&lt;/strong&gt;。协调者通常实现为共享库，运行在请求事务相同进程中（也可以是单独的进程或服务）。&lt;/p&gt;
&lt;p&gt;通常，2PC 事务从应用程序在多个数据库节点上执行数据读/写开始。我们将这些数据库节点称为事务中的参与者。当应用程序准备提交事务时，协调者开始阶段 1：&lt;strong&gt;发送一个准备请求到所有节点，询问他们是否可以提交。协调者然后跟踪参与者的回应&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果所有参与者回答是，表示他们已准备好提交，那么协调者接下来在阶段 2 会发出提交请求，提交开始实际执行。&lt;/li&gt;
&lt;li&gt;如果有任何参与者回答否，则协调者在阶段 2 中向所有节点发送放弃请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;系统承诺&#34;&gt;系统承诺&lt;/h5&gt;
&lt;p&gt;该协议有两个关键的不归路：首先，当参与者投票是时，它做出了肯定提交的承诺（尽管还取决于其他的参与者的投票，协调者才能做出最后决定）。其次，协调者做出了提交（或者放弃）的决定，这个决定也是不可撤销。正是这两个承诺确保了 2PC 的原子性（而单节点原子提交其实是将两个事件合并，写入事务日志即提交） 。&lt;/p&gt;
&lt;h5 id=&#34;协调者故障&#34;&gt;协调者故障&lt;/h5&gt;
&lt;blockquote&gt;
&lt;p&gt;如果协调者本身发生了故障，那么此时该怎么处理呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2PC 能够顺利完成的唯一方法是&lt;strong&gt;等待协调者恢复&lt;/strong&gt;。这就是为什么协调者必须在向参与者发送提交（或中止）请求之前要将决定写入磁盘的事务日志，协调者恢复之后通过读取事务日志来确定所有未决的事务状态。如果在协调 日志中没有完成提交记录就会中止。 此时 2PC 的提交点现在归结为协调者在常规单节点上的原子提交。&lt;/p&gt;
&lt;h4 id=&#34;三阶段提交&#34;&gt;三阶段提交&lt;/h4&gt;
&lt;p&gt;作为 2PC 的替代方案，目前也有三阶段提交算法。然而，&lt;strong&gt;3PC 假定一个有界的网络延迟和节点在规定时间内响应&lt;/strong&gt;。考虑到目前大多数实际场景中存在无限网络延迟和进程暂停的情况，&lt;strong&gt;因此它无法保证原子性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常，非阻塞原子提交依赖于一个完美的故障检测器，即有一个非常可靠的机制可以判断出节点是否已经崩溃。&lt;strong&gt;在无限延迟的网络环境中，超时机制并不是可靠的故障检测器，因为即使节点正常，请求也可能由于网络问题而最终超时。&lt;/strong&gt; 正是由于这样的原因，尽管大家已经意识到上述协调者潜在的问题，但还在普遍使用 2PC。&lt;/p&gt;
&lt;h3 id=&#34;实际中的分布式事务&#34;&gt;实际中的分布式事务&lt;/h3&gt;
&lt;p&gt;目前有两种截然不同的分布式事务概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据库内部的分布式事务&lt;/strong&gt;：某些分布式数据库（例如那些标配支持复制和分区的数据库）支持跨数据库节点 的内部事务。例如，VoltDB 和 MySQL Cluster 的 NDB 存储引擎就支持这样的内部分布式事务。此时，所有参与节点都运行着相同的数据库软件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异构分布式事务&lt;/strong&gt;：在异构分布式事务中，存在两种或两种以上不同的参与者实现技术。例如来自不同供应商的数据库，甚至是非数据库系统（如消息中间件）。即使是完全不同的系统，跨系统的分布式事务也必须确保原子提交。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;exactly-once消息处理&#34;&gt;Exactly-Once消息处理&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;异构的分布式事务旨在无缝集成多种不同的系统。&lt;strong&gt;例如，当且仅当数据库中处理消息事务成功提交，消息队列才会标记该消息已处理完毕。这个过程是通过&lt;/strong&gt;自动提交消息&lt;/strong&gt;和&lt;strong&gt;数据库写入&lt;/strong&gt;来实现的。即使消息系统和数据库两种不同的技术运行在不同的节点上，采用分布式事务也能达到上述目标。&lt;/p&gt;
&lt;p&gt;如果消息发送或数据库事务任何一个发生失败，则两者必须中止，消息队列可以在稍后再次重传消息。因此，通过自动提交消息和消息处理的结果，&lt;strong&gt;可以确保消息可以有效处理有且仅有一次&lt;/strong&gt;（成功之前有可能需要重试）。而如果事务最后发生终止，则放弃所有部分完成的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需要指出，只有在所有受影响的系统都使用相同的原子提交协议的前提下，这种分布式事务才是可行。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;xa事务&#34;&gt;XA事务&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;X/Open XA（eXtended Architecture，XA）&lt;/strong&gt; 是异构环境下实施两阶段提交的一个工业标准，于 1991 年推出并得到广泛推广。目前，许多传统关系数据库（包括 PostgreSQL、MySQL、DB2、SQL Server、Oracle）和消息队列（包括 ActiveMQ、HornetQ、MSMQ、IBM MQ）都支持 XA。&lt;/p&gt;
&lt;p&gt;XA 并不是一个网络协议，而是一个与事务协调者进行通信的 API（它也支持其他语言的 API 绑定）。XA 假定应用程序通过网络或客户端的库函数与参与者（包括数据库、消息服务）节点进行通信。如果驱动程序支持 XA ，意味着应用可以调用 XA API 来确定操作是否是异构分布式事务的一部分。如果是，则发送必要的信息给数据库服务器。它还支持回调，这样协调者可以通过回调函数来通知所有参与者执行准备或者提交（或者中止）。&lt;/p&gt;
&lt;h4 id=&#34;分布式事务的限制&#34;&gt;分布式事务的限制&lt;/h4&gt;
&lt;p&gt;XA 事务解决了多个参与者之间如何达成一致这样一个非常现实而重要的问题，但它也引入了不少操作方面的限制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果协调者不支持数据复制，而是在单节点上运行，那么它就是整个系统的单点故障。而现实情况是，有许多协调者的实现默认情况下井非高可用，或者只支持最基本的复制。&lt;/li&gt;
&lt;li&gt;许多服务器端应用程序都倾向于无状态模式（因为更受 HTTP 青睐），而所有的持久状态都保存在数据库中，这样应用服务器可以轻松地添加或删除实例。但是，当协调者就是应用服务器的一部分时，部署方式就发生了根本的变化。突然间，协调者的日志成为可靠系统的重要组成部分，它要求与数据库本身一样重要（需要协调者日志恢复那些有疑问的事务）。这样的应用服务器已经不再是无状态。&lt;/li&gt;
&lt;li&gt;由于 XA 需要与各种数据系统保持兼容，所以它最终其实是多系统可兼容的最低标准。例如，它无法深入检测不同系统之间的死锁条件（因为这就将需要另一个标准化协议，使得多个系统交换事务所等待的锁信息），而且不适用于 SSI ，后者要求一个复杂的协议来识别不同系统间的写冲突。&lt;/li&gt;
&lt;li&gt;对于数据库内部的分布式事务（而不是 XA），限制则少很多，例如 SSI 的分布式版本是可行的 。然而 2PC 要成功提交事务还是存在潜在的限制，它要求必须所有参与者都投票赞成， 如果有任何部分发生故障，整个事务只能失败。所以分布式事务有扩大事务失败的风险，这与我们构建容错系统的目标有些背道而驰。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;支持容错的共识&#34;&gt;支持容错的共识&lt;/h3&gt;
&lt;p&gt;共识问题通常形式化描述如下：&lt;strong&gt;一个或多个节点可以提议某些值，由共识算法来决定最终值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共识算法必须满足以下性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;协商一致性&lt;/strong&gt;：所有的节点都接受相同的决议。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;诚实性&lt;/strong&gt;：所有节点不能反悔，即对一项提议不能有两次决定。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合法性&lt;/strong&gt;：如果决定了值 v，则 v 一定是由某个节点所提议的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可终止性&lt;/strong&gt;：节点如果不崩溃则最终一定可以达成决议。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;协商一致性和诚实性属性定义了共识的核心思想：决定一致的结果，一旦决定，就不能改变。合法性属性主要是为了排除一些无意义的方案。可终止性则引入了容错的思想。&lt;/strong&gt; 它重点强调一个共识算法不能原地空转，永远不做事情，换句话说，它必须取得实质性进展。即使某些节点出现了故障，其他节点也必须最终做出决定。&lt;/p&gt;
&lt;p&gt;可终止性属于一种活性，而另外三种则属于安全性方面的属性。&lt;/p&gt;
&lt;h4 id=&#34;共识算法与全序广播&#34;&gt;共识算法与全序广播&lt;/h4&gt;
&lt;p&gt;最著名的容错式共识算法包括 VSR、Paxos、Raft、Zab。这些算法大部分其实并不是直接使用上述的形式化模型（提议井决定某个值，同时满足上面四个属性）。相反，他们是决定了一系列值，然后采用全序关系广播算法。&lt;/p&gt;
&lt;p&gt;全序关系广播的要点是，&lt;strong&gt;消息按照相同的顺序发送到所有节点，有且只有一次&lt;/strong&gt;。如果仔细想想，这其实相当于进行了多轮的共识过程：在每一轮，节点提出他们接下来想要发送的消息，然后决定下一个消息的全局顺序。&lt;/p&gt;
&lt;p&gt;所以，全序关系广播相当于持续的多轮共识（每一轮共识的决定对应于一条消息）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于协商一致性，所有节点决定以相同的顺序发送相同的消息。&lt;/li&gt;
&lt;li&gt;由于诚实性，消息不能重复。&lt;/li&gt;
&lt;li&gt;由于合法性，消息不会被破坏，也不是凭空捏造的。&lt;/li&gt;
&lt;li&gt;由于可终止性，消息不会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;共识的局限性&#34;&gt;共识的局限性&lt;/h4&gt;
&lt;p&gt;共识算法对于分布式系统来说是一个巨大的突破：它为其他充满不确定性的系统带来了基础的安全属性（一致性，完整性和合法性），然而它们还能保持容错（只要多数节点正常工作且可达，就能取得进展）。它们提供了全序广播，因此它们也可以以一种容错的方式实现线性一致的原子操作。&lt;/p&gt;
&lt;p&gt;虽然有着上面这些好处，但这些好处的背后仍然存在一些代价：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;在达成一致性决议之前，节点投票的过程是一个同步复制过程。&lt;/strong&gt; 而数据库通常配置为异步复制，存在某些已提交的数据在故障切换时丢失的风险。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共识体系需要严格的多数节点才能运行。&lt;/strong&gt; 如果由于网络故障切断了节点之间的连接，则只有多数节点所在的分区可以继续工作，剩下的少数节点分区则处于事实上的停顿状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多数共识算法假定一组固定参与投票的节点集，这意味着不能动态添加或删除节点。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共识系统通常依靠超时机制来检测节点失效。&lt;/strong&gt; 在网络延迟高度不确定的环境中，特别是那些跨区域分布的系统，经常由于网络延迟的原因，导致节点错误地认为主节点发生了故障。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共识算法往往对网络问题特别敏感。&lt;/strong&gt; 例如，如果整个网络中存在一条网络连接持续不可靠， Raft 会进入一种奇怪的状态：它不断在两个节点之间反复切换主节点，当前主节点不断被赶下台，这最导致系统根本无法安心提供服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;成员与协调服务&#34;&gt;成员与协调服务&lt;/h3&gt;
&lt;p&gt;ZooKeeper 或 etcd 这样的项目通常被描述为 “分布式键值存储” 或 “协调与配置服务”。它们通常采用容错的全序广播算法在所有节点上复制这些数据从而实现高可靠。不仅如此，Zookeepr 还提供了以下这些特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;线性化的原子操作&lt;/strong&gt;：使用原子 CAS 操作可以实现锁：如果多个节点同时尝试执行相同的操作，只有一个节点会成功。共识协议保证了操作的原子性和线性一致性，即使节点发生故障或网络在任意时刻中断。分布式锁通常以租约（lease）的形式实现，租约有一个到期时间，以便在客户端失效的情况下最终能被释放。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;操作全序&lt;/strong&gt;：当某个资源受到锁或租约的保护时，你需要一个防护令牌来防止客户端在进程暂停的情况下彼此冲突。防护令牌是每次锁被获取时单调增加的数字。ZooKeeper 通过全序化所有操作来提供这个功能，它为每个操作提供一个单调递增的事务 ID（&lt;code&gt;zxid&lt;/code&gt;）和版本号（&lt;code&gt;cversion&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;故障检测&lt;/strong&gt;：客户端在 ZooKeeper 服务器上维护一个长期会话，客户端和服务器周期性地交换心跳包来检查节点是否还活着。即使连接暂时中断，或者 ZooKeeper 节点失效，会话仍保持在活跃状态。但如果心跳停止的持续时间超出会话超时，ZooKeeper 会宣告该会话已死亡。当会话超时时（ZooKeeper 称这些节点为临时节点，即 ephemeral nodes），会话持有的任何锁都可以配置为自动释放。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更改通知&lt;/strong&gt;：客户端不仅可以读取其他客户端创建的锁和值，还可以监听它们的变更。因此，客户端可以知道另一个客户端何时加入集群（基于新客户端写入 ZooKeeper 的值），或发生故障（因其会话超时，而其临时节点消失）。通过订阅通知，客户端不用再通过频繁轮询的方式来找出变更。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;节点任务分配&#34;&gt;节点任务分配&lt;/h4&gt;
&lt;p&gt;ZooKeeper 和 Chubby 系统非常适合节点任务分配这一场景，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果系统有多个流程或服务的实例，并且需求其中的一个实例充当主节点；而如果主节点失效，由其他某个节点来接管。（例如主从复制数据库、作业调度系统等）&lt;/li&gt;
&lt;li&gt;对于一些分区资源（可以是数据库，消息流，文件存储，分布式 actor system 等），需要决定将哪个分区分配给哪个节点。当有新节点加入集群时， 需要将某些现有分区从当前节点迁移到新节点， 从而实现负载动态平衡。 当节点移除或失败时，其他节点还需要接管失败节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述场景中的任务，可以借助 ZooKeeper 中的原子操作，ephemeral nodes 和通知机制来实现。&lt;/p&gt;
&lt;h4 id=&#34;服务发现&#34;&gt;服务发现&lt;/h4&gt;
&lt;p&gt;ZooKeeper、Etcd、Consul 还经常用于服务发现。例如需要某项服务时，应该连接到哪个 IP 地址等。在典型的云环境中，虚拟机可能会起起停停，这种动态变化的节点无法提前知道服务节点的 IP 地址，因此，可以这样配置服务，每当节点启动时将其网络端口信息、向 ZooKeeper等服务注册，然后其他人只需向 ZooKeeper 的注册表中询问即可。&lt;/p&gt;
&lt;h4 id=&#34;成员服务&#34;&gt;成员服务&lt;/h4&gt;
&lt;p&gt;ZooKeeper 等还可以看作是成员服务范畴的一部分。&lt;strong&gt;成员服务用来确定当前哪些节点处于活动状态并属于集群的有效成员。&lt;/strong&gt; 由于无限的网络延迟，无法可靠地检测一个节点究竟是否发生了故障。但是，&lt;strong&gt;可以将故障检测与共识绑定在一起，让所有节点就节点的存活达成一致意见。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里依然存在发生误判的可能性，&lt;strong&gt;即节点其实处于活动状态、却被错误地宣判为故障。&lt;/strong&gt; 即使这样，系统就成员资格问题的决定是全体一致的，这是最重要的。例如，选举主节点的方式可能是简单地投票选择编号最小的节点， 一旦节点对于当前包含哪些成员出现了不同意见，那么共识过程就无法继续。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（八）：分布式系统的挑战</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AB%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%91%E6%88%98/</link>
        <pubDate>Sun, 10 Jul 2022 07:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AB%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%91%E6%88%98/</guid>
        <description>&lt;h1 id=&#34;分布式系统的挑战&#34;&gt;分布式系统的挑战&lt;/h1&gt;
&lt;h2 id=&#34;故障与部分失效&#34;&gt;故障与部分失效&lt;/h2&gt;
&lt;p&gt;在分布式系统中，可能会出现&lt;strong&gt;系统的一部分工作正常，但其他某些部分出现难以预测的故障&lt;/strong&gt;，我们称之为&lt;strong&gt;部分失效&lt;/strong&gt;。问题的难点就在于这种部分失效是不确定的:如果涉及多个节点和网络，几乎肯定会碰到有时网络正常，有时则莫名的失败。&lt;/p&gt;
&lt;p&gt;正是由于这种不确定性和部分失效大大提高了分布式系统的复杂性。要使分布式系统可靠工作，就必然面临部分失效，这就需要依靠软件系统来提供容错机制。换句话说，&lt;strong&gt;我们需要在不可靠的组件之上构建可靠的系统&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;不可靠的网络&#34;&gt;不可靠的网络&lt;/h2&gt;
&lt;p&gt;互联网和数据中心中的大多数内部网络都是&lt;strong&gt;异步分组网络（asynchronous packet networks）&lt;/strong&gt;。在这种网络中，一个节点可以向另一个节点发送一个消息，但是网络不能保证它什么时候到达，甚至是能否到达。发送之后等待响应过程中，有很多事情可能会出错：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;请求可能已经丢失&lt;/strong&gt;（可能有人拔掉了网线）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;请求可能正在排队，稍后将交付&lt;/strong&gt;（也许网络或接收方过载）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;远程节点可能已经失效&lt;/strong&gt;（比如是崩溃或关机）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;远程节点可能暂时停止了响应&lt;/strong&gt;（遇到长时间的垃圾回收）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;远程节点可能已经处理了请求，但是网络上的响应已经丢失&lt;/strong&gt;（可能是网络交换机配置错误）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;远程节点可能已经处理了请求，但是响应被延迟处理&lt;/strong&gt;（可能是网络或者你自己的机器过载）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;发送者甚至不清楚数据包是否完成了发送，只能选择让接收者来回复响应消息，但回复也有可能丟失或延迟。这些问题在一个异步网络中无法明确区分，发送者拥有的唯一信息是，尚未收到响应，但却无法判定具体原因。&lt;/p&gt;
&lt;p&gt;处理这个问题通常采用&lt;strong&gt;超时机制&lt;/strong&gt;，&lt;strong&gt;即在等待一段时间之后，如果仍然没有收到回复则选择放弃，并且认为响应不会到达。&lt;/strong&gt; 但是，即使判定超时，仍然并不清楚远程节点是否收到了请求（一种情况，请求仍然在某个地方排队，即使发送者放弃了，但最终请求会发送到接收者)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那如何确定这个超时时间呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;较长的超时值意味着更长时间的等待，才能宣告节点失效。而在此期间， 用户只能等待或者拿到错误信息。&lt;/li&gt;
&lt;li&gt;较短的超时设置可以帮助快速检测故障，但可能会出现误判，例如实际上节点只是出现暂时的性能波动(由于节点或网络上的高负载峰值，结果却被错误地宣布为失效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;这并没有一个标准的答案，而需要结合具体的业务场景来进行分析。&lt;/strong&gt; 通常通过实验的方式来一步步设置超时。先在多台机器上，多次测量网络往返时间，以确定延迟的大概范围，然后结合应用特点，在故障检测与过早超时风险之间选择一个合适的中间值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;超时设置并不是一个不变的常量，而是需要持续测量响应时间及其变化，然后根据最新的响应时间分布来自动调整。&lt;/strong&gt; 可以用 Phi Accrual 故障检测器完成，该检测器目前已在 Akka 和 Cassandra 中使用。TCP的重传超时也采用了类似的机制。&lt;/p&gt;
&lt;h2 id=&#34;不可靠的时钟&#34;&gt;不可靠的时钟&lt;/h2&gt;
&lt;p&gt;在分布式系统中， 时间总是件棘手的问题，由于跨节点通信不可能即时完成，消息由网络从一台机器到另一台机器总是需要花费时间。收到消息的时间应该晚于发送的时间，但是由于网络的不确定延迟，精确测量面临着很多挑战。这些情况使得多节点通信时很难确定事情发生的先后顺序。&lt;/p&gt;
&lt;p&gt;同时，网络上的每台机器都有自己的时钟硬件设备。这些设备并非绝对准确，即每台机器都维护自己本地的时间版本，可能比其他机器稍快或更慢。&lt;/p&gt;
&lt;h3 id=&#34;时钟&#34;&gt;时钟&lt;/h3&gt;
&lt;p&gt;现代计算机内部至少有两种不同的时钟，一个是&lt;strong&gt;日历时钟（time-of-day clock）&lt;/strong&gt;， 另一个是&lt;strong&gt;单调时钟（monotonic clock）&lt;/strong&gt;。虽然它们都可以衡量时间，但要仔细区分二者，本质上他们是服务于不同的目的。&lt;/p&gt;
&lt;h4 id=&#34;日历时钟&#34;&gt;日历时钟&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;日历时钟会根据某个日历返回当前的日期与时间。&lt;/strong&gt; 例如，Linux 上的 &lt;code&gt;clock_gettime(CLOCK_REALTIME)&lt;/code&gt; 会返回自纪元 1970 年 1 月 1 日（ UTC ）以来的秒数和毫秒数，不含闺秒。而有些系统则使用其他日期作为参考点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;日历时钟通常与 NTP 服务器同步，这意味着来自一台机器的时间戳（理想情况下）与另一台机器上的时间戳相同&lt;/strong&gt;。但是，如果本地时钟远远快于 NTP 服务器，则它可能会被强制重置，跳回到先前的某个时间点。这种跳跃经常忽略闰秒 ，导致其不太适合测量时间间隔。可以在一定程度上同步机器之间的时钟，最常用的方法也是&lt;strong&gt;网络时间协议 NTP （Network Time Protocl）&lt;/strong&gt;，它可以根据 组专门的时间服务器来调整本地时间，时间服务器则从精确更高的时间源获取高精度时间。&lt;/p&gt;
&lt;h4 id=&#34;单调时钟&#34;&gt;单调时钟&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;单调时钟适用于测量持续时间（时间间隔），例如超时或服务的响应时间&lt;/strong&gt;。Linux 上的 &lt;code&gt;clock_gettime(CLOCK_MONOTONIC)&lt;/code&gt; 返回的即是单调时钟。单调时钟的名字来源于它们保证总是向前走（日历时钟会出现的回拨现象）。&lt;/p&gt;
&lt;p&gt;可以在一个时间点读取单调时钟的值，完成某项工作，然后再次检查时钟。时钟值之间的差值即两次检查之间的时间间隔。==注意，单调时钟的绝对值井没有任何意义，它可能是电脑启动以后经历的纳秒数或者其他含义。因此比较不同节点上的单调时钟值毫无意义，它们没有任何相同的基准==。&lt;/p&gt;
&lt;p&gt;在分布式系统中，可以采用单调时钟测量一段任务的持续时间（例如超时 ），它不假定节点间有任何的时钟同步，且可以容忍轻微测量误差。&lt;/p&gt;
&lt;h3 id=&#34;进程暂停&#34;&gt;进程暂停&lt;/h3&gt;
&lt;p&gt;在分布式环境中，&lt;strong&gt;进程暂停&lt;/strong&gt;有时会引起意想不到的时钟问题。&lt;/p&gt;
&lt;p&gt;假如有这样一个场景，主节点从其他节点获得一个租约，类似一个带有超时的锁。为了维持主节点的身份，节点必须在到期之前定期去更新租约 。如果节点发生了故障，则续约失败，这样另一个节点到期之后就可以接管。代码逻辑如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;request&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;getIncomingRequest&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;c1&#34;&gt;// 确保租约还剩下至少10秒
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lease&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expiryTimeMillis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;lease&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lease&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;renew&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lease&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;isValid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;process&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;上述代码依赖于同步的时钟，即租约到期时间由另一台机器所设置，并和本地时钟进行比较。如果时钟之间有超过几秒的差异，这段代码会出现些奇怪的事情。&lt;/p&gt;
&lt;p&gt;即使我们改为仅使用本地单调时钟，还有另一个问题：代码假定时间检查点 &lt;code&gt;System.currentTimeMillis()&lt;/code&gt; 与请求处理 &lt;code&gt;process(request)&lt;/code&gt; 间隔很短，通常代码运行足够快，所以设置 10 秒的缓冲区来确保在请求处理过程中租约不会过期。&lt;/p&gt;
&lt;p&gt;如果程序执行中出现了某些意外的暂停呢？假设线程在 &lt;code&gt;lease.isValid()&lt;/code&gt; 消耗了了整 15 秒。那么当开始处理请求时，租约已经过期，而另一个节点已经接管了主节点。可惜我们无告有效通知线程暂停了这么长时间了，后续代码也不会注意到租约已经到期，除非运行到下一个循环迭代。不过，到那个时候它已经做了不安全的请求处理。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那什么原因会带来这么长时间的暂停呢？可能会存在以下事件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;许多编程语言都有垃圾收集器（ GC ），有时运行期间会暂停所有正在运行的线程。&lt;/li&gt;
&lt;li&gt;在虚拟化环境中，可能会暂停虚拟机（暂停所有执行进程并将内存状态保存到磁盘）然后继续（从内存中加载数据然后继续执行）。&lt;/li&gt;
&lt;li&gt;运行在终端用户设备时，执行也可能发生暂停。例如用户关机脑或休眠。&lt;/li&gt;
&lt;li&gt;当操作系统执行线程上下文切换时，或者虚拟机管理程序切换到另一个虚拟机时，正在运行的线程可能会在代码的任意位置被暂停。&lt;/li&gt;
&lt;li&gt;如果应用程序执行同步磁盘访问，则线程可能暂停，直到缓慢的磁盘 I/O 操作完成。&lt;/li&gt;
&lt;li&gt;如果操作系统配置了基于磁盘的内存交换分区，内存访问可能触发缺页中断，进而需要从磁盘中加载内存页。 当 I/O 进行时线程为暂停。&lt;/li&gt;
&lt;li&gt;发送 SIGSTOP 信号来暂停 UNIX 进程，例如通过在 shell 中按下 Ctrl+Z。 这个信号立即阻止进程继续执行更多的 CPU 周期，直到 SIGCONT 恢复为止，此时它才会继续运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有这些事件都可以随时抢占正在运行的线程，并在稍后的时间恢复运行，而线程甚至不会注意到这一点。这个问题类似于在单个机器上使多线程代码线程安全，&lt;strong&gt;因此你不能对时序做任何假设，因为随时可能发生上下文切换，或者出现并行运行&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以分布式系统中的每个节点都必须假定，&lt;strong&gt;执行过程中的任何时刻都可能被暂停相当长一段时间，即使是运行在某个函数中间 。&lt;/strong&gt; 暂停期间，整个集群的其他部分都在照常运行，甚至会一致将暂停的节点宣告为故障节点。最终，暂停的节点可能会回来继续运行，除非再次检查时钟，否则它对刚刚过去的暂停一无所知。&lt;/p&gt;
&lt;h2 id=&#34;知识真相与谎言&#34;&gt;知识、真相与谎言&lt;/h2&gt;
&lt;h3 id=&#34;真相由多数决定&#34;&gt;真相由多数决定&lt;/h3&gt;
&lt;p&gt;假定在一个发生了非对称故障的网络环境中，即某节点能够收到发送给它的消息，但是该节点发出的所有消息要么被丢弃，要么被推迟发送。&lt;strong&gt;即使该节点本身运行良好，可以接收来自其他节点的请求，但其他节点却无法顺利收到响应。当消息超时之后，由于都收不到回复，其他节点就会一致声明上述节点发生失效。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;综上所述，节点不能根据自己的信息来判断自身的状态。分布式系统不能完全依赖单个节点，因为节点可能随时失效，也可能暂停或者假死，甚至最终无法恢复。目前许多分布式算法都依赖于&lt;strong&gt;法定人数&lt;/strong&gt;，&lt;strong&gt;即在节点之间进行投票。任何决策都需要来自多个节点的最小投票数，以减少对于某个特定节点的依赖。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最常见的法定人数是取系统节点半数以上&lt;/strong&gt;。如果某些节点发生故障，quorum 机制可以使系统继续工作（对于三个节点的系统，可以容忍一个节点失效）。由于系统只可能存在一个多数，绝不会有两个多数在同时做出相互冲突的决定，因此系统的决议是可靠的 &lt;strong&gt;（防止脑裂）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;拜占庭故障&#34;&gt;拜占庭故障&lt;/h3&gt;
&lt;p&gt;如果节点存在撒谎的情况（即故意发送错误的或破坏性的响应），那么分布式系统处理的难度就上了一个台阶。例如，节点明明没有收到某条消息，但却对外声称收到了。这种行为称为&lt;strong&gt;拜占庭故障&lt;/strong&gt;，在这样不信任的环境中需要达成共识的问题也被称为&lt;strong&gt;拜占庭将军问题&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;拜占庭将军问题&#34;&gt;拜占庭将军问题&lt;/h3&gt;
&lt;p&gt;拜占庭将军问题是所谓“两将军问题”的更抽象标识，后者假定有两名将军需要就战斗计划达成一致。由于他们在两个不同的地点建立了营地， 中间只能通过信使进行沟通，而信使在传递消息时可能会出现延迟或丢失（就像网络中的信息包一样）。&lt;/p&gt;
&lt;p&gt;而在拜占庭版本中，有 n 位将军需要达成共识，并且其中存在一些叛徒试图阻挠共识的达成，即使大多数的将军都是忠诚的，发出了真实的信息，但是叛徒则试图通过发送虚假或不真实的信息来欺骗和混淆他人（同时努力隐藏自己）。而且大家事先并不知道叛徒是谁。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击、干扰网络，但仍可继续正常运行，那么我们称之为&lt;strong&gt;拜占庭式容错系统&lt;/strong&gt;。这种担忧在某些场景下是合理的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在航空航天领域，计算机内存或 CPU 寄存器中的数据可能会被辐射而发生故障，导致以不可预知的方式响应其他节点。这种情况下如果将系统下线，代价将异常昂贵（例如，可能出现飞机撞毁或致使火箭与国际空间站相撞等），飞行控制系统必须做到容忍拜占庭故障 。&lt;/li&gt;
&lt;li&gt;在有多个参与者的系统中，某些参与者可能会作弊或者欺骗他人。这时节点不能完全相信另一个节点所发送的消息，它可能就是恶意的。例如，像比特币和其他区块链一样的点对点网络就是让互不信任的当事方就某项交易达成一致，且不依赖于集中的机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大多数拜占庭容错算法要求系统超过三分之二的节点功能正常，例如有四个节点，则最多允许一台发生故障）。要采用这类算法对付 bug ，必须有四种不同的软件实现，然后希望该 bug 只出现在四个实现中的一个。但这并不现实，通常如果攻击者可以入侵一个节点，则很可能会攻陷几乎所有节点（由于运行相同的软件）。因此，传统的安全措施如认证、访问控制、加密、防火墙等仍是防范攻击的主要保护机制。&lt;/p&gt;
&lt;h3 id=&#34;理论系统模型与现实&#34;&gt;理论系统模型与现实&lt;/h3&gt;
&lt;p&gt;目前分布式系统方面已有许多不错的具体算法（如共识算法 Raft、Paxos 等），而算法的实现不能过分依赖特定的硬件和软件配置。这就要求我们需要对预期的系统错误进行形式化描述。我们通过定义一些系统模型来形式化描述算法的前提条件。&lt;/p&gt;
&lt;p&gt;关于&lt;strong&gt;计时方面&lt;/strong&gt;有三种常见的系统模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;同步模型&lt;/strong&gt;：假设网络延迟、进程暂停和和时钟误差都是受限的。这并不意味着完全同步的时钟或网络延迟为零。这只意味着你清楚了解网络延迟、进程暂停和时钟漂移将永远不会超过某个固定的上限。大多数实际系统的现实模型并不是同步模型，因为无限延迟和暂停确实会发生。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;部分同步模型&lt;/strong&gt;：意味着一个系统在大多数情况下像一个同步系统一样运行，但有时候会超出网络延迟、进程暂停和时钟漂移的界限。这是一个比较现实的模型，大多数情况下，网络和进程表现良好（否则无法持续提供服务），但是我们必须承认，在任何时刻都存在时序假设偶然被破坏的事实。而一旦发生这种情况，网络延迟、暂停和时钟错误可能会变得相当大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异步模型&lt;/strong&gt;：在这个模型中，一个算法不允许对时序做任何假设——事实上它甚至没有时钟（所以它不能使用超时）。一些算法被设计为可用于异步模型，但非常受限。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了时机之外，我们还需要考虑&lt;strong&gt;节点失效&lt;/strong&gt;。有以下三种最常见的节点失效系统模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;崩溃-中止&lt;/strong&gt;：在崩溃-中止模型中，算法假设一个节点只能以一种方式发生故障，即遭遇系统&lt;/p&gt;
&lt;p&gt;崩溃。这意味着节点可能在任何时候突然停止响应，且该节点以后永远消失，无法恢复。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;崩溃-恢复&lt;/strong&gt;：节点可能会在任何时候发生崩溃，且可能会在一段时间之后得到恢复并再次响应。在崩溃－恢复模型中，节点上持久性存储的数据会在崩溃之后得以保存，而内存中状态可能会丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;拜占庭（任意）故障&lt;/strong&gt;：节点可以做任何事情，包括试图戏弄和欺骗其他节点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于真实系统的建模，最普遍的组合是&lt;strong&gt;崩溃-恢复模型结合部分同步模型&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;为了定义算法的正确性，我们可以描述它的一些属性信息。如果针对某个系统模型的算法在各种情况下都能满足定义好的属性要求，那么我们称这个算法是正确的。而其中最重要的两种属性是&lt;strong&gt;安全性&lt;/strong&gt;与&lt;strong&gt;活性&lt;/strong&gt;。安全性通常可以理解为&lt;strong&gt;没有发生意外&lt;/strong&gt;，而&lt;strong&gt;活性则类似预期的事情最终一定会发生&lt;/strong&gt;（如最终一致性）。&lt;/p&gt;
&lt;p&gt;对于分布式算法，要求在所有可能的系统模型下，都&lt;strong&gt;必须符合安全属性&lt;/strong&gt;。也就是说，&lt;strong&gt;即使所有节点都发生崩溃，或者整个网络中断，算法确保不会返回错误的结果。&lt;/strong&gt; 而对于活性，则存在一些必要条件。例如，&lt;strong&gt;只有在多数节点没有崩溃，以及网络最终可以恢复的前提下，我们才能保证最终可以收到响应。&lt;/strong&gt; 部分同步模型的定义即要求任何网络中断只会持续一段有限的时间，然后得到了修复，系统最终返回到同步的一致状态。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（七）：事务</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%83%E4%BA%8B%E5%8A%A1/</link>
        <pubDate>Sun, 10 Jul 2022 06:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%83%E4%BA%8B%E5%8A%A1/</guid>
        <description>&lt;h1 id=&#34;事务&#34;&gt;事务&lt;/h1&gt;
&lt;h2 id=&#34;深入理解事务&#34;&gt;深入理解事务&lt;/h2&gt;
&lt;h3 id=&#34;acid&#34;&gt;ACID&lt;/h3&gt;
&lt;p&gt;事务所提供的安全保证即大家所熟知的 &lt;strong&gt;ACID&lt;/strong&gt; ，分别代表&lt;strong&gt;原子性（Atomicity）&lt;/strong&gt;， &lt;strong&gt;一致性（Consistency）&lt;/strong&gt;，&lt;strong&gt;隔离性（Isolation）&lt;strong&gt;与&lt;/strong&gt;持久性（Durability）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而不符合 ACID 标准的系统有时被称为 &lt;strong&gt;BASE&lt;/strong&gt; ，取另外几个特性的首字母，即&lt;strong&gt;基本可用性（Basically Available）&lt;/strong&gt;，&lt;strong&gt;软状态（Soft State）&lt;/strong&gt; 和&lt;strong&gt;最终一致性（ Eventual consistency）&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;原子性&#34;&gt;原子性&lt;/h4&gt;
&lt;p&gt;ACID 中原子性所定义的特征是：&lt;strong&gt;在出错时中止事务，并将部分完成的写入全部丢弃&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;假如没有原子性保证，当多个更新操作中间发生了错误，就需要知道哪些更改已经生效，哪些没有生效，这个寻找过程会非常麻烦。或许应用程序可以重试，但情况类似，并且可能导致重复更新或者不正确的结果。原子性则大大简化了这个问题：&lt;strong&gt;如果事务已经中止，应用程序可以确定没有实质发生任何更改，所以可以安全地重试&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;一致性&#34;&gt;一致性&lt;/h4&gt;
&lt;p&gt;ACID 中的一致性的主要是指&lt;strong&gt;对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如一个账单系统，账户的贷款余额应和借款余额保持平衡。如果某事务从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。&lt;/p&gt;
&lt;p&gt;这种一致性本质上&lt;strong&gt;要求应用层来维护状态一致（或者恒等）&lt;/strong&gt;，应用程序有责任正确地定义事务来保持一致性。这不是数据库可以保证的事情：即如果提供的数据修改违背了恒等条件，数据库很难检测进而阻止该操作（数据库可以完成针对某些特定类型的恒等约束检查，例如使用外键约束或唯一性约束。但通常主要靠应用程序来定义数据的有效／无效状态，数据库主要负责存储）。&lt;/p&gt;
&lt;h4 id=&#34;隔离性&#34;&gt;隔离性&lt;/h4&gt;
&lt;p&gt;ACID 语义中的隔离性意味着&lt;strong&gt;并发执行的多个事务相互隔离，它们不能互相交叉。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如，如果某个事务进行多次写入，则另一个事务应该观察到的是其全部完成（或者一个都没完成）的结果，而不应该看到中间的部分结果。&lt;/p&gt;
&lt;h4 id=&#34;持久性&#34;&gt;持久性&lt;/h4&gt;
&lt;p&gt;持久性即&lt;strong&gt;保证事务提交成功，即使存在硬件故障或数据库崩溃， 事务所写入的任何数据也不会消失&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;对于单节点数据库，持久性通常意味着数据已被写入非易失性存储设备，如硬盘或 SSD。在写入执行过程中，通常还涉及预写日志等， 这样万一	磁盘数据损坏可以进行恢复。而对于支持远程复制的数据库，持久性则意味着数据已成功复制到多个节点。为了实现持久性的保证，数据库必须等到这些写入或复制完成之后才能报告事务成功提交。&lt;/p&gt;
&lt;h2 id=&#34;弱隔离级别&#34;&gt;弱隔离级别&lt;/h2&gt;
&lt;p&gt;可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于采用较弱的隔离级别，它可以防止某些但并非全部的并发问题。&lt;/p&gt;
&lt;h3 id=&#34;读已提交&#34;&gt;读已提交&lt;/h3&gt;
&lt;p&gt;读已提交是最基本的的事务隔离级别，它只提供以下两个保证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读数据库时，只能看到巳成功提交的数据（防止脏读）。&lt;/li&gt;
&lt;li&gt;写数据库时，只会覆盖已成功提交的数据（防止脏写）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;某些数据库提供更弱的隔离级别，称为读未提交。它只防止脏写，而不防止脏读。&lt;/p&gt;
&lt;h4 id=&#34;脏读&#34;&gt;脏读&lt;/h4&gt;
&lt;p&gt;假定某个事务已经完成部分数据写入，但事务尚未提交（或中止），此时如果可以看到尚未提交的数据的话，那就是&lt;strong&gt;脏读&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;脏写&#34;&gt;脏写&lt;/h4&gt;
&lt;p&gt;如果两个事务同时尝试更新相同的对象，先前的写入是尚未提交的事务的一部分，如果被覆盖，那就是&lt;strong&gt;脏写&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;实现方法&#34;&gt;实现方法&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;数据库通常采用行级锁来防止脏写&lt;/strong&gt;。&lt;strong&gt;当事务想修改某个对象时，它必须首先获得该对象的锁，然后一直持有锁直到事务提交（或中止）。&lt;/strong&gt; 给定时刻，只有一个事务可以拿到特定对象的锁，如果有另一个事务尝试更新同一个对象，则必须等待，直到前面的事务完成了提交（或中止）后，才能获得锁并继续。&lt;/p&gt;
&lt;p&gt;但上述方法应用于脏写则不够理想。因为运行时间较长的写事务会导致许多只读的事务等待太长时间，这会严重影响只读事务的响应延迟，且可操作性差。&lt;/p&gt;
&lt;p&gt;因此，大多数数据库采用 &lt;strong&gt;MVCC&lt;/strong&gt; 的方式来实现。&lt;strong&gt;对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交之前，所有其他读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;快照隔离级别与可重复读&#34;&gt;快照隔离级别与可重复读&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;快照级别隔离对于只读事务特别有效。但是，具体到实现，许多数据库却对它有不同的命名。 Oracle 称之为可串行化， PostgreSQL、MySQL 则称为可重复读。&lt;/p&gt;
&lt;p&gt;这种命名混淆的原因是 SQL 标准并没有定义快照级别隔离，而仍然是基于老的 System R 1975 年所定义的隔离级别，而当时还没有出现快照级别隔离。标准定义的是可重复读，这看起来比较接近于快照级别隔离，所以 PostgreSQL、MySQL 称它们的快照级别隔离为可重复读，这符合标准要求（即合规性）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;实现方法-1&#34;&gt;实现方法&lt;/h4&gt;
&lt;p&gt;为了实现快照隔离级别，数据库采用了一种防止脏读但却更为通用的机制。考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以&lt;strong&gt;数据库保留了对象多个不同的提交版本&lt;/strong&gt;，这种技术因此也被称为&lt;strong&gt;多版本并发控制（Multi-Version Concurrency Control，MVCC）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果只是为了提供读已提交级别隔离，而不是完整的快照隔离级别，则只保留对象的两个版本就足够了：一个己提交的旧版本和尚未提交的新版本。所以，支持快照隔离级别的存储引擎往往直接采用 MVCC 来实现读已提交隔离。典型的做法是，&lt;strong&gt;在读已提交级别下，对每一个不同的查询单独创建一个快照；而快照隔离级别级别隔离则是使用一个快照来运行整个事务。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来看看 PostgreSQL 是如何实现基于 MVCC 的快照隔离级别 （其他实现基本类似）。&lt;/p&gt;
&lt;p&gt;当事务开始时，首先赋予一个&lt;strong&gt;唯一的、单调递增&lt;/strong&gt;的事务 ID（txid）。每当事务向数据库写入新内容时，所写的数据都会被标记写入者的事务 ID。&lt;/p&gt;
&lt;p&gt;表中的每行都有 &lt;code&gt;created_by&lt;/code&gt; 字段，其中包含了创建该行的事务 ID 。还有一个 &lt;code&gt;deleted_by&lt;/code&gt; 字段，初始为空。 如果事务要删除某行，该行实际上并未从数据库中删除，而只是将 &lt;code&gt;deleted_by&lt;/code&gt; 字段设置为请求删除的事务 ID （&lt;strong&gt;标记删除&lt;/strong&gt;） 。事后，当确定没有其他事务引用该标记删除的行时，数据库的垃圾回收进程才去真正删除井释放存储空间。&lt;strong&gt;这样一笔更新操作在内部会被转换为一个删除操作加一个创建操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图，事务 13 从账户中扣除 100 美元，余额从 500 美元减为 400 美元。 accounts 表里会出现两行账户 2 。一行是余额为 500 但标记为删除（由事务 13 删除），另一个余额为 400 ，由事务 13 创建。&lt;/p&gt;
&lt;h4 id=&#34;一致性快照的可见规则&#34;&gt;一致性快照的可见规则&lt;/h4&gt;
&lt;p&gt;当事务读数据库时·，通过事务 ID 可以决定哪些对象可见，哪些不可见。要想对上层应用维护好快照的一致性，需要精心定义数据的可见性规则。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每笔事务开始时，数据库列出所有当时尚在进行中的其他事务（即尚未提交或中止），然后忽略这些事务完成的部分写入（尽管之后可能会被提交），即不可见。&lt;/li&gt;
&lt;li&gt;所有中止事务所做的修改全部不可见。&lt;/li&gt;
&lt;li&gt;较晚事务ID（即晚于当前事务）所做的任何修改不可见，不管这些事务是否完成了提交。&lt;/li&gt;
&lt;li&gt;除此之外，其他所有的写入都对应用查询可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;换句话说，仅当以下两个条件都成立， 主数据对象对事务可见：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事务开始的时刻，创建该对象的事务已经完成了提交。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对象没有被标记为删除；或者即使标记了，但删除事务在当前事务开始时还没有完成提交。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;防止丢失更新&#34;&gt;防止丢失更新&lt;/h3&gt;
&lt;p&gt;写事务并发除了脏写以外，还会带来其他一些值得关注的冲突问题，最著名的就是&lt;strong&gt;更新丢失&lt;/strong&gt;问题。&lt;/p&gt;
&lt;p&gt;更新丢失可能发生在这样一个操作场景中：应用程序从数据库读取某些值，根据应用逻辑做出修改，然后写回新值 （read-modify-write）。 &lt;strong&gt;当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一事务的修改值可能会丢失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种冲突还可能在其他不同的场景下发生，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;递增计数器，或更新账户余额（需要读取当前值，计算新值井写回更新后的值）。&lt;/li&gt;
&lt;li&gt;对某复杂对象的一部分内容执行修改，例如对 JSON 文档中一个列表添加新元素（需要读取并解析文档，执行更改井写回修改后的文档）。&lt;/li&gt;
&lt;li&gt;两个用户同时编辑 wiki 页面，且每个用户都尝试将整个页面发送到服务器，覆盖数据库中现有内容以使更改生效 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并发写事务冲突是一个普遍问题，目前有多种可行的解决方案。&lt;/p&gt;
&lt;h4 id=&#34;原子写操作&#34;&gt;原子写操作&lt;/h4&gt;
&lt;p&gt;许多数据库提供了&lt;strong&gt;原子更新&lt;/strong&gt;操作，以避免在应用层代码完成读取-修改-写回操作，如果支持的话，通常这就是最好的解决方案。例如，以下指令在多数关系数据库中都是井发安全的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;UPDATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;counters&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SET&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;foo&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;原子操作通常采用&lt;strong&gt;对读取对象加独占锁的方式来实现&lt;/strong&gt;，这样在更新被提交之前不会让其他事务读取它。这种技术有时被称为&lt;strong&gt;游标稳定性&lt;/strong&gt;。另一种实现方式是&lt;strong&gt;强制所有的原子操作都在单线程上执行&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;显式加锁&#34;&gt;显式加锁&lt;/h4&gt;
&lt;p&gt;如果数据库不支持内置原子操作，另一种防止更新丢失的方法是&lt;strong&gt;由应用程序显式锁定待更新的对象&lt;/strong&gt;。 然后，应用程序可以执行读取-修改-写回这样的操作序列。此时如果有其他事务尝试并发读取对象，则必须等待当前正在执行的序列全部完成。&lt;/p&gt;
&lt;p&gt;例如这样一个场景，在一个多人游戏中，几个玩家可以同时移动同 个数字。只靠原子操作可能还不够，因为应用程序还需要确保玩家的移动还需遵守其他游戏规则，这涉及应用层逻辑，不可能将其剥离转移给数据库层在查询时执行。此时，可以使用锁来防止两名玩家同时操作相同的棋子，如下列代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;BEGIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figures&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;robot&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;game_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;222&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FOR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;UPDATE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- FOR UPDATE 指令指示数据库对返回的所有结果行要加锁。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- 检查玩家的操作是否有效，然后更新先前SELECT返回棋子的位置。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;UPDATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figures&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SET&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;position&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;c4&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1234&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COMMIT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;原子比较和设置&#34;&gt;原子比较和设置&lt;/h4&gt;
&lt;p&gt;原子操作和锁都是通过强制读取-修改-写回操作序列串行执行来防止丢失更新。另一种思路则是&lt;strong&gt;先让他们并发执行，但是如果事务管理器检测到了更新丢失的风险，则会中止当前事务，并强制回退到安全的读取-修改-写回方式。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该方法的一个优点是&lt;strong&gt;数据库完全可以借助快照级别隔离来高效地执行检查&lt;/strong&gt;。的确，PostgreSQL 的可重复读， Oracle 的可串行化以及 SQL Server 的快照级别隔离等，都可以自动检测何时发生了更新丢失，然后会中止违规的那个事务。但是，MySQL/InnoDB 的可重复读却并不支持检测更新丢失。有一些观点认为，数据库必须防止更新丢失，要不然就不能宣称符合快照级别隔离，如果基于这样的定义，那么 MySQL 就属于没有完全支持快照级别隔离。&lt;/p&gt;
&lt;h4 id=&#34;冲突解决和复制&#34;&gt;冲突解决和复制&lt;/h4&gt;
&lt;p&gt;对于支持多副本的数据库，防止丢失更新还需要考虑另一个维度 ：&lt;strong&gt;由多节点上的数据副本，不同的节点可能会并发修改数据&lt;/strong&gt;，因此必须采取一些额外的措施来防止丢失更新。&lt;/p&gt;
&lt;p&gt;加锁和原子修改都有个前提即&lt;strong&gt;只有一个最新的数据副本&lt;/strong&gt;。然而，对于多主节点或者无主节点的多副本数据库，由于支持多个井发写 ，且通常以异步方式来同步更新，所以会出现多个最新的数据副本。&lt;strong&gt;此时加锁和原子比较将不再适用。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多副本数据库通常支持多个井发写，然后保留多个冲突版本，之后由应用层逻辑或依靠特定的数据结构来解决、合并多版本。&lt;/p&gt;
&lt;p&gt;如果操作可交换（顺序无关，在不同的副本上以不同的顺序执行时仍然得到相同的结果），则原子操作在多副本情况下也可以工作。例如，计数器递增或向集合中添加元素等都是典型的可交换操作。&lt;/p&gt;
&lt;h3 id=&#34;写倾斜与幻读&#34;&gt;写倾斜与幻读&lt;/h3&gt;
&lt;h4 id=&#34;写倾斜&#34;&gt;写倾斜&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;当两笔事务根据读取相同的一组记录进行条件判断通过后，更新了不同的记录对象，刚刚的写操作改变了决定的前提条件，结果可能违背了业务约束要求&lt;/strong&gt;，此时的异常情况称为&lt;strong&gt;写倾斜&lt;/strong&gt;。只有&lt;strong&gt;可串行化&lt;/strong&gt;的隔离级别才能防止这种异常。&lt;/p&gt;
&lt;p&gt;写倾斜看起来很晦涩拗口，下面举几个常见场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;会议室预订系统&lt;/strong&gt;：要求在同一时间内，同一个会议室不能被预订两次。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户名&lt;/strong&gt;：网站通常要求每个用户有唯一的用户名，两个用户可能同时尝试创建相同的用户名。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;防止双重开支&lt;/strong&gt;：支付或积分相关的服务通常需要检查用户的花费不能超过其限额。如果有两笔交易同时进行，两个交易各自都不能超额，也不能加在一起后超额。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;可以将写倾斜视为一种更广义的更新丢失问题。&lt;/strong&gt; 即如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜。不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。&lt;/p&gt;
&lt;h4 id=&#34;幻读&#34;&gt;幻读&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。&lt;/strong&gt; 快照隔离可以防止只读查询的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁。&lt;/p&gt;
&lt;h2 id=&#34;串行化&#34;&gt;串行化&lt;/h2&gt;
&lt;p&gt;可串行化隔离通常被认为是&lt;strong&gt;最强的隔离级别&lt;/strong&gt;。 &lt;strong&gt;它保证即使事务可能会井行执行，但最终的结果与每次一个即串行执行结果相同。&lt;/strong&gt; 这意味着，如果事务在单独运行时表现正确，那么它们在并发运行时结果仍然正确，换句话说，&lt;strong&gt;数据库可以防止所有可能的竞争条件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;目前大多数提供可串行化的数据库都使用了以下三种技术之一：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;严格按照串行顺序执行&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;两阶段加锁&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;乐观井发控制技术&lt;/strong&gt;，例如可串行化的快照隔离。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;严格串行执行&#34;&gt;严格串行执行&lt;/h3&gt;
&lt;p&gt;解决并发问题最直接的方法是&lt;strong&gt;避免并发&lt;/strong&gt;，&lt;strong&gt;即在一个线程上按顺序方式每次只执行一个事务&lt;/strong&gt;。这样我们完全回避了诸如检测、防止事务冲突等问题，其对应的隔离级别是严格串行化的。&lt;/p&gt;
&lt;p&gt;当满足以下约束条件时，串行执行事务可以实现串行化隔离：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事务必须简短而高效，否则一个缓慢的事务将会影响到所有事务的执行性能。&lt;/li&gt;
&lt;li&gt;仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移动到磁盘，但万一单线程事务需要访问它，就会严重拖累性能 。&lt;/li&gt;
&lt;li&gt;写入吞吐量必须足够低，才能在单个 CPU 核上处理，否则就需要采用分区，最好没有跨分区事务。&lt;/li&gt;
&lt;li&gt;跨分区事务虽然也可以支持，但是占比必须很小。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;两阶段加锁&#34;&gt;两阶段加锁&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;虽然两阶段加锁（2PL）听起来和两阶段提交（two-phase commit，2PC）很相近，但它们是完全不同的东西。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;近三十年来，可以说数据库只有一种被广泛使用的串行化算法，那就是&lt;strong&gt;两阶段加锁（two-phase locking，2PL）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;两阶段加锁与前面提到的加锁方法类似，但锁的强制性更高。&lt;strong&gt;多个事务可以同时读取同一对象，但只要出现任何写操作（包括修改或删除），则必须加锁以独占访问&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么就必须等到 事务 A 提交或中止之才能继续。以确保事务 B 不会在事务 A 执行的过程中间去修改对象。&lt;/li&gt;
&lt;li&gt;如果事务 A 已经修改了对象， 此时事务 B 想要读取该对象， 则事务 B 必须等到事务 A 提交或者中止之后才能继续。对于 2PL ，不会出现读到旧值的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此 2PL &lt;strong&gt;不仅在并发写操作之间互斥，读取也会和修改产生互斥。&lt;strong&gt;另一方面，因为 2PL 提供了串行化，所以它&lt;/strong&gt;可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;实现方法-2&#34;&gt;实现方法&lt;/h4&gt;
&lt;p&gt;目前， 2PL 已经用于 MySQL（InnoDB）和 SQL Server 中的可串行化， 以及 DB2 中的可重复读。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据库的每个对象都有一个读写锁来隔离读写操作，即锁可以处于共享模式或独占模式。&lt;/strong&gt; 基本用法如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;如果事务要读取对象 ，必须先以共享模式获得锁。&lt;/strong&gt; 可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果事务要修改对象，必须以独占模式获取锁。&lt;/strong&gt; 不允许多个事务同时持有该锁（包括共享或独占模式），换句话说，如果对象上已被加锁，则修改事务必须等待。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果事务先是读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。&lt;/strong&gt; 升级锁的流程等价于直接获得独占锁。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事务获得锁之后，一直持有锁直到事务结束（包括提交或中止）。&lt;/strong&gt; 这也是名字两阶段的来由，在第一阶段（事务执行前）获取锁，第二阶段（事务结束后）释放锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于使用了很多锁机制，所以很容易出现&lt;strong&gt;死锁&lt;/strong&gt; ，例如事务 A 可能在等待事务 B 释放它的锁， 事务 B 在等待事务 A 释放所持有的锁（循环等待）。数据库系统会自动检测事务之间的死锁情况（常见方法是超时或者回路检测），并强行中止其中的一个以打破僵局，这样另一个可以继续向前执行，而被中止的事务需要由应用层来重试。&lt;/p&gt;
&lt;h4 id=&#34;谓词锁&#34;&gt;谓词锁&lt;/h4&gt;
&lt;p&gt;在前面的章节我们提到了幻读的问题，那么可串行化是如何解决幻读的呢？&lt;/p&gt;
&lt;p&gt;我们需要引入一种&lt;strong&gt;谓词锁&lt;/strong&gt;。它的作用于之前描述的共享/独占锁， 区别在于，&lt;strong&gt;它并不属于某个特定的对象（行），而是作用于满足某些搜索条件的所有查询对象（区间）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象（幻读）。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变得真正可串行化。&lt;/p&gt;
&lt;h4 id=&#34;索引区间锁&#34;&gt;索引区间锁&lt;/h4&gt;
&lt;p&gt;但是由于谓词锁性能不佳，如果活动事务中存在过多的锁，那么检查匹配这些锁就变得非常耗时。因此，大多数使用 2PL 的数据库实际上实现的是&lt;strong&gt;索引区间锁&lt;/strong&gt;（&lt;strong&gt;index-range locking，也称为next-key locking&lt;/strong&gt;）。本质上它是对谓词锁的简化或者近似。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简化谓词锁的方式是将其保护的对象扩大化到一整个索引上。&lt;/strong&gt; 例如存在下面这样一个场景，我们有一个酒店的管理系统，假设谓词锁保护的查询条件是：房间 123 ，时间段是周六 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;如果索引建立在房间号上&lt;/strong&gt;：此时数据库会将共享锁附加到房间号索引上，此时会锁定 123 号房间的所有记录。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果索引建立在日期上&lt;/strong&gt;：此时数据库会将共享锁附加到日期上，此时会锁定周六的所有记录。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;无论哪种方式，查询条件的近似值都附加到某个索引上。&lt;/strong&gt; 接下来，如果另一个事务想要插入、更新或删除同一个房间或重叠时间段的预订，则肯定需要更新这些索引，一定就会与共享锁冲突，因此会自动处于等待状态直到共享锁释放。&lt;/p&gt;
&lt;p&gt;这样就有效防止了 写倾斜和幻读问题。 的确，索引区间锁不像谓词锁那么精确，但由于开销低得多，可以认为是一种很好的折中方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。&lt;/strong&gt; 这种方式的性能肯定不好，它甚至会阻止所有其他事务的写操作，但的确可以保证安全性。&lt;/p&gt;
&lt;h4 id=&#34;性能&#34;&gt;性能&lt;/h4&gt;
&lt;p&gt;两阶段加锁的主要缺点在于其性能，其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多。&lt;/p&gt;
&lt;p&gt;其主要原因有以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;锁的获取和释放本身的开销大&lt;/strong&gt;：开销大的同时也降低了事务的并发性。两个并发事务如果做任何可能导致竞争条件的事情，其中一个必须等待对方完成。一旦出现多个事务同时访问同一对象，会形成一个等待队列，事务就必须等待队列前面所有其他事务完成之后才能继续。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据库的访问延迟具有非常大的不确定性&lt;/strong&gt;：某个事务本身很慢，或者是由于需要访问大量数据而获得了许多锁， 则它还会导致系统的其它部分都停顿下来。如果应用需要稳定的性能，这种不确定性就是致命的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;死锁变得更为频繁&lt;/strong&gt;：如果事务由于死锁而被强行中止，应用层就必须从头重试，假如死锁过于频繁，则最后的性能和效率必然大打折扣。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可串行化的快照隔离&#34;&gt;可串行化的快照隔离&lt;/h3&gt;
&lt;p&gt;两阶段加锁虽然可以保证串行化，但性能差强人意且无法扩展（由于串行执行）。弱级别隔离虽然性能不错，但容易引发各种边界条件（如更新丢失，写倾斜 ，幻读等）。那有什么方法可以使性能和串行化隔离得到均衡吗？&lt;/p&gt;
&lt;p&gt;这时候就需要提到&lt;strong&gt;可串行化的快照隔离（Serializable Snapshot Isolation, SSI) 算法&lt;/strong&gt;。它提供了完整的可串行性保证，而性能相比于快照隔离损失很小。目前， SSI 可用于单节点数据库（如 PostgreSQL 9.1 之后的可串行化隔离）或者分布式数据库（如 FoundationDB 采用了类似的算法）。&lt;/p&gt;
&lt;h4 id=&#34;实现&#34;&gt;实现&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;可串行化的快照隔离是一种乐观井发控制&lt;/strong&gt;。&lt;strong&gt;如果可能发生潜在冲突，事务会继续执行而不是中止，寄希望一切相安无事。而当事务提交时（只有可串行化的事务被允许提交），数据库会检查是否确实发生了冲突，如果是的话，中止事务并接下来重试。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SSI 基于快照隔离&lt;/strong&gt;，也就是说，&lt;strong&gt;事务中的所有读取操作都是基于数据库的一致性快照&lt;/strong&gt;。这是与早期的乐观并发控制主要区别。在快照隔离的基础上， &lt;strong&gt;SSI 新增加了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;性能-1&#34;&gt;性能&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。&lt;/strong&gt; 这一点和快照隔离一样 ，读写通常不会互相阻塞。这样的设计使得查询延迟更加稳定、可预测。特别是，在一致性快照上执行只读查询不需要任何锁，这对于读密集的负载非常有吸引力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;与串行执行相比，可串行化快照隔离可以突破单个 CPU 的限制。&lt;/strong&gt; FoundationDB 将冲突检测分布在多台机器上，从而提高总体吞吐量。即使数据可能跨多台机器进行分区，事务也可以在多个分区上读、写数据并保证可串行化隔离。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是，事务中止的比例会显著影响 SSI 的性能表现。&lt;/strong&gt; 例如，一个运行很长时间的事务，读取和写入了大量数据，因而产生冲突并中止的概率就会增大，所以 SSI 要求读写型事务要简短（而长时间执行的只读事务则没有此限制）。但总体讲，&lt;strong&gt;相比于两阶段加锁与串行执行， SSI 更能容忍那些执行缓慢的事务。&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（六）：分区</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD%E5%88%86%E5%8C%BA/</link>
        <pubDate>Sun, 10 Jul 2022 05:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD%E5%88%86%E5%8C%BA/</guid>
        <description>&lt;h1 id=&#34;分区&#34;&gt;分区&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;分区通常是这样定义的，即每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;采用数据分区的主要目的是&lt;strong&gt;提高可扩展性&lt;/strong&gt;。不同的分区可以放在一个无共享集群的不同节点上。这样一个大数据集可以分散在更多的磁盘上，查询负载也随之分布到更多的处理器上&lt;/p&gt;
&lt;p&gt;对单个分区进行查询时，每个节点对自己所在分区可以独立执行查询操作，因此添加更多的节点可以提高查询吞吐量。 超大而复杂的查询尽管比较困难，但也可能做到跨节点的并行处理。&lt;/p&gt;
&lt;h2 id=&#34;分区与复制&#34;&gt;分区与复制&lt;/h2&gt;
&lt;p&gt;分区通常与复制结合使用，即&lt;strong&gt;每个分区在多个节点都存有副本&lt;/strong&gt;。这意味着某条记录属于特定的分区 ，而同样的内容会保存在不同的节点上以提高系统的容错性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一个节点上可能存储了多个分区。&lt;/strong&gt; 如下图，每个分区都有自己的主副本，例如被分配给某节点，而从副本则分配在其他一些节点。&lt;strong&gt;一个节点可能即是某些分区的主副本，同时又是其他分区的从副本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;k-v-数据的分区&#34;&gt;K-V 数据的分区&lt;/h2&gt;
&lt;p&gt;分区的主要目标是&lt;strong&gt;将数据和查询负载均匀分布在所有节点上&lt;/strong&gt;，如果节点平均分担负载，那么理论上 10 个节点应该能够处理 10 倍的数据量和 10 倍于单个节点的读写吞吐量。&lt;/p&gt;
&lt;p&gt;而如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为&lt;strong&gt;倾斜&lt;/strong&gt;。倾斜会导致分区效率严重下降，在极端情况下，所有的负载可能会集中在一个分区节点上，这就意味着 10 个节点中 9 个空闲，系统的瓶颈在最繁忙的那个节点上。这种负载严重不成比例的分区即成为系统热点。&lt;/p&gt;
&lt;p&gt;避免热点最简单的方法是&lt;strong&gt;将记录随机分配到所有节点上&lt;/strong&gt;。这种方法虽然可以比较均匀地分布数据，但是有个很大的缺点，即当我们试图读取特定的数据时，没有办法知道数据保存在哪个节点上，所以不得不井行查询所有节点。&lt;/p&gt;
&lt;h3 id=&#34;基于key的区间分区&#34;&gt;基于Key的区间分区&lt;/h3&gt;
&lt;p&gt;一种分区方式是&lt;strong&gt;为每个分区分配一段连续的 Key 或者 Key 区间范围（以最小值和最大值来标识）&lt;/strong&gt;。如果知道 Key 区间的上下限，就可以轻松确定哪个分区包含这些 Key。 如果还知道哪个分区分配在哪个节点，就可以直接向该节点发出请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;每个分区内可以按照 Key 排序保存，这样可以轻松支持区间查询&lt;/strong&gt;，即将关键字作为一个拼接起来的索引项从而一次查询得到多个相关记录。&lt;/p&gt;
&lt;p&gt;然而，基于 Key 的区间分区的缺点是&lt;strong&gt;某些访问模式会导致热点&lt;/strong&gt;。如果 Key 是时间戳，则分区对应于一个时间范围，例如每天一个分区。这会导致该分区在写入时负载过高，而其他分区始终处于空闲状态。因此当 Key 为时间戳或者其他类似的属性时，我们需要对这些 Key 进行修改已保证不会产生大量倾斜。&lt;/p&gt;
&lt;h3 id=&#34;基于key的哈希值分区&#34;&gt;基于Key的哈希值分区&lt;/h3&gt;
&lt;p&gt;对于上述数据倾斜与热点问题，许多分布式系统采用了&lt;strong&gt;基于 Key 的哈希值&lt;/strong&gt;来分区。一个好的哈希函数可以处理数据倾斜并使其均匀分布。&lt;/p&gt;
&lt;p&gt;一旦找到合适的哈希函数，就可以为每个分区分配一个哈希范围（而不是直接作用于 Key 范围），Key 根据其哈希值的范围划分到不同的分区中。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;这种方法可以很好地将 Key 均匀分配到多个分区中。分区边界可以是均匀间隔， 也可以是伪随机选择（如&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_35423154/article/details/108727532?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164164219816781683953528%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;amp;request_id=164164219816781683953528&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-108727532.nonecase&amp;amp;utm_term=%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C&amp;amp;spm=1018.2226.3001.4450&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一致性哈希&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;然而，通过 Key 的哈希值进行分区，就&lt;strong&gt;丧失了良好的区间查询特性&lt;/strong&gt;。即使 Key 原本相邻，但经过哈希之后会分散在不同的分区中，区间查询就失去了原有的有序相邻的特性。&lt;/p&gt;
&lt;p&gt;基于哈希的分区方法可以减轻热点，但无法做到完全避免。 如在极端情况下，所有的读/写操作都是针对同一个Key，则最终所有请求都将被路由到同一个分区。如今大多数的系统仍然无法自动消除这种高度倾斜的负载，只能通过应用层来减轻倾斜程度。&lt;/p&gt;
&lt;h2 id=&#34;分区与二级索引&#34;&gt;分区与二级索引&lt;/h2&gt;
&lt;p&gt;如果涉及到二级索引，分区的逻辑又会变得更加复杂，因为&lt;strong&gt;二级索引通常不能唯一标识一条记录，而是用来加速特定值的查询。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二级索引面临的主要挑战是它们不能规整的映射到分区中&lt;/strong&gt;。目前有两种主要的方法来支持对二级索引进行分区：&lt;strong&gt;基于文档的分区&lt;/strong&gt;和&lt;strong&gt;基于词条的分区&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基于文档来分区二级索引（本地索引）&lt;/strong&gt;：二级索引存储在与关键字相同的分区 ，这意味着写入时我们只需要更新一个分区，但缺点是读取二级索引时需要在所有分区上执行分散/聚集 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基于词条来分区二级索引（全局索引）&lt;/strong&gt;：它是基于索引的值而进行的独立分区。二级索引中的条目可能包含来自关键字的多个分区里的记录。在写入时，不得不更新二级索引的多个分区。但读取时，则可以从单个分区直接快速提取数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于文档分区的二级索引&#34;&gt;基于文档分区的二级索引&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;在这种索引方法中，每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中的数据&lt;/strong&gt;。每当需要写数据库时，包括添加，删除或更新文档等，&lt;strong&gt;只需要处理包含目标文档 ID 的那一个分区&lt;/strong&gt;。因此文档分区索引被称为&lt;strong&gt;本地索引&lt;/strong&gt;，而不是全局索引。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia9.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图，由于数据可能分布在不同分区中，&lt;strong&gt;在读取时我们就需要将查询发送到所有的分区，然后合并所有返回的结果&lt;/strong&gt;。这种查询分区数据库的方法被称为分散/聚集，其二级索引的查询代价高昂。即使采用了并行查询，也容易导致读延迟显著放大。&lt;/p&gt;
&lt;h3 id=&#34;基于词条分区的二级索引&#34;&gt;基于词条分区的二级索引&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;我们对所有的数据构建全局索引，而不是每个分区维护自己的本地索引&lt;/strong&gt;。而且，为避免成为瓶颈，不能将全局索引存储在一个节点上，否则就破坏了设计分区均衡的目标。所以，&lt;strong&gt;全局索引也必须进行分区，且可以与数据关键字采用不的分区策略。&lt;strong&gt;我们将这种索引方案称为&lt;/strong&gt;词条分区&lt;/strong&gt;，它&lt;strong&gt;以待查找的关键字本身作为索引&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;这种全局的词条分区相比于文档分区索引的主要优点是，它的读取更为高效，即它不需要采用分散/聚集对所有的分区都执行一遍查询，相反，&lt;strong&gt;客户端只需要向包含词条的那个分区发出读请求&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而全局索引的不利之处在于其写入速度较慢且非常复杂，主要因为单个文档更新时，里面可能会涉及多个二级索引，而二级索引的分区又可能完全不同甚至在不同的节点上，由此势必引人显著的&lt;strong&gt;写放大&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;分区再平衡&#34;&gt;分区再平衡&lt;/h2&gt;
&lt;p&gt;随着时间的推移，数据库可能总会出现某些变化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;查询压力增加，因此需要更多的 CPU来处理负载。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据规模增加，因此需要更多的磁盘和内存来存储数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;节点可能出现故障，因此需要其他机器来接管失效的节点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有这些变化都要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为&lt;strong&gt;再平衡&lt;/strong&gt;（或动态平衡）。无论对于哪种分区方案，分区再平衡通常至少要满足 ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;再平衡执行过程中，数据库应该可以继续正常提供读写服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;避免不必要的负载迁移，以加快动态再平衡，井尽量减少网络和磁盘 I/O 影响。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;动态再平衡&#34;&gt;动态再平衡&lt;/h3&gt;
&lt;h4 id=&#34;固定数量的分区&#34;&gt;固定数量的分区&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;创建远超实际节点数的分区数，然后为每个节点分配多个分区。&lt;/strong&gt; 例如一个 10 节点的集群，数据库可以从一开始就逻辑划分为 1000 个分区，这样大约每个节点承担 100 个分区。如果集群中添加了新节点，该新节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡。如果从集群中删除节点，则采取相反的均衡措施。具体逻辑如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia11.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;原则上，也可以将集群中的不同的硬件配置因素考虑进来，&lt;strong&gt;即性能更强大的节点将分配更多的分区&lt;/strong&gt;，从而分担更多的负载。目前 Riak、Elasticsearch、Couchbase、Voldemort 都支持这种动态平衡方法。&lt;/p&gt;
&lt;h4 id=&#34;动态创建分区&#34;&gt;动态创建分区&lt;/h4&gt;
&lt;p&gt;因此，一些数据库如 HBase 和 RethinkDB 等采用了&lt;strong&gt;动态创建分区&lt;/strong&gt;。&lt;strong&gt;当分区的数据增长超过一个可配的参数阔值时，它就拆分为两个分区，每个分区承担一半的数据。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合井。&lt;/strong&gt; 该过程类似于 B 树的分裂操作。&lt;/p&gt;
&lt;p&gt;动态分区的一个优点是&lt;strong&gt;分区数量可以自动适配数据总量&lt;/strong&gt;。如果只有少量的数据，少量的分区就足够了，这样就减轻了系统的开销；如果有大量数据，每个分区的大小则被限制一个可配置的最大值。 &lt;strong&gt;因此分区的数量与数据集的大小成正比关系。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;按节点比例分区&#34;&gt;按节点比例分区&lt;/h4&gt;
&lt;p&gt;在前面两种方法中，分区的数量都与数据集大小有关，而与节点数无关。而 Cassandra 和 Ketama 采用了第三种方式，&lt;strong&gt;使分区数与集群节点数成正比关系&lt;/strong&gt;。换句话说，&lt;strong&gt;每个节点具有固定数量的分区&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;此外，当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系。当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大量的节点来存储，因此这种方法使每个分区大小保持稳定。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当一个新节点加入集群时，它随机选择固定数量的现有分区进行分裂，然后拿走这些分区的一半数据量，将另一半数据留在原节点。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;手动与自动再平衡&#34;&gt;手动与自动再平衡&lt;/h3&gt;
&lt;p&gt;动态平衡的执行方式有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;手动再平衡&lt;/strong&gt;：分区到节点的映射由管理员来显式配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全自动再平衡&lt;/strong&gt;：由系统自动决定何时将分区从一个节点迁移到另一个节点，不需要任何管理员的介入。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;半自动再平衡&lt;/strong&gt;：自动生成分区分配的建议方案，但需要管理员的确认才能生效。 如 Couchbase，Riak 和 Vodemort。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;全自动式再平衡会更加方便，它在正常维护之外所增加的操作很少。但是，也有可能出现结果难以预测的情况。再平衡总体讲是个比较昂贵的操作，它需要重新路由请求并将大量数据从一个节点迁移到另一个节点。万一执行过程中间出现异常，会使网络或节点的负载过重，并影响其他请求的性能。&lt;/p&gt;
&lt;p&gt;基于以上描述综合考虑，半自动再平衡可能是个更好的选择。虽然它比全自动再平衡响应慢，但它可以有效防止意外发生。&lt;/p&gt;
&lt;h2 id=&#34;请求路由&#34;&gt;请求路由&lt;/h2&gt;
&lt;p&gt;当客户端需要发送请求时，如何知道应该连接哪个节点呢？这其实属于一类典型的&lt;strong&gt;服务发现&lt;/strong&gt;问题，这个问题有以下几种不同的处理策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;允许客户端连接任何一个的节点，如果某节点恰好拥有所请求的分区，则直接处理该请求；否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将所有客户端的请求都发送到路由层，由后者负责将请求转发到对应的分区节点上。路由层本身不处理任何请求，它仅充当一个分区感知的负载均衡器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端感知分区和节点的分配关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;许多分布式数据系统依靠独立的协调服务（如 ZooKeeper ）跟踪集群范围内的元数据，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia7.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;每个节点都向 ZooKeeper 注册自己， ZooKeeper 维护了分区到节点的最终映射关系。其他参与者（路由层或分区感知的客户端 ）可以向 ZooKeeper 订阅此信息。一旦分区发生了改变，或者添加、删除节点， ZooKeeper 就会主动通知路由层，这样使路由信息保持最新状态。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（五）：复制</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94%E5%A4%8D%E5%88%B6/</link>
        <pubDate>Sun, 10 Jul 2022 04:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94%E5%A4%8D%E5%88%B6/</guid>
        <description>&lt;h1 id=&#34;复制&#34;&gt;复制&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;复制主要指通过互联网络在多台机器上保存相同数据的副本。&lt;/strong&gt; 通过数据复制方案，人们通常希望达到以下目的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;低延迟&lt;/strong&gt;：使数据在地理位置上更接近用户，从而降低访问延迟&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;高可用&lt;/strong&gt;：当部分组件出现故障，系统依然可以继续工作，从而提高可用性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可拓展&lt;/strong&gt;：扩展至多台机器以同时提供数据访问服务，从而提高读吞量。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主流的三种流行的复制数据变化的方法是：&lt;strong&gt;主从复制&lt;/strong&gt;、&lt;strong&gt;多主节点复制&lt;/strong&gt;和&lt;strong&gt;无主节点复制&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;主从复制&#34;&gt;主从复制&lt;/h2&gt;
&lt;p&gt;每个保存数据库完整数据集的节点称之为&lt;strong&gt;副本&lt;/strong&gt;。而每当有数据写入时，所有的副本需要随之更新，否则就会出现数据不一致的问题。最常见的解决方案就是&lt;strong&gt;主从复制&lt;/strong&gt;，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;其工作原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;指定某一个节点为主节点。当用户写数据库时，必须将写请求首先发送给主节点，主节点首先将新数据写入本地存储。&lt;/li&gt;
&lt;li&gt;其他节点则全部称为从节点。主节点把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从节点。每个从节点获得更改日志之后将其应用到本地，且严格保持与主节点相同的写入顺序。&lt;/li&gt;
&lt;li&gt;客户端从数据库中读数据时，可以在主节点或者从节点上执行查询。只有主节点才可以接受写请求 ，从客户端的角度来看，从节点都是只读的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;同步复制与异步复制&#34;&gt;同步复制与异步复制&lt;/h3&gt;
&lt;p&gt;复制非常重要的一个设计选项是&lt;strong&gt;同步复制&lt;/strong&gt;还是&lt;strong&gt;异步复制&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;同步复制&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：一旦向用户确认，从节点可以明确保证完成了与主节点的更新同步，数据已经处于最新版本 。万 一主节点发生故障，总是可以在从节点继续访问最新的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：如果同步的从节点无法完成确认，写入就不能视为成功。 主节点会阻塞其后所有的写操作，直到同步副本确认完成。因此任何一个同步节点的中断都会导致整个系统更新停滞不前。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;异步复制&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：不管从节点上数据多么滞后，主节点总是可以继续响应写请求，系统的吞吐性能更好。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：如果主节点发生失败且不可恢复 ，则所有尚未复制到从节点的写请求都会丢失。这意味着即使向客户端确认了写操作， 却还是无法保证数据的持久化。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实际使用中有时还会采用&lt;strong&gt;半同步&lt;/strong&gt;的设计方案。即某个从节点是同步的，而其他节点则是异步模式。万一同步的从节点变得不可用或性能下降， 则将另一个异步的从节点提升为同步模式。这样可以保证至少有两个节点（即主节点和一个同步从节点）拥有最新的数据副本。&lt;/p&gt;
&lt;h3 id=&#34;新增节点&#34;&gt;新增节点&lt;/h3&gt;
&lt;p&gt;如果需要增加副本数以提高容错能力，或者替换失败的副本，就需要考虑增加新的从节点。但如何确保新的从节点和主节点保持数据一致呢？&lt;/p&gt;
&lt;p&gt;主要操作步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在某个时间点对主节点的数据副本产生一个一致性快照，这样避免长时间锁定整个数据库。&lt;/li&gt;
&lt;li&gt;将此快照拷贝到新的从节点。&lt;/li&gt;
&lt;li&gt;从节点连接到主节点并请求快照点之后所发生的数据更改日志。&lt;/li&gt;
&lt;li&gt;获得日志之后，从节点来应用这些快照点之后所有数据变更。&lt;/li&gt;
&lt;li&gt;不断重复上述过程。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;节点失效的处理&#34;&gt;节点失效的处理&lt;/h3&gt;
&lt;h4 id=&#34;从节点失效&#34;&gt;从节点失效&lt;/h4&gt;
&lt;p&gt;从节点的本地磁盘上都保存了副本收到的数据变更日志。如果从节点发生崩溃，然后顺利重启，或者主从节点之间的网络发生暂时中断（闪断），则恢复比较容易，根据副本的复制日志，从节点可以知道在发生故障之前所处理的最后一笔事务，然后连接到主节点，并请求自那笔事务之后中断期间内所有的数据变更。在收到这些数据变更日志之后，将其应用到本地来追赶主节点。之后就和正常情况 样持续接收来自主节点数据流的变化。&lt;/p&gt;
&lt;h4 id=&#34;主节点失效&#34;&gt;主节点失效&lt;/h4&gt;
&lt;p&gt;处理主节点故障的情况则比较棘手：&lt;strong&gt;选择某个从节点将其提升为主节点。这样之后的写请求会发送给新的主节点，然后其他从节点要接受来自新的主节点上的变更数据&lt;/strong&gt;，这一过程称之为&lt;strong&gt;故障转移&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;故障转移可以手动进行，例如通知管理员主节点发生失效，采取必要的步骤来创建新的主节点。或者以自动方式进行切换。自动切换的步骤通常如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;确认主节点失效。&lt;strong&gt;大多数系统都采用了基于&lt;/strong&gt;超时&lt;/strong&gt;的机制。节点间频繁地互相发生发送心跳存活消息，如果发现 某一个节点在一段比较长时间内（例如 30s）没有响应，即认为该节点发生失效。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选举新的主节点。&lt;strong&gt;可以通过&lt;/strong&gt;选举&lt;/strong&gt;的方式（超过多数的节点达成共识）来选举新的主节点，或者由之前选定的某控制节点来指定新的主节点。候选节点最好与原主节点的数据差异最小，这样可以最小化数据丢失的风险。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重新配置系统使新主节点生效。&lt;/strong&gt; 客户端现在需要将写请求发送给新的主节点。如果原主节点之后重新上线，这时系统要确保原主节点降级为从节点，并让其认可新的主节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;复制日志的实现&#34;&gt;复制日志的实现&lt;/h3&gt;
&lt;h4 id=&#34;基于语句的复制&#34;&gt;基于语句的复制&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;主节点记录所执行的每个写请求（操作语句）并将该操作语句作为日志发送给从节点。&lt;/strong&gt; 对于关系数据库，这意味着每个 &lt;code&gt;INSERT&lt;/code&gt;、&lt;code&gt;UPDATE&lt;/code&gt;、 &lt;code&gt;DELETE&lt;/code&gt; 语句都会转发给从节点，并且每个从节点都会分析井执行这些 SQL 语句。&lt;/p&gt;
&lt;p&gt;但这种复制方式有一些不适用的场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任何调用非确定性函数的语句，如 &lt;code&gt;NOW()&lt;/code&gt; 获取当前时间，或 &lt;code&gt;RAND()&lt;/code&gt;  获取一个随机数等，可能会在不同的副本上产生不同的值。&lt;/li&gt;
&lt;li&gt;如果语句中使用了自增列，或者依赖于数据库的现有数据（例如，&lt;code&gt;UPDATE ... WHERE &amp;lt;某些条件&amp;gt;&lt;/code&gt;），则所有副本必须按照完全相同的顺序执行，否则可能会带来不同的结果。进而，如果有多个同时并发执行的事务时， 会有很大的限制。&lt;/li&gt;
&lt;li&gt;有副作用的语句（例如，触发器、存储过程、用户定义的函数等），可能会在不同的副本上产生不同的副作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;基于预写日志传输&#34;&gt;基于预写日志传输&lt;/h4&gt;
&lt;p&gt;对于常见的磁盘数据结构，通常每个写操作都是以追加写的方式写入到日志中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于日志结构存储引擎，日志是主要的存储方式。日志段在后台压缩井支持垃圾回收。&lt;/li&gt;
&lt;li&gt;对于采用覆盖写磁盘的 B 树 结构，每次修改会预先写入日志，如系统发生崩溃，通过索引更新的方式迅速恢复到此前一致状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有对数据库写入的字节序列都被记入日志。因此可以使用完全相同的日志在另一个节点上构建副本：&lt;strong&gt;将日志入磁盘之后，主节点通过网络将其发送给从节点。 从节点收到日志进行处理，建立和主节点内容完全相同的数据副本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其主要缺点是&lt;strong&gt;日志描述的数据结果非常底层。&lt;/strong&gt; WAL 包含了哪些磁盘块的哪些字节发生改变，诸如此类的细节。这使得复制方案和存储引擎紧密耦合。如果数据库的存储格式从一个版本改为另一个版本，那么系统通常无法支持主从节点上运行不同版本的软件。&lt;/p&gt;
&lt;h4 id=&#34;基于行的逻辑日志复制&#34;&gt;基于行的逻辑日志复制&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;复制和存储采用不同的日志格式，这样使得复制与存储逻辑剥离。&lt;strong&gt;这种复制日志称为&lt;/strong&gt;逻辑日志&lt;/strong&gt;，以区分物理存储引擎的数据表示。&lt;/p&gt;
&lt;p&gt;关系数据库的逻辑日志通常是指一系列记录来描述数据表行级别的写请求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于行插入，日志包含所有相关列的新值。&lt;/li&gt;
&lt;li&gt;对于行删除，日志里有足够的信息来唯一标识已删除的行，通常是靠主键，但如果表上没有定义主键，就需要记录所有列的旧值。&lt;/li&gt;
&lt;li&gt;对于行更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少包含所有已更新列的新值）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于逻辑日志与存储引擎逻辑解耦，因此可以更容易地保持向后兼容，从而使主从节点能够运行不同版本的软件甚至是不同的存储引擎。对于外部应用程序来说，逻辑日志格式也更容易解析。&lt;/p&gt;
&lt;h4 id=&#34;基于触发器的复制&#34;&gt;基于触发器的复制&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;触发器支持注册自己的应用层代码，使得当数据库系统发生数据更改（写事务）时自动执行上述自定义代码&lt;/strong&gt;。通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，实施必要的自定义应用层逻辑，例如将数据更改复制到另一个系统。&lt;/p&gt;
&lt;p&gt;基于触发器的复制通常比其他复制方式开销更高， 也比数据库内置复制更容易出错，或者暴露一些限制。然而，其高度灵活性仍有用武之地。&lt;/p&gt;
&lt;h2 id=&#34;复制滞后问题&#34;&gt;复制滞后问题&lt;/h2&gt;
&lt;h3 id=&#34;写后读一致性&#34;&gt;写后读一致性&lt;/h3&gt;
&lt;p&gt;对于分布式数据库来说，提交新数据须发送到主节点，但是当用户读取数据 ，数据可能来自从节点，这就会带来一个问题。&lt;strong&gt;当用户在写入不久时查看数据，则新数据可能尚未到达从节点。对用户来讲， 看起来似乎是刚刚提交的数据丢失了&lt;/strong&gt;，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;对于这种情况，就需要引入&lt;strong&gt;写后读一致性（也称读写一致性）&lt;/strong&gt;。 &lt;strong&gt;其保证如果用户重新加载页面，他们总能看到自己最近提交的更新。但对其他用户则没有任何保证，这些用户的更新可能会在稍后才能刷新看到。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;单调读&#34;&gt;单调读&lt;/h3&gt;
&lt;p&gt;如下图所示。假定用户 2345 从不同副本进行了多次完全相同的读取，第一次首先查询到了一个相对来说正常的节点，该节点接收到了用户 1234 发布的内容，并将其返回给了用户 2345。而当网页再次刷新，用户 2345 再次进行查询，此时又路由到了一个相对来说较为滞后的节点，这时由于其还未来得及同步用户 1234 的数据，就导致了其返回了一个空结果。对于用户 2345 来说，此时他&lt;strong&gt;看到了最新内容之后又看到了过期的内容，好像时间被回拨了一样&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;单调读&lt;/strong&gt;可以确保不会发生这种异常。这是一个介于强一致性与最终一致性的保证 。&lt;strong&gt;其保证了当读取数据时，如果某个用户依次进行多次读取，则他绝不会看到回滚现象，即在读取较新值之后又发生读旧值的情况。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实现单调读的一种方式是，&lt;strong&gt;确保每个用户总是从固定的同一副本执行读取&lt;/strong&gt;（而不同的用户可以从不同的副本读取）。例如，基于用户 ID 的哈希的方法而不是随机选择副本。但如果该副本发生失效，则用户的查询必须重新路由到另一个副本。&lt;/p&gt;
&lt;h3 id=&#34;前缀一致读&#34;&gt;前缀一致读&lt;/h3&gt;
&lt;p&gt;如果数据库总是以相同的顺序写入，则读取总是看到一致的序列，不会发生这种反常。然而，在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序。&lt;strong&gt;这就导致当用户从数据库中读数据时，可能会看到数据库的某部分旧值和另一部分新值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia16.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;为了防止这种异常问题，就需要引入一种保证：&lt;strong&gt;前缀一致读&lt;/strong&gt;。&lt;strong&gt;其保证了对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比较常见的实现方案是&lt;strong&gt;确保任何具有因果顺序关系的写入都交给一个分区来完成&lt;/strong&gt;。但由于其性能不佳，如今通常使用一些新的算法来&lt;strong&gt;显式追踪事件因果关系&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;多主节点复制&#34;&gt;多主节点复制&lt;/h2&gt;
&lt;p&gt;主从复制并不是完美的，其存在&lt;strong&gt;单点问题&lt;/strong&gt;：&lt;strong&gt;系统只有一个主节点，而所有的写入都必须经由主节点&lt;/strong&gt; 。如果由于某种原因，例如与主节点之间的网络中断而导致主节点无法连接，主从复制方案就会影响所有的写入操作。&lt;/p&gt;
&lt;p&gt;如果要改进这个策略，就可以对主从复制模型进行自然的扩展。&lt;strong&gt;即配置多个主节点，每个主节点都可以接受写操作，处理写的每个主节点都必须将该数据更改转发到所有其他节点 。&lt;strong&gt;这就是&lt;/strong&gt;多主节点复制&lt;/strong&gt;。此时，每个主节点同时扮演其他主节点的从节点。&lt;/p&gt;
&lt;h3 id=&#34;处理写冲突&#34;&gt;处理写冲突&lt;/h3&gt;
&lt;p&gt;多主复制的最大问题是可能发生&lt;strong&gt;写冲突&lt;/strong&gt;。而通常采用下面三种方法来处理。&lt;/p&gt;
&lt;h4 id=&#34;避免冲突&#34;&gt;避免冲突&lt;/h4&gt;
&lt;p&gt;而处理冲突最理想的策略是&lt;strong&gt;避免发生冲突&lt;/strong&gt; ，即&lt;strong&gt;如果应用层可以保证对特定记录的写请求总是通过同一个主节点，这样就不会发生写冲突。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如，在一个应用系统中，用户需要更新自己的数据，那么我们确保特定用户的更新请求总是路由到特定的数据中心，并在该数据中心的主节点上进行读/写。但是，有时可能需要改变事先指定的主节点，例如由于该数据中心发生故障，不得不将流量重新路由到其他数据中心，此时，冲突避免方式不再有效，必须有措施来处理同时写入冲突的可能性。&lt;/p&gt;
&lt;h4 id=&#34;收敛于一致状态&#34;&gt;收敛于一致状态&lt;/h4&gt;
&lt;p&gt;当多个主节点写入数据发生冲突时，所有的复制模型至少应该确保&lt;strong&gt;数据在所有副本中最终状态一定是一致的&lt;/strong&gt;。因此，数据库必须以一种&lt;strong&gt;收敛趋同&lt;/strong&gt;的方式来解决冲突，这就意味着&lt;strong&gt;当所有更改最终被复制、同步之后，所有副本的最终值是相同&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;收敛的冲突解决有以下几种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;给每个写入分配唯一 ID。&lt;/strong&gt; 例如时间戳、足够长的随机数，UUID 或者基于 K-V 的哈希值，挑选最高 ID 的写入作为胜利者，并将其他写入丢弃。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为每个副本分配一个唯一的 ID，并制定规则。&lt;/strong&gt; 例如序号高的副本写入始终优先于序号低的副本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;以某种方式将这些值合并在一起。&lt;/strong&gt; 例如，按字母顺序排序，然后拼接在一起。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;自定义冲突解决逻辑&#34;&gt;自定义冲突解决逻辑&lt;/h4&gt;
&lt;p&gt;解决冲突最合适的方式可能还是依靠应用层，所以大多数多主节点复制模型都有工具让用户编写应用代码来解决冲突。可以在写入时或在读取时执行这些代码逻辑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;在写入时执行&lt;/strong&gt;：只要数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突处理程序。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在读取时执行&lt;/strong&gt;：当检测到冲突时，所有冲突写入值都会暂时保存下来。当下一次读取数据时，会将数据的多个版本读返回给应用层。应用层可能会提示用户或自动解决冲突， 井将最后处理好的结果返回到数据库。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;拓扑结构&#34;&gt;拓扑结构&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;拓扑结构描述了写请求从一个节点传播到其他节点的通信路径。&lt;/strong&gt; 常见的拓扑结构如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;环形拓扑&lt;/strong&gt;：每个节点接收来自前序节点的写入，井将这些写入（加上自己的）转发给后序节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;星形拓扑&lt;/strong&gt;：一个指定的根节点将写入转发给所有其他节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全链接拓扑&lt;/strong&gt;：每个主节点将其写入同步到其他所有主节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在环形和星形拓扑中，写请求需要通过多个节点才能到达所有的副本，即中间节点需要转发从其他节点收到的数据变更。为防止无限循环，每个节点需要赋予一个唯一标识符，在复制日志中的每个写请求都标记了已通过的节点标识符。如果某个节点收到了包含自身标识符的数据更改，表明该请求已经被处理过，因此会忽略变更请求，避免重复转发。&lt;/p&gt;
&lt;p&gt;环形和星形拓扑的问题是，如果某一个节点发生了故障，在修复之前，会影响其他节点之间复制日志的转发。可以采用重新配置拓扑结构的方法暂时排除掉故障节点。&lt;/p&gt;
&lt;p&gt;全链接拓扑也存在一些问题。主要是存在某些网络链路比其他链路更快的情况（例如由于不同网络拥塞），从而导致复制日志之间的覆盖。为了使得日志消息正确有序，可以使用一种称为版本向量的技术。&lt;/p&gt;
&lt;h2 id=&#34;无主节点复制&#34;&gt;无主节点复制&lt;/h2&gt;
&lt;p&gt;无主节点复制模型采用了另一种方案，&lt;strong&gt;其选择放弃主节点，允许任何副本直接接受来自客户端的写请求。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;节点失效处理&#34;&gt;节点失效处理&lt;/h3&gt;
&lt;p&gt;对于有主复制模型来说，当节点失效后，其会通过主从切换、从节点追赶等方式来进行修复。但是对于无主模型来说，并没有这样的切换机制。&lt;/p&gt;
&lt;p&gt;对于无主模型，其解决节点失效的方法如下：&lt;strong&gt;当一个客户端从数据库中读取数据时，它不是向一个副本发送请求，而是并行地发送到多个副本。&lt;strong&gt;客户端可能会得到不同节点的不同响应，包括某些节点的新值和某些节点的旧值。可以采用&lt;/strong&gt;版本号&lt;/strong&gt;来确定哪个值更新。&lt;/p&gt;
&lt;h4 id=&#34;读修复与反熵&#34;&gt;读修复与反熵&lt;/h4&gt;
&lt;p&gt;复制模型应确保所有数据最终复制到所有的副本。当一个失效的节点重新上线之后，它如何赶上中间错过的那些写请求呢？&lt;/p&gt;
&lt;p&gt;Dynamo 风格的数据存储系统经常使用以下两种机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;读修复&lt;/strong&gt;：当客户端并行读取多个副本时，可以检测到过期的返回值，然后将新值写入到该副本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反熵&lt;/strong&gt;：后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;读写的quorum&#34;&gt;读写的quorum&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;如果有 n 个副本，写入需要 w 个节点确认，读取必须至少查询 r 个节点，则只要满足 w + r &amp;gt; n ，读取的节点中一定会包含最新值。&lt;/strong&gt;（成功写入的节点集合和读取的节点集合必然有重合 ，这样读取的节点中至少有一个具有最新值）。满足上述这些 r、w 值的读/写操作被称之为&lt;strong&gt;法定票数读&lt;/strong&gt;或&lt;strong&gt;法定票数写&lt;/strong&gt;。也可以认为 r 和 w 是用于判定读、写是否有效的最低票数。&lt;/p&gt;
&lt;p&gt;在 Dynamo 风格的数据库中，**参数 n、w 和 r 通常是可配置的。一个常见的选择是设置 n 为奇数，&lt;code&gt;w = r = (n + 1) / 2 &lt;/code&gt;。**通常会根据具体的业务场景来灵活配置。&lt;/p&gt;
&lt;p&gt;仲裁条件 w + r &amp;gt; n 定义了系统可容忍的失效节点数，如下所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当 w &amp;lt; n ，如果一个节点不可用，仍然可以处理写入。&lt;/li&gt;
&lt;li&gt;当 r &amp;lt; n ，如果一个节点不可用，仍然可以处理读取。&lt;/li&gt;
&lt;li&gt;例如 n = 5，w = 3，r = 3。则可以容忍两个不可用的节点。&lt;/li&gt;
&lt;li&gt;读取和写入操作总是并行发送到所有的 n 个副本。参数 r 和参数 w 只是决定要等待的节点数。即有多少个节点需要返回结果 ，我们才能判断出结果的正确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia18.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如果可用节点数小于所需的 w 或 r，则写入或读取就会返回错误。&lt;/p&gt;
&lt;h3 id=&#34;检查并发写&#34;&gt;检查并发写&lt;/h3&gt;
&lt;p&gt;Dynamo 风格的数据库允许多个客户端对相同的主键同时发起写操作， 即使采用严格的 quorum 机制也可能会发生写冲突。这与多主节复制类似，此外，由于读时修复或者数据回传也会导致并发写冲突。&lt;/p&gt;
&lt;p&gt;由于网络延迟不稳定或者局部失效，请求在不同的节点上可能会呈现不同的顺序。如果节点每当收到新的写请求时就简单地覆盖原有的主键，那么这些节点将永久无法达成一致。&lt;/p&gt;
&lt;p&gt;下面就来介绍一下数据库内部如何进行冲突处理，保证副本收敛于相同的内容，从而达到最终一致性。&lt;/p&gt;
&lt;h4 id=&#34;最后写入获胜lww算法&#34;&gt;最后写入获胜（LWW算法）&lt;/h4&gt;
&lt;p&gt;一种实现最终收敛的方方法是，&lt;strong&gt;每个副本总是保存最新值，允许覆盖并丢弃旧值。&lt;/strong&gt; 那么，假定每个写请求都最终同步到所有副本，只要有一个明确的方法来确定哪个写入是最新的， 副本可以最终收敛到相同的值。但问题又来了，&lt;strong&gt;对于并发的写入，我们无法确定他们的顺序。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;即使无法确定写请求的自然顺序，我们也可以强制对其排序。&lt;strong&gt;附加为每一个写请求附加一个时间戳，然后选择最新的时间戳，丢弃较早时间戳的写入。这个冲突解决算能被称为&lt;/strong&gt;最后写入获胜（LWW, last write wins）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LWW 可以达成最终一致，但代价是牺牲数据持久性。如果同一个主键有多个并发写，即使这些并发写都向客户端报告成功（因为完成了写入 w 个副本），但最后只有一个写入值会存活下来，其他的将被系统默默丢弃。&lt;/p&gt;
&lt;p&gt;在某些场景下，由于 LWW 会导致数据的覆盖和丢失，所以它并不是一个好的选择。要确保 LWW 安全无副作用的唯一方法是：&lt;strong&gt;只写入一次然后写入值视为不可变，这样就避免了对同一主键的并发（覆盖）写。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;happens-before关系和并发&#34;&gt;Happens-before关系和并发&lt;/h4&gt;
&lt;p&gt;如何判断两个操作是否是并发呢？通常如果两个操作&lt;strong&gt;同时发生&lt;/strong&gt;，则称之为并发，然而事实上，操作是否在时间上重叠并不重要，由于分布式系统中复杂的时钟同步问题，现实当中，我们很难严格确定它们是否同时发生。 为了更好的定义并发性，我们并不依赖确切的发生时间，即不管物理的时机如何，&lt;strong&gt;如果两个操作并不需要意识到对方，我们即可称它们是并发操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果 B 知道 A，或者 B 依赖于 A，或者以某种方式在 A 的基础上构建，则称操作 A 在操作 B 之前发生。&lt;strong&gt;这是定义何为并发的关键。事实上，我们也可以简单地说，&lt;strong&gt;如果两个操作都不在另一个之前发生（或者两者都不知道对方）&lt;/strong&gt; ，那么操作是&lt;/strong&gt;并发&lt;/strong&gt;的。&lt;/p&gt;
&lt;h4 id=&#34;确定前后关系&#34;&gt;确定前后关系&lt;/h4&gt;
&lt;p&gt;服务器判断操作是否并发的依据主要依靠&lt;strong&gt;对比版本号&lt;/strong&gt; ，而并不需要解释新旧值本身（值可以是任何数据结构）。算法的工作流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，井将新版本号与写入的值一起保存 。&lt;/li&gt;
&lt;li&gt;当客户端读取主键时，服务器将返回所有（未被覆盖的）当前值以及最新的版本号。且要求写之前，客户必须先发送读请求 。&lt;/li&gt;
&lt;li&gt;客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合。写请求的响应可以像读操作一样会返回所有当前值，这样就可以一步步链接起多个写入的值。&lt;/li&gt;
&lt;li&gt;当服务器收到带有特定版本号的写入时，覆盖该版本号或更低版本的所有值（因为知道这些值已经被合并到新传入的值集合中），但必须保存更高版本号的所有值（因为这些值与当前的写操作属于并发）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当写请求包含了前一次读取的版本号时，意味着修改的是基于以前的状态。如果一个写请求没有包含版本号，它将与所有其他写入同时进行，不会覆盖任何已有值，其传入的值将包含在后续读请求的返回值列表当中。&lt;/p&gt;
&lt;h4 id=&#34;合并同时写入的值&#34;&gt;合并同时写入的值&lt;/h4&gt;
&lt;p&gt;如果多个操作并发发生，则客户端必须通过合并并发写入的值来继承旧值。&lt;/p&gt;
&lt;h4 id=&#34;版本矢量&#34;&gt;版本矢量&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;所有副本的版本号集合称为版本矢量。&lt;/strong&gt; 当读取数据时，数据库副本会返回版本矢量给客户端，而在随后写入时需要将版本信息包含在请求当中一起发送到数据库。&lt;strong&gt;版本矢量技术使数据库可以区分究竟应该覆盖写还是保留并发值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;版本矢量可以保证从某一个副本读取值然后写入到另一个副本，而这些值可能会导致在其他副本上衍生出来新的“兄弟”值，但至少不会发生数据丢失且可以正确合并所有并发值。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（四）：编码与演化</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96/</link>
        <pubDate>Sun, 10 Jul 2022 03:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9B%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96/</guid>
        <description>&lt;h1 id=&#34;编码与演化&#34;&gt;编码与演化&lt;/h1&gt;
&lt;h2 id=&#34;数据编码格式&#34;&gt;数据编码格式&lt;/h2&gt;
&lt;p&gt;程序通常使用（ 至少）两种不同的数据表示形式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;在内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中。&lt;/strong&gt; 这些数据结构针对 CPU 高效访问和操作进行了优化（通常使用指针）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;将数据写入文件或通过网络发送时，必须将其编码为某种自包含的字节序列（例如 JSON 文档）。&lt;/strong&gt; 由于指针对其他进程没有意义，所以这个字节序列表示看起来与内存中使用的数据结构大不一样。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，在这两种表示之间需要进行类型的转化。从内存中的表示到字节序列的转化称为&lt;strong&gt;编码（或序列化）&lt;/strong&gt;，相反的过程称为&lt;strong&gt;解码（或解析，反序列化）&lt;/strong&gt; 。&lt;/p&gt;
&lt;h3 id=&#34;语言特定的格式&#34;&gt;语言特定的格式&lt;/h3&gt;
&lt;p&gt;许多编程语言都内建了将内存对象编码为字节序列的支持。例如，Java 有 &lt;code&gt;java.io.Serializable&lt;/code&gt; ，Ruby 有&lt;code&gt;Marshal&lt;/code&gt;，Python 有 &lt;code&gt;pickle&lt;/code&gt; 等等。许多第三方库也存在，例如 Java 的 Kryo。&lt;/p&gt;
&lt;p&gt;这些编码库非常方便，可以用很少的额外代码实现内存对象的保存与恢复。但是它们也有一些深层次的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;这类编码通常与特定的编程语言深度绑定，其他语言很难读取这种数据。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;为了在相同的对象类型中恢复数据，解码过程需要能够实例化任意的类。这经常导致一些安全问题&lt;/strong&gt;：如果攻击者可以让应用程序解码任意的字节序列，那么它们可以实例化任意的类，这通常意味着，它们可以做些可怕的 情，比如远程执行任意代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在这些库中，数据版本控制通常是事后才考虑的。&lt;/strong&gt; 因为它们旨在快速简便地对数据进行编码，所以往往忽略了前向后向兼容性带来的麻烦问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率（编码或解码所花费的CPU时间，以及编码结构的大小）往往也是事后才考虑的&lt;/strong&gt;。 例如，Java 的内置序列化由于其糟糕的性能和臃肿的编码而臭名昭着&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，除非临时使用，采用语言内置编码通常是一个坏主意。&lt;/p&gt;
&lt;h3 id=&#34;jsonxml与二进制变体&#34;&gt;JSON、XML与二进制变体&lt;/h3&gt;
&lt;p&gt;当我们谈到可以被多种编程语言读写的标准编码时，JSON 和 XML 是最显眼的角逐者。它们广为人知，广受支持，也广受憎恶。 XML 经常收到批评：过于冗长与且过份复杂。 JSON 的流行则主要源于 Web 浏览器的内置支持，以及相对于 XML 的简单性。 CSV 是另一种流行的与语言无关的格式，尽管其功能相对较弱。&lt;/p&gt;
&lt;p&gt;JSON，XML 和 CSV 属于文本格式，因此具有较高的可读性。除了表面的语法问题之外，它们也存在一些微妙的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数值编码多很多存在歧义的地方&lt;/strong&gt;。XML 和 CSV 不能区分数字和字符串（除非引用一个外部模式）。 JSON 虽然区分字符串与数值，但不区分整数和浮点数，而且不能指定精度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JSON 和 XML 对 Unicode 字符串有很好的支持，但是它们不支持二进制数据。&lt;/strong&gt; 二进制字符串是很有用的功能，所以人们通过使用 Base64 将二进制数据编码为文本来绕过此限制。其特有的模式标识着这个值应当被解释为 Base64 编码。这种方案虽然管用，但会增加 33% 的数据大小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XML 和 JSON 都有可选的模式支持。&lt;/strong&gt; 这些模式语言相当强大，所以学习和实现起来都相当复杂。 XML 模式的使用相当普遍，但许多基于 JSON 的工具才不会去折腾模式。由于对数据的正确解读取决于模式中的信息，因此不使用 XML/JSON 模式的应用程序可能需要对相应的编码/解码逻辑进行硬编码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CSV 没有任何模式，因此每行和每列的含义完全由应用程序自行定义。&lt;/strong&gt; 如果应用程序变更添加了新的行或列，那么这种变更必须通过手工处理。 CSV 也是一个相当模糊的格式。尽管其转义规则已经被正式指定，但并不是所有的解析器都能够正确的实现它们。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;thrift与protocol-buffers&#34;&gt;Thrift与Protocol Buffers&lt;/h3&gt;
&lt;p&gt;Apache Thrift 和 Protocol Buffers 是基于相同原理的二进制编码库。 Protocol Buffers 最初是在 Google 开发的，Thrift最初是在 Facebook 开发的，并且它们都是在 2007~2008 年开源的。&lt;/p&gt;
&lt;p&gt;Thrift 和 Protocol Buffers 都需要一个模式来编码任何数据，因此需要通过接口定义语言 IDL 描述模式。如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;// Thrift
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;struct Person {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    1: required string       userName,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    2: optional i64          favoriteNumber,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    3: optional list&amp;lt;string&amp;gt; interests
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;// Protocol Buffers
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;message Person {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    required string user_name       = 1;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    optional int64  favorite_number = 2;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    repeated string interests       = 3;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;avro&#34;&gt;Avro&lt;/h3&gt;
&lt;p&gt;Apache Avro 是另一种二进制编码格式，与 Protocol Buffers 和 Thrift 有着有趣的不同。由于 Thrift 不适合 Hadoop 的用例，因此它作为 Hadoop 的一个子项目在 2009 年开始启动。&lt;/p&gt;
&lt;p&gt;Avro 也使用模式来指定正在编码的数据的结构。 它有两种模式语言：一种（Avro IDL）用于人工编辑，一种（基于JSON）更易于机器读取。&lt;/p&gt;
&lt;p&gt;我们用 Avro IDL 编写的示例模式可能如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;record Person {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    string                userName;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    union { null, long }  favoriteNumber = null;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    array&amp;lt;string&amp;gt;         interests;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;该模式的等价 JSON 表示如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;record&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Person&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;fields&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;userName&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;string&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;favoriteNumber&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;null&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;long&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;interests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;array&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;&amp;#34;items&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;string&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;数据流模式&#34;&gt;数据流模式&lt;/h2&gt;
&lt;p&gt;进程间数据流动的常见方式有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;通过数据库&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通过服务调用（RPC、REST）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通过异步消息传递&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于数据库的数据流&#34;&gt;基于数据库的数据流&lt;/h3&gt;
&lt;p&gt;在数据库中，写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。可能只有一个进程访问数据库，在这种情况下， Reader 只是同一个进程的较新版本，此时，&lt;strong&gt;可以认为向数据库中存储内容，就是给未来的自己发送消息。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;基于服务的数据流&#34;&gt;基于服务的数据流&lt;/h3&gt;
&lt;p&gt;对于需要通过网络进行通信的进程，有许多不同的通信方式。最常见的是有两个角色：客户端和服务器。服务器通过网络公开 PI ，客户端可以连接到服务器以向该 API 发出请求。 服务器公开的 API 称为服务。&lt;/p&gt;
&lt;p&gt;Web 以这种方式工作：&lt;strong&gt;客户向 Web 服务器发出请求，通过 GET 请求下载 HTML，CSS，JavaScript，图像等，并通过 POST 请求提交数据到服务器。&lt;/strong&gt; API 包含一组标准的协议和数据格式（HTTP，URL，SSL/TLS，HTML 等）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;将大型应用程序按照功能区域分解为较小的服务，这样当一个服务需要来自另一个服务的某些功能或数据时，就会向另一个服务发出请求。&lt;strong&gt;这种构建应用程序的方式传统上被称为&lt;/strong&gt;面向服务的体系结构（service-oriented architecture，SOA）&lt;/strong&gt;，最近被改进和更名为&lt;strong&gt;微服务架构&lt;/strong&gt;。&lt;strong&gt;面向服务/微服务架构的一个关键设计目标是通过使服务独立部署和演化来使应用程序更易于更改和维护。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;web-服务restsoap&#34;&gt;Web 服务（REST、SOAP）&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;当服务使用 HTTP 作为底层通信协议时，可称之为 Web 服务&lt;/strong&gt;。这可能是一个小错误，因为 Web 服务不仅在 Web上使用，而且在几个不同的环境中使用。例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;运行在用户设备上的客户端应用程序通过 HTTP 向服务发出请求。&lt;/strong&gt; 这些请求通常通过公共互联网进行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一种服务向同一组织拥有的另一项服务提出请求&lt;/strong&gt;，这些服务通常位于同一数据中心内，作为面向服务/微型架构的一部分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一种服务通过互联网向不同组织所拥有的服务提出请求&lt;/strong&gt;。这用于不同组织后端系统之间的数据交换。此类别包括由在线服务提供的公共 API，或用于共享访问用户数据的 OAuth。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;有两种流行的 Web 服务方法：REST 和 SOAP：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;REST&lt;/strong&gt;：REST 不是一种协议，而是一个基于 HTTP 原则的设计理念。它强调简单的数据格式，使用 URL 来标识资源，并使用 HTTP 功能进行缓存控制 、身份验证和内容类型协商。根据 REST 原则所设计的 API 称为 RESTful。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SOAP&lt;/strong&gt;：SOAP 是一种基于 XML 的协议，用于发出网络 API 请求。虽然它最常用于 HTTP ，但其目的是独立于HTTP ，并避免使用大多数 HTTP功能。相反，它带有庞大 而复杂的多种相关标准（Web 服务框架， Web Service Framework ，称为WS-*）和新增的各种功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rpc&#34;&gt;RPC&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;RPC（Remote Procedure Call ）即远程过程调用，其试图向远程网络服务发出请求，看起来与在同一进程中调用编程语言中的函数或方法相同（这种抽象称为位置透明）。&lt;/strong&gt; RPC 主要侧重于同一组织内多项服务之间的请求，通常发生在同一个数据中心内。&lt;/p&gt;
&lt;p&gt;其与本地函数调用存在以下差异：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;本地函数调用是可预测的，并且成功或失败仅取决于受你控制的参数。而网络请求是不可预知的&lt;/strong&gt;。由于网络问题，请求或响应可能会丢失，或者远程计算机可能很慢或不可用，这些问题完全不在你的控制范围之内。网络问题是常见的，所以你必须预测他们，例如通过重试失败的请求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;本地函数调用要么返回结果，要么抛出异常，或者永远不返回（因为进入无限循环或进程崩溃）。网络请求有另一个可能的结果&lt;/strong&gt;。由于超时，它可能会返回没有结果。在这种情况下，如果你没有得到来自远程服务的响应，你无法知道请求是否通过。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如果重试失败的网络请求，可能会发生请求实际上已经完成，但是响应丢失。在这种情况下，重试将导致该操作被执行多次。&lt;/strong&gt; 除非你在协议中引入去重机制（&lt;strong&gt;幂等&lt;/strong&gt;）。本地函数调用没有这个问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;每次调用本地函数时，通常需要大致相同的时间来执行。网络请求比函数调用要慢得多，而且其延迟也是非常可变的&lt;/strong&gt;。好的时候它可能会在不到一毫秒的时间内完成，但是当网络拥塞或者远程服务超载时，可能需要几秒钟的时间完成一样的东西。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。&lt;/strong&gt; 如果参数是像数字或字符串这样的基本类型倒是没关系，但是对于较大的对象很快就会变成问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;客户端和服务可以用不同的编程语言实现，所以 RPC 框架必须将数据类型从一种语言翻译成另一种语言&lt;/strong&gt;。这可能会捅出大篓子，因为不是所有的语言都具有相同的类型 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于消息传递的数据流&#34;&gt;基于消息传递的数据流&lt;/h3&gt;
&lt;p&gt;它与 RPC 的相似之处在于，客户端的请求（通常称为消息）以低延迟传递到另一个进程。它与基于数据库的方式的相似之处在于，不是通过直接的网络连接发送消息，而是通过称为消息队列的中介发送的， 该中介会暂存消息。&lt;/p&gt;
&lt;p&gt;使用异步消息传递存在以下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;如果接收方不可用或过载，可以充当缓冲区，从而提高系统的可靠性。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;它可以自动将消息重新发送到已经崩溃的进程，从而防止消息丢失。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;避免发送方需要知道接收方的 IP 地址和端口号（这在虚拟机经常启启停停的云部署中特别有用）。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;它允许将一条消息发送给多个接收方。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;将发送方与接收方逻辑分离（发送方只是发布消息，不关心使用者）。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与 RPC 的差异在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;消息传递通信通常是单向的&lt;/strong&gt;：发送方通常不期望收到对其消息的回复 。进程可能发送一个响应，但这通常是在一个独立的通道上完成的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;这种通信模式是异步的&lt;/strong&gt; ：发送者不会等待消息被传递，而只是发送然后忘记它。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;消息队列&#34;&gt;消息队列&lt;/h4&gt;
&lt;p&gt;详细的交付语义因实现和配置而异，但通常情况下，消息队列的使用方式如下：&lt;strong&gt;一个进程将消息发送到指定的队列或主题，代理确保将消息传递给那个队列或主题的一个或多个消费者或订阅者&lt;/strong&gt;。在同一主题上可以有许多生产者和许多消费者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一个主题只提供单向数据流。&lt;/strong&gt; 但是，消费者本身可能会将消息发布到另一个主题上（因此，可以将它们链接在一起，就像我们将在中看到的那样），或者发送给原始消息的发送者使用的回复队列（允许请求/响应数据流，类似于 RPC）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息代理通常不会执行任何特定的数据模型 —— 消息只是包含一些元数据的字节序列，因此你可以使用任何编码格式。&lt;/strong&gt; 如果编码是向后和向前兼容的，你可以灵活地对发布者和消费者的编码进行独立的修改，并以任意顺序进行部署。&lt;/p&gt;
&lt;h4 id=&#34;分布式actor框架&#34;&gt;分布式Actor框架&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Actor 模型是单个进程中并发的编程模型。逻辑被封装在 Actor 中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）。&lt;/strong&gt; 每个 Actor 通常代表一个客户或实体，它可能有一些本地状态（不与其他任何角色共享），它通过发送和接收异步消息与其他角色通信。**不保证消息传送：在某些错误情况下，消息将丢失。**由于每个角色一次只能处理一条消息，因此不需要担心线程，每个角色可以由框架独立调度。&lt;/p&gt;
&lt;p&gt;在分布式 Actor 框架中，此编程模型用于跨多个节点伸缩应用程序。不管发送方和接收方是在同一个节点上还是在不同的节点上，都使用相同的消息传递机制。如果它们在不同的节点上，则该消息被透明地编码成字节序列，通过网络发送，并在另一侧解码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分布式的 Actor 框架实质上是将消息队列和 Actor 编程模型集成到一个框架中。&lt;/strong&gt; 但是，如果要执行基于 Actor 的应用程序的滚动升级，则仍然需要担心向前和向后兼容性问题，因为消息可能会从运行新版本的节点发送到运行旧版本的节点，反之亦然。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（三）：存储与检索</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2/</link>
        <pubDate>Sun, 10 Jul 2022 02:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2/</guid>
        <description>&lt;h1 id=&#34;存储与检索&#34;&gt;存储与检索&lt;/h1&gt;
&lt;h2 id=&#34;核心存储结构&#34;&gt;核心存储结构&lt;/h2&gt;
&lt;h3 id=&#34;哈希&#34;&gt;哈希&lt;/h3&gt;
&lt;p&gt;K-V 存储与大多数编程语言所内置的字典结构非常相似，通常采用&lt;strong&gt;哈希表（hash table）&lt;/strong&gt; 来实现。那如果我们想将其拓展到磁盘存储索引，该如何去做呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;保存内存中的哈希表，把每个键一一映射到数据文件中特定的字节偏移，这样就可以找到每个值的位置。&lt;/strong&gt; 每当在文件中追加新的数据，还要更新哈希表来反映刚刚写入数据的偏移量 （包括插入新的键和更新已有的键）。 查找某个值时，使用哈希表来找到文件中的偏移量，即存储位置，然后读取其内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只要所有的 key 可以放入内存（因为哈希表需要保存在内存中），value 的数据量则可以超过内存大小，只需一次磁盘寻址，就可以将 value 从磁盘加载到内存。&lt;/strong&gt; 如果那部分数据文件已经在文件系统的缓存中，则读取根本不需要任何的磁盘 I/O。&lt;/p&gt;
&lt;p&gt;如果只追加到一个文件，那么很有可能导致磁盘空间用尽。因此通常将日志分解成一定大小的段，当文件达到一定大小时就关闭它，井将后续写入到新的段文件中。&lt;/p&gt;
&lt;p&gt;此外，由于压缩往往使得段更小（假设键在段内被覆盖多次），也可以在执行压缩的同时将多个段合并在一起。&lt;/p&gt;
&lt;p&gt;每个段现在都有自己的内存哈希表，将键映射到文件的偏移量。为了找到键的值，首先检查最新的段的哈希表；如果键不存在，检查第二最新的段，以此类推。由于合并过程可以维持较少的段数，因此查找通常不需要检查很多哈希表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;追加和分段合并主要是顺序写，它通常比随机写入快得多，特别是在 HDD 上。&lt;/li&gt;
&lt;li&gt;如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。&lt;/li&gt;
&lt;li&gt;合并旧段可以避免随着时间的推移数据文件出现碎片化的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;哈希表必须全部放入内存，随着数据越来越多，哈希冲突解决的成本会越来越高。&lt;/li&gt;
&lt;li&gt;区间查询效率不高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sstable与lsm-tree&#34;&gt;SSTable与LSM-Tree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;将日志结构的存储段中的 key-value 顺序按键排序。&lt;strong&gt;这种结构称为&lt;/strong&gt;排序字符串表（SSTable）&lt;/strong&gt;。它要求每个键在每个合并的段文件中只能出现一次。&lt;/p&gt;
&lt;p&gt;SSTable 相比哈希索引的日志段，具有以下优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;合并段更加简单高效，即使文件大于可用内存。&lt;/li&gt;
&lt;li&gt;在文件中查找特定的键时，不再需要在内存中保存所有键的索引。&lt;/li&gt;
&lt;li&gt;由于读请求往往需要扫描请求范围内的多个 key-value 对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sstable的构建与维护&#34;&gt;SSTable的构建与维护&lt;/h4&gt;
&lt;p&gt;基本工作流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当写入时，将其添加到内存中的平衡树数据结构中（例如红黑树）。这个内存中的树有时被称为内存表。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当内存表大于某个阈值（通常为几兆字节）时，将其作为 SSTable 文件写入磁盘。由于树已经维护了按键排序的 key-value 对， 磁盘可以比较高效。新的 SSTable 文件成为数据库的最新部分。当 SSTable 写磁盘的同时，写入可以继续添加到一个新的内存表实例。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标（或为空）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后台进程周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果数据库崩溃，最近的写入（在内存表中但尚未写入磁盘）将会丢失。为了避免该问题，可以在磁盘上保留单独的日志（WAL 日志），每个写入都会立即追加到该日志。每当将内存表写入 SSTable 时，则相应的日志可以被丢弃。&lt;/p&gt;
&lt;h4 id=&#34;优化&#34;&gt;优化&lt;/h4&gt;
&lt;p&gt;LSM-Tree 的一些优化措施如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;布隆过滤器&lt;/strong&gt;：在确定键不存在之前，必须先检查内存表，然后将段一直回溯访问到最旧的段文件（可能必须从磁盘多次读取）。为了优化这种访问，存储引擎通常使用额外的布隆过滤器，其用于近似计算集合的内容。如果数据库中不存在某个键，它能够很快告诉你结果，从而节省了很多对于不存在的键的不必要的磁盘读取。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分层压缩与大小分级&lt;/strong&gt;：在大小分级的压缩中，较新的和较小的 SSTable 被连续合并到较旧和较大的 SSTable 。在分层压缩中，键的范围分裂成多个更小的 SSTable，旧数据被移动到单独的层级，这样压缩可以逐步进行并节省磁盘空间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;b-tree&#34;&gt;B-Tree&lt;/h3&gt;
&lt;p&gt;B-Tree 将数据库分解成固定大小的块或页（页是内部读/写的最小单元），传统页的大小为 4 KB。这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列。&lt;/p&gt;
&lt;p&gt;每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，类似指针，不过是指向磁盘地址，而不是内存。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia21.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;某一个页被指定为 B-Tree 的根，每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。&lt;/p&gt;
&lt;p&gt;例如上图即是一个查询，假定正在查找键 251，因此需要沿着 200~300 间的页引用，到达类似的页，它进一步将 200~300 范围分解成子范围。最终，我们到达一个包含单个键的页（叶子页），该页包含每个内联键的值或包含可以找到值的页的引用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia22.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图。如果要更新 B-Tree 中现有键的值，首先搜索包含该键的叶子页，更改该页的值，并将页写回到磁盘（对该页的任何引用仍然有效）。如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页也需要更新以包含分裂之后的新的键范围。&lt;/p&gt;
&lt;h4 id=&#34;预写日志&#34;&gt;预写日志&lt;/h4&gt;
&lt;p&gt;为了使数据库能从崩溃中恢复，常见 B-Tree 实现需要支持磁盘上的额外的数据结构：&lt;strong&gt;预写日志（write-ahead log, WAL ）&lt;strong&gt;也称重做日志（Redo-log）。这是一个&lt;/strong&gt;仅支持追加修改&lt;/strong&gt;的文件，每个 B-tree 的修改必须先更新 WAL 然后再修改树本身的页。当数据库在崩溃后需要恢复 ，该日志用于将B-tree 恢复到最近一直的状态。&lt;/p&gt;
&lt;h4 id=&#34;优化-1&#34;&gt;优化&lt;/h4&gt;
&lt;p&gt;B-Tree 常见的一些优化措施如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;一些数据库（如 LMDB）不使用覆盖页和维护 WAL 来进行崩溃恢复，而是使用写时拷贝方案 。&lt;/strong&gt; 修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;保存键的缩略信息，而不是完整的键，这样可以节省页空间。&lt;/strong&gt; 特别是在树中间的页中，只需要提供足够的信息来描述键的起止范围。这样可以将更多的键压入到页中，让树具有更高的分支因子，从而减少层数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;许多 B-Tree 的实现尝试对树进行布局，以便相邻叶子页可以按顺序保存在磁盘上。&lt;/strong&gt; 这主要由于页可以放在磁盘上的任何位置；没有要求相邻的页需要放在磁盘的相邻位置。如果查询需要按照顺序扫描大段的键范围，考虑到每个读取的页都可能需要磁盘 I/O，所以逐页的布局可能是低效的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;添加额外的指针到树中。&lt;/strong&gt; 例如，每个叶子页面可能会向左和向右引用其同级的兄弟页，这样可以顺序扫描键，而不需要跳回到父页。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B-Tree 的变体如分形树借鉴了一些日志结构的想法也来减少磁盘寻道。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事务处理与分析处理&#34;&gt;事务处理与分析处理&lt;/h2&gt;
&lt;p&gt;即使数据库开始被用于许多不同类型的数据，比如博客文章的评论，游戏中的动作，地址簿中的联系人等等，基本的访问模式仍然类似于处理商业交易。应用程序通常使用索引通过某个键查找少量记录。根据用户的输入插入或更新记录。由于这些应用程序是交互式的，这种访问模式被称为&lt;strong&gt;在线事务处理（OLTP, OnLine Transaction Processing）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;数据库也开始越来越多地用于数据分析，这些数据分析具有非常不同的访问模式。通常，分析查询需要扫描大量记录，每个记录只读取几列，并计算汇总统计信息（如计数、总和或平均值），形成报告以帮助公司管理层做出更好的决策（商业智能）。这种访问模式被称为&lt;strong&gt;在线分析处理（OLAP, OnLine Analytice Processing）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;OLTP 和 OLAP 之间的区别如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;属性&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;事务处理 OLTP&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;分析处理 OLAP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主要读取模式&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;查询少量记录，按键读取&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;在大批量记录上聚合&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主要写入模式&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;随机访问，写入要求低延时&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;批量导入（ETL）或者事件流&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主要用户&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;终端用户，通过Web应用&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;内部数据分析师，用于决策支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;处理的数据&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;数据的最新状态（当前时间点）&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;随时间推移的历史事件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;数据集尺寸&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;GB ~ TB&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;TB ~ PB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;数据仓库&#34;&gt;数据仓库&lt;/h3&gt;
&lt;p&gt;起初，事务处理和分析查询使用了相同的数据库。 SQL 被证明是非常灵活的，可以同时胜任 OLTP 类型和OLAP 类型查询 。尽管如此，在二十世纪八十年代末和九十年代初期，企业有停止使用 OLTP 系统进行分析的趋势，转而在单独的数据库上运行分析。这个单独的数据库被称为&lt;strong&gt;数据仓库（data warehouse）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;考虑到直接在 OLTP 数据库上运行临时的分析查询的开销特别大（会扫描大部分数据集），这可能会损害并发执行事务的性能。因此，数据仓库是一个独立的数据库，分析人员可以查询他们想要的内容而不影响 OLTP 操作。&lt;/p&gt;
&lt;p&gt;数据仓库包含公司各种 OLTP 系统中所有的只读数据副本。从 OLTP 数据库中提取数据（使用定期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存入仓库的过程称为&lt;strong&gt;抽取-转换-加载（ETL）&lt;/strong&gt;。具体流程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;雪花模型与星型模型&#34;&gt;雪花模型与星型模型&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;事实表&lt;/strong&gt;的每一行代表在特定时间发生的事件。而它的一些列是属性，例如产品销售的价格和从供应商那里购买的成本（可以用来计算利润余额）。其他列可能会引用其他表的外键，称为&lt;strong&gt;维度表&lt;/strong&gt;。由于&lt;strong&gt;事实表中的每一行都代表一个事件，维度通常代表事件的对象（who）、什么（what）、地点（where）、时间（when）、方法（how）以及原因（why）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;星型模式这个名字的来源是当我们对表之间的关系进行可视化时，&lt;strong&gt;事实表在中间，被维度表包围&lt;/strong&gt;；与这些表的连接就像星星的光芒。例如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;这个模板的变体被称为&lt;strong&gt;雪花模式&lt;/strong&gt;，&lt;strong&gt;维度被进一步分解为子维度&lt;/strong&gt;。例如，品牌和产品类别可能有单独的表格，并且 &lt;code&gt;dim_product&lt;/code&gt; 表格中的每一行都可以将品牌和类别作为外键引用，而不是将它们作为字符串存储在 &lt;code&gt;dim_product&lt;/code&gt; 表格中。雪花模式比星形模式更规范化，但是星形模式通常是首选，因为它使用起来更简单。&lt;/p&gt;
&lt;h2 id=&#34;列式存储&#34;&gt;列式存储&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在传统的按行存储的数据库中，当用户需要查询某个特定列的时候，即使我们已经建立了索引，但是存储引擎仍然会将这些行数据（可能有上百个字段）完整的从硬盘加载到内存中，并对它们进行解析、条件过滤，这需要花费大量的时间。在一些大数据的场景下，事实表中可能会有万亿行和数 PB 的数据，此时按行存储很明显是不可用的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;列式存储背后的想法很简单：不要将所有来自一行的值存储在一起，而是将来自每一列的所有值存储在一起。如果每个列存储在一个单独的文件中，查询只需要读取和解析查询中使用的那些列，这可以节省大量的工作，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia25.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;列式存储布局依赖于一组列文件，每个列文件以相同顺序的顺序存储行数据。 因此，如果需要重新组装完整的行，可以从每个单独的列文件中获取对应的那一行，并将它们放在一起形成完整的行。&lt;/p&gt;
&lt;h3 id=&#34;压缩&#34;&gt;压缩&lt;/h3&gt;
&lt;p&gt;由于同一列中的数据类型相同，因此我们可以通过压缩数据来进一步降低对硬盘吞吐量的要求。在数据仓库中，通常使用位图编码来压缩数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;通常情况下，一列中不同值的数量要远远小于它的行数。我们假设某一列中有 n 种不同的值，此时我们就可以将其转换为 n 个位图，位图中对应位置用 0 和 1 标识该行是否存在这个值（即列中每个值对应一个位图，每行对应一个比特位）。&lt;/p&gt;
&lt;p&gt;考虑到 n 可能会很大，此时位图中存储的 1 可能会较为稀疏（浪费空间），这时就可以另外对位图进行游程编码，如图的下半部分所示。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;内存带宽&lt;/strong&gt;：对于需要扫描数百万行的数据仓库查询来说，一个巨大的瓶颈是从硬盘获取数据到内存的带宽。但是，这不是唯一的瓶颈。分析型数据库的开发人员还需要有效地利用主存储器到 CPU 缓存的带宽，避免 CPU 指令处理流水线中的分支预测错误和气泡，以及在现代 CPU 上使用单指令多数据（SIMD）指令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;矢量化处理&lt;/strong&gt;：列式存储布局可以更有效的利用 CPU 周期。查询引擎可以将大量压缩的列数据放在 CPU 的 L1 缓存中，然后在紧密的循环（即没有函数调用）中遍历。相比较于每个记录的处理都需要大量函数调用和条件判断的代码，CPU 执行这样一个循环要快得多。列压缩允许列中的更多行被放进相同数量的 L1 缓存。前面描述的按位 “与” 和 “或” 运算符可以被设计为直接在这样的压缩列数据块上操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;排序&#34;&gt;排序&lt;/h3&gt;
&lt;p&gt;对于列式存储来说，按照插入顺序来存储数据是最简单的，因为我们只需要将插入行的数据追加到各个列文件中即可。但是考虑到查询、压缩的效率，通常我们会选择几个列作为排序列，所有列文件以该列为标准来排序数据。&lt;/p&gt;
&lt;p&gt;最常见的做法是依据我们的查询条件来指定，例如在经常以时间来筛选的场景，就可以将时间设定为第一个排序 key，这样在查询的时候，我们就能够缩小扫描的范围，只锁定对应时间周期的数据。接着，我们可以将数据的特征等信息作为第二、三个排序 key，这样就能够帮助我们更加精准的进行查询、分组、聚合。&lt;/p&gt;
&lt;p&gt;排序还有另一个好处，就是在排序完成后，相同的数据会连续存储。这时再采用一些压缩算法（例如前面提到的游程编码），就可以极大的节省空间。&lt;/p&gt;
&lt;h3 id=&#34;写入&#34;&gt;写入&lt;/h3&gt;
&lt;p&gt;对于列式存储来说，使用类似于 B+ 树那样原地更新的方法是不可行的，这不仅意味着我们需要先对数据进行解码，如果数据插入在中间位置，还需要在全部列文件中向后偏移该行以后的所有数据，效率十分低下。&lt;/p&gt;
&lt;p&gt;基于以上原因，列式存储通常采用类似 LSM 树那样的存储结构。即所有的写入首先会存储到内存中的 MemTable 中（红黑树、跳表、AVL 树等结构），当 MemTable 达到一定的大小后，此时就会将数据写入到磁盘中，与原有的列数据进行合并（保留最新的），并批量写入到新文件中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在查询的时候其实也是分别查询磁盘结构和内存结构后合并查询结果，但是查询优化器向用户隐藏了这个细节。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;聚合物化视图与数据立方体&#34;&gt;聚合：物化视图与数据立方体&lt;/h3&gt;
&lt;p&gt;数据仓库的查询通常会涉及聚合函数，如 SQL 中的 &lt;code&gt;COUNT&lt;/code&gt;、&lt;code&gt;SUM&lt;/code&gt;、&lt;code&gt;AVG&lt;/code&gt;、&lt;code&gt;MIN&lt;/code&gt; 或 &lt;code&gt;MAX&lt;/code&gt;。为了避免每次查询时都对原始数据进行一次聚合计算，通常会将一些频繁使用的聚合结果给缓存下来。&lt;/p&gt;
&lt;p&gt;创建这种缓存的一种方式是&lt;strong&gt;物化视图（Materialized View）&lt;/strong&gt;。在关系数据模型中，它通常被定义为一个标准（虚拟）视图：**一个类似于表的对象，其内容是一些查询的结果。**不同的是，&lt;strong&gt;物化视图是查询结果的实际副本，会被写入硬盘，而虚拟视图只是编写查询的一个捷径。从虚拟视图读取时，SQL 引擎会将其展开到视图的底层查询中，然后再处理展开的查询。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当底层数据发生变化时，物化视图就需要更新，因为它是数据的非规范化副本。虽然数据库可以自动完成该操作，但是这样的更新使得写入的成本更高，这就是在 OLTP 数据库中不经常使用物化视图的原因，而在读取频繁的 OLAP 数据仓库中，它们的作用就体现了出来。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;物化视图常见的一种特殊实现被称为数据立方体或 OLAP 立方体，它是按不同维度分组的聚合网格，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia27.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;数据立方体的优点是其提前计算好了一些聚合的结果，可以让一些查询变得非常快，但同时也因为它没有保留原始数据，不具有查询原始数据的灵活性，所以它通常作为提升查询性能的优化手段。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（二）：数据模型与查询语言</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/</link>
        <pubDate>Sun, 10 Jul 2022 01:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/</guid>
        <description>&lt;h1 id=&#34;数据模型与查询语言&#34;&gt;数据模型与查询语言&lt;/h1&gt;
&lt;h2 id=&#34;关系模型与文档模型&#34;&gt;关系模型与文档模型&lt;/h2&gt;
&lt;p&gt;现在最著名的数据模型可能是 &lt;strong&gt;SQL&lt;/strong&gt; ，它基于 Edgar Codd 在 1970 年提出的关系模型： &lt;strong&gt;数据被组织成关系（在 SQL 中称为表），其中每个关系都是元组的无序集合（SQL 中称为行）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;关系模型的目标就是&lt;strong&gt;将实现细节隐藏在更简洁的接口后面&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;nosql的诞生&#34;&gt;NoSQL的诞生&lt;/h3&gt;
&lt;p&gt;NoSQL最常见的解释是 Non-Relationa，而如今又使用  Not Only SQL 来对其进行解释。NoSQL 其实并不代表具体的某些技术，它仅仅是一个概念，泛指非关系型的数据库，区别于关系数据库，&lt;strong&gt;它们不保证关系数据的ACID特性&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;采用 NoSQL 数据库有这样几个驱动因素 ，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比关系数据库更好的扩展性需求，包括支持超大数据集或超高写入吞吐量。&lt;/li&gt;
&lt;li&gt;普遍偏爱免费和开源软件而不是商业数据库产品。&lt;/li&gt;
&lt;li&gt;关系模型不能很好地支持一些特定的查询操作。&lt;/li&gt;
&lt;li&gt;对关系模式一些限制性感到沮丧，渴望更具动态和表达力数据模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;对象-关系不匹配&#34;&gt;对象-关系不匹配&lt;/h3&gt;
&lt;p&gt;如今大多数应用开发都采用面向对象的编程语言，由于兼容性问题，普遍对 SQL 数据模型存在抱怨：&lt;strong&gt;如果数据存储在关系表中，那么应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层。&lt;strong&gt;这种模型之间的脱离被称为&lt;/strong&gt;阻抗失谐&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;像 ActiveRecord 和 Hibernate 这样的&lt;strong&gt;对象关系映射（ORM，Object-Relational Mapping）&lt;/strong&gt; 框架减少了此转换 层的样板代码 ，但是他们并不能完全隐藏两个模型之间的差异。&lt;/p&gt;
&lt;p&gt;例如我们使用关系模型来描述一个简历：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;对于简历这种用户与经历这种一对多的关系，我们可以用多种方法表示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统的 SQL 模型，将职位、教育和联系信息放在单独的表中并使用外键引用 users 表。&lt;/li&gt;
&lt;li&gt;SQL 标准增加了对结构化数据类型和 XML 数据的支持。这允许将多值数据存储在单行，井支持在这些文档中查询和索引。&lt;/li&gt;
&lt;li&gt;将信息编码为 JSON、XML 文档，将其存储在数据库的文本列中，并由应用程序解释其结构和内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于像简历这样的数据结构，它主要是一个自包含的文档，因此用 JSON 表示更加合适。代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;user_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;251&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;first_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bill&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;last_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Gates&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;summary&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Co-chair of the Bill &amp;amp; Melinda Gates... Active blogger.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;region_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;us:91&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;industry_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;131&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;photo_url&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/p/7/000/253/05b/308dd6e.jpg&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;positions&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;job_title&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Co-chair&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;organization&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Bill &amp;amp; Melinda Gates Foundation&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;job_title&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Co-founder, Chairman&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;organization&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Microsoft&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;education&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;school_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Harvard University&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1973&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;end&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1975&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;school_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Lakeside School, Seattle&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;nt&#34;&gt;&amp;#34;end&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;contact_info&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;blog&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://thegatesnotes.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;#34;twitter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;http://twitter.com/BillGates&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;JSON 模型减少了应用程序代码和存储层之间的阻抗失配，并且其比起关系模式的多表查询具有更好的局部性，其所有的相关信息都在一个地方，所以一次查询就足够了，因此大部分文档数据库都支持这种模型。&lt;/p&gt;
&lt;h3 id=&#34;数据模型&#34;&gt;数据模型&lt;/h3&gt;
&lt;h4 id=&#34;层次模型&#34;&gt;层次模型&lt;/h4&gt;
&lt;p&gt;层次模型与文档数据库使用的 JSON 模型有一些显著的相似之处。&lt;strong&gt;它将所有数据表示为嵌套在记录中的记录（树）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;层次模型可以很好地支持一对多关系，但是它支持多对多关系则有些困难，而且不支持联结。开发人员必须决定是复制（反规范化）多份数据，还是手动解析记录之间的引用。&lt;/p&gt;
&lt;p&gt;为了解决层次模型的局限性，之后又提出了多种解决方案。其中最著名的是&lt;strong&gt;关系模型（relational model）&lt;strong&gt;和&lt;/strong&gt;网络模型（network model）&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;网络模型&#34;&gt;网络模型&lt;/h4&gt;
&lt;p&gt;网络模型由一个称为数据系统语言会议（Conference on Data System Languages, CODASYL）的委员会进行标准化，井由多个不同的数据库厂商实施，它也被称为 CODASYL 模型。&lt;/p&gt;
&lt;p&gt;网络模型是层次模型的推广。在层次模型的树结构中，每个记录只有一个父节点；&lt;strong&gt;而在网络模型中， 一个记录可能有多个父结点，从而支持对多对一和多对多的关系进行建模。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针（会存储在磁盘上），访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。这条链接链条也因此被称为&lt;strong&gt;访问路径&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;网络模型中的查询通过遍历记录列表，并沿着访问路径在数据库中移动游标来执行。如果记录有多个父结点，应用程序代码必须跟踪所有关系。因此其最大的问题在于它们使查询和更新数据库变得异常复杂而没有灵活性。&lt;/p&gt;
&lt;h4 id=&#34;关系模型&#34;&gt;关系模型&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系模型所做的则是定义了所有数据的格式：关系（表）只是元组（行）集合。&lt;/strong&gt; 没有复杂的嵌套结构，也没有复杂的访问路径。可以读取表中的任何一行或者所有行，支持任意条件查询。可以指定某些列作为键并匹配这些列来读取特定行。可以在任何表中插入新行，而不必担心与其他表之间的外键关系。&lt;/p&gt;
&lt;p&gt;在关系数据库中，查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些选择实际上等价于访问路径 但最大的区别在于它是由查询优化器自动生成的，而不是由应用开发人员所维护，因此不用过多地考虑它。&lt;/p&gt;
&lt;h2 id=&#34;数据查询语言&#34;&gt;数据查询语言&lt;/h2&gt;
&lt;h3 id=&#34;声明式命令式查询语言&#34;&gt;声明式/命令式查询语言&lt;/h3&gt;
&lt;p&gt;数据查询语言通常分为以下两类：&lt;strong&gt;命令式查询语言、声明式查询语言。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;命令式查询语言&lt;/strong&gt;：&lt;strong&gt;其会告诉计算机以特定顺序执行某些操作。&lt;/strong&gt; 因此我们完全可以推理整个过程，逐行遍历代码、评估相关条件、更新对应的变量，并决定是否再循环一遍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;声明式查询语言&lt;/strong&gt;：&lt;strong&gt;只需指定所需的数据模式，结果需满足什么条件，以及如何转换数据（例如，排序、分组和聚合），而不需指明如何实现这些目标。&lt;/strong&gt; 数据库系统的查询优化器会决定采用哪些索引和联结，以及用何种顺序来执行查询的各个语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;声明式查询语言很有吸引力，它比命令式 API 更加简洁和容易使用。但更重要的是，它对外隐藏了数据库引擎的很多实现细节，这样数据库系统能够在不改变查询语句的情况下提高性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;声明式语言通常适合于并行执行。&lt;/strong&gt; 现在 CPU 提升速度的方式是增加核心数，而不是实现比之前更高的时钟频率。而命令式代码由于指定了特定的执行顺序，很难在多核和多台机器上并行。声明式语言则对于并行执行更加友好，它们仅指定了结果所满足的模式，而不指定如何得到结果的具体算法。&lt;/p&gt;
&lt;h3 id=&#34;mapreduce查询&#34;&gt;MapReduce查询&lt;/h3&gt;
&lt;p&gt;MapReduce 是一种编程模型，用于在许多机器上批量处理海量数据，兴起于 Google。一些 NoSQL 存储系统（包括 MongoDB 和 CouchDB）支持有限的 MapReduce 方式在大量文档上执行只读查询。&lt;/p&gt;
&lt;p&gt;MapReduce 既不是声明式查询语言，也不是一个完全命令式的查询 API，而是介于两者之间：查询的逻辑用代码片段来表示，这些代码片段可以被处理框架重复地调用。它主要基于许多函数式编程语言中的 &lt;code&gt;map&lt;/code&gt; 和 &lt;code&gt;reduce&lt;/code&gt; 函数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设你是一名海洋生物学家，每当你看到海洋中的动物时，你都会在数据库中添加一条观察记录。现在你想生成一个报告，说明你每月看到多少鲨鱼&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果使用 SQL 来表示，代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;date_trunc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;month&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observation_timestamp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observation_month&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_animals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                           &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;total_animals&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observations&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;family&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Sharks&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;GROUP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observation_month&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;而如果使用 MongoDB 的 MapReduce 功能，则可以按如下来表述：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;db.observations.mapReduce(
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	function map() {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        var year = this.observationTimestamp.getFullYear();
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        var month = this.observationTimestamp.getMonth() + 1;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        emit(year + &amp;#34;-&amp;#34; + month, this.numAnimals);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    function reduce(key, values) {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        return Array.sum(values);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        query: {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          family: &amp;#34;Sharks&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        out: &amp;#34;monthlySharkReport&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;MapReduce 函数对于可执行的操作有所限制。它必须是纯函数，这意味着只能使用传递进去的数据作为输入，而不能执行额外的数据库查询，也不能有任何副作用。这些限制使得数据库能够在任何位置、以任意顺序来运行函数，并在失败时重新运行这些函数。&lt;/p&gt;
&lt;h2 id=&#34;图状数据模型&#34;&gt;图状数据模型&lt;/h2&gt;
&lt;p&gt;图由两种对象组成：&lt;strong&gt;顶点（也称为结点或实体）&lt;strong&gt;和&lt;/strong&gt;边（也称为关系或弧）&lt;/strong&gt;。很多数据可以建模为图。典型的例子包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;社交网络&lt;/strong&gt;：顶点是人，边指示哪些人彼此认识。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web 图&lt;/strong&gt;：顶点是网页，边表示与其他页面的 HTML 链接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;公路或铁路网&lt;/strong&gt;：顶点是交叉路口，边表示他们之间的公路或铁路线。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下图，即使用图来存储族谱信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.orekilee.top//imgbed/ddia/ddia19.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;属性图&#34;&gt;属性图&lt;/h3&gt;
&lt;p&gt;在属性图模型中，每个顶点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;唯一的标识符。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;出边的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;入边的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;属性的集合（键值对） 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个边包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;唯一的标识符。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;边开始的顶点（尾部顶点） 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;边结束的顶点（头部顶点） 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;描述两个顶点间关系类型的标签。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;属性的集合（键-值对）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**可以将图存储看作由两个关系表组成，一个用于顶点， 另一个用于边。**如下列代码使用关系模式来标识属性图：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;INTEGER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edge_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;INTEGER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;PRIMARY&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;KEY&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;INTEGER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;REFERENCES&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;INTEGER&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;REFERENCES&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;TEXT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges_tails&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;INDEX&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges_heads&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;对于图模型还有一些值得注意的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任何顶点都可以连接到其他任何顶点。没有模式限制哪种事物可以或不可以关联。&lt;/li&gt;
&lt;li&gt;给定某个顶点，可以高效地得到它的所有人边和出边，从而遍历图，即沿着这些顶点链条一直向前或向后。&lt;/li&gt;
&lt;li&gt;通过对不同类型的关系使用不同的标签，可以在单个图中存储多种不同类型的信息，同时仍然保持整洁的数据模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cypher查询语言&#34;&gt;Cypher查询语言&lt;/h3&gt;
&lt;p&gt;Cypher 是一种用于属性图的声明式查询语言，最早为 Neo4j 图形数据库而创建。&lt;/p&gt;
&lt;p&gt;来看看一个创建的代码示例，每个顶点都有一个像 USA、Idaho 这样的名称，查询可以使用这些名称创建顶点之间的边，如使用箭头符号： &lt;code&gt;(Idaho) -[:WITHIN]-&amp;gt;  (USA)&lt;/code&gt; 创建一个标签为 &lt;code&gt;WITHIN&lt;/code&gt; 边，其中 &lt;code&gt;Idaho&lt;/code&gt; 为尾结点， &lt;code&gt;USA&lt;/code&gt; 为头结点。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CREATE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (NAmerica:Location {name:&amp;#39;North America&amp;#39;, type:&amp;#39;continent&amp;#39;}),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (USA:Location      {name:&amp;#39;United States&amp;#39;, type:&amp;#39;country&amp;#39;  }),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (Idaho:Location    {name:&amp;#39;Idaho&amp;#39;,         type:&amp;#39;state&amp;#39;    }),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (Lucy:Person       {name:&amp;#39;Lucy&amp;#39; }),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (Idaho) -[:WITHIN]-&amp;gt;  (USA)  -[:WITHIN]-&amp;gt; (NAmerica),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (Lucy)  -[:BORN_IN]-&amp;gt; (Idaho)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接下来看一个使用 MATCH 语句的查询示例（查询从美国移民到欧洲的人员名单），其使用与上面相同的箭头语义：&lt;code&gt;(person) -[:BORN_IN]-&amp;gt; ()&lt;/code&gt; 即匹配所有顶点间带有标签 &lt;code&gt;BORN_IN&lt;/code&gt; 的边，且尾部顶点对应于变量 &lt;code&gt;person&lt;/code&gt; ，而头部顶点则没有要求。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MATCH
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (person) -[:BORN_IN]-&amp;gt;  () -[:WITHIN*0..]-&amp;gt; (us:Location {name:&amp;#39;United States&amp;#39;}),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  (person) -[:LIVES_IN]-&amp;gt; () -[:WITHIN*0..]-&amp;gt; (eu:Location {name:&amp;#39;Europe&amp;#39;})
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RETURN person.name
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;该代码会匹配所有满足以下两个条件的任何顶点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;person&lt;/code&gt; 有一个到其他顶点的出边 &lt;code&gt;BORN_IN&lt;/code&gt; 。从该顶点开始，可以沿着一系列出边 &lt;code&gt;WITHIN&lt;/code&gt;，直到最终到达类型为 &lt;code&gt;Location&lt;/code&gt; 的顶点，&lt;code&gt;name&lt;/code&gt; 属性为 &lt;code&gt;United States&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;States&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;person&lt;/code&gt; 顶点也有一个出边 &lt;code&gt;LIVES_IN&lt;/code&gt;。沿着这条边，然后是一系列出边 &lt;code&gt;WITHIN&lt;/code&gt;，最终到达类型为 &lt;code&gt;Location&lt;/code&gt; 的顶点， &lt;code&gt;name&lt;/code&gt; 属性为 &lt;code&gt;Europe&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们不需要关注它底层是如何进行查询的，对于声明式查询语言，通常在编写查询语句时，不需要指定执行细节,查询优化器会自动选择效率最高的执行策略，因此开发者可以专注于应用的其他部分。&lt;/p&gt;
&lt;h3 id=&#34;sql中的图查询&#34;&gt;SQL中的图查询&lt;/h3&gt;
&lt;p&gt;既然可以使用关系数据库来表示图数据，那如果把图数据放在关系结构中，是否意味着也可以支持 SQL 查询呢？&lt;/p&gt;
&lt;p&gt;在关系数据库中，通常会预先知道查询中需要哪些 join 操作。而对于图查询，在找到要查询的顶点之前，可能需要遍历数量未知的边。也就是说，&lt;strong&gt;join 操作数量并不是预先确定的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在 SQL 查询过程中，这种可变的遍历路径可以使用&lt;strong&gt;递归公用表表达式&lt;/strong&gt;（&lt;code&gt;WITH RECURSIVE&lt;/code&gt; 语法）来表示。&lt;/p&gt;
&lt;p&gt;例如在上面 Cypher 中提到的用例，用 SQL 表示如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;WITH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RECURSIVE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- in_usa 包含所有的美国境内的位置ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;United States&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;UNION&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;within&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- in_europe 包含所有的欧洲境内的位置ID
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_europe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Europe&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;UNION&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_europe&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_europe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;within&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- born_in_usa 包含了所有类型为Person，且出生在美国的顶点
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;born_in_usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;born_in&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;-- lives_in_europe 包含了所有类型为Person，且居住在欧洲的顶点。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lives_in_europe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tail_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_europe&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head_vertex&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in_europe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edges&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;label&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lives_in&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;properties&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;born_in_usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;born_in_usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;JOIN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lives_in_europe&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ON&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lives_in_europe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vertex_id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;下面来看看上述代码的逻辑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;首先，查找 &lt;code&gt;name&lt;/code&gt; 属性为 &lt;code&gt;United States&lt;/code&gt; 的顶点，将其作为 &lt;code&gt;in_usa&lt;/code&gt; 顶点的集合的第一个元素。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从 &lt;code&gt;in_usa&lt;/code&gt; 集合的顶点出发，沿着所有的 &lt;code&gt;with_in&lt;/code&gt; 入边，将其尾顶点加入同一集合，不断递归直到所有 &lt;code&gt;with_in &lt;/code&gt;入边都被访问完毕。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同理，从 &lt;code&gt;name&lt;/code&gt; 属性为 &lt;code&gt;Europe&lt;/code&gt; 的顶点出发，建立 &lt;code&gt;in_europe&lt;/code&gt; 顶点的集合。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于 &lt;code&gt;in_usa&lt;/code&gt; 集合中的每个顶点，根据 &lt;code&gt;born_in&lt;/code&gt; 入边来查找出生在美国某个地方的人。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同样，对于 &lt;code&gt;in_europe&lt;/code&gt; 集合中的每个顶点，根据 &lt;code&gt;lives_in&lt;/code&gt; 入边来查找居住在欧洲的人。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最后，把在美国出生的人的集合与在欧洲居住的人的集合相交。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过对比，如果相同的查询可以用 Cypher 查询语言写 4 行代码就可以完成，而使用 SQL 需要 29 行代码，这足以说明不同的数据模型适用于不同的场景。&lt;/p&gt;
&lt;h3 id=&#34;三元存储与sparql&#34;&gt;三元存储与SPARQL&lt;/h3&gt;
&lt;p&gt;三元存储模式几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。在三元存储中，所有信息都以非常简单的三部分形式存储**（主体，谓语，客体）** 。&lt;/p&gt;
&lt;p&gt;三元组的主体相当于图中的顶点。而客体是以下两种之一：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;原始数据类型中的值，如字符串或数字。&lt;/strong&gt; 在这种情况下，三元组的谓语和客体分别相当于主体（顶点）属性中的键和值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;图中的另一个顶点。&lt;/strong&gt; 此时，谓语是图中的边，主体是尾部顶点，而客体是头部顶点。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们再次拿出 Cypher 中提到的例子，以 Turtle 三元组方式来表示这些数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-turtle&#34; data-lang=&#34;turtle&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;@prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;&amp;lt;urn:example:&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lucy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lucy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Lucy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lucy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bornIn&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Location&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Idaho&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;state&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Location&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;United States&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;country&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Location&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;North America&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;continent&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;顶点的名字在定义文件以外没有任何意义，只是为了区分三元组的不同顶点。&lt;/p&gt;
&lt;p&gt;如果要定义相同主体的多个三元组，反复输入相同的单词就略显枯燥。可以使用分号来说明同一主体的多个对象信息。下面即用更简洁的语法来重写上面的逻辑：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-turtle&#34; data-lang=&#34;turtle&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;@prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;&amp;lt;urn:example:&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lucy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Person&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Lucy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bornIn&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;idaho&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;     &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Location&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Idaho&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;state&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;usa&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Loaction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;United States&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;country&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namerica&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;Location&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;North America&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;continent&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;rdf数据模型&#34;&gt;RDF数据模型&lt;/h4&gt;
&lt;p&gt;语义网从本质上讲源于一个简单而合理的想法：&lt;strong&gt;网站通常将信息以文字和图片的方式发布给人类阅读，那为什么不把信息发布为机器可读的格式给计算机阅读呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;资源描述框架（Resource Description Framework, RDF）&lt;/strong&gt; 就是这样一种机制，&lt;strong&gt;它让不同网站以一致的格式发布数据，这样来自不同网站的数据自动合并成一个数据网络，一种互联网级别包含所有数据的数据库。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Turtle 语言代表了 RDF 数据的人类可读格式。有时候 RDF 也用 XML 格式编写，不过更冗长一些，人眼容易阅读 Turtle 这种格式，因此通常会借助一些自动化工具（如 Apache Jena）来快速转换各种 RDF 格式。&lt;/p&gt;
&lt;p&gt;下面即用 RDF/XML 语法重写上面的示例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;rdf:RDF&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;xmlns=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;urn:example:&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xmlns:rdf=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://www.w3.org/1999/02/22-rdf-syntax-ns#&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;Location&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;rdf:nodeID=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;idaho&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Idaho&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;state&lt;span class=&#34;nt&#34;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;within&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;Location&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;rdf:nodeID=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;usa&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;United States&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;country&lt;span class=&#34;nt&#34;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;within&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;Location&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;rdf:nodeID=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;namerica&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;North America&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nt&#34;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;continent&lt;span class=&#34;nt&#34;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/Location&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;/within&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;/Location&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/within&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/Location&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;Person&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;rdf:nodeID=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;lucy&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;Lucy&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;bornIn&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;rdf:nodeID=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;idaho&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/Person&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/rdf:RDF&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因为旨在为全网数据交换而设计，RDF 存在一些特殊的约定：&lt;strong&gt;三元组的主体、谓语和客体通常是 URI&lt;/strong&gt;。这种设计背后的原因是其假设你的数据需要和其他人的数据相结合，万一不同的人给同一个单词附加了不同的含义，采用 URI 则可以避免冲突。&lt;/p&gt;
&lt;h4 id=&#34;sparql查询语言&#34;&gt;SPARQL查询语言&lt;/h4&gt;
&lt;p&gt;SPARQL 是一种采用 RDF 数据模型的三元存储查询语言，它比 Cypher 更早，并且由于 Cypher 的模式匹配是借用 SPARQL 的，所以二者看起来非常相似。&lt;/p&gt;
&lt;p&gt;让我们再次使用 Cypher 中的那个示例，如果用 SPARQL 执行相同的查询，其会比 Cypher 要简洁的多，代码如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-SPARQL&#34; data-lang=&#34;SPARQL&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;PREFIX&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;&amp;lt;urn:example:&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;?personName&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nv&#34;&gt;?person&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;?personName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nv&#34;&gt;?person&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;bornIn&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;United States&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nv&#34;&gt;?person&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;livesIn&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;within&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Europe&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;SPARQL 是一种非常优秀的查询语言， 即使语义网从未实际出现，它也可以成为应用程序内部使用的强大查询工具。&lt;/p&gt;
&lt;h3 id=&#34;datalog&#34;&gt;Datalog&lt;/h3&gt;
&lt;p&gt;Datalog 是比 SPARQL 和 Cypher 更为古老的语言，在 20 世纪 80 年代被学者广泛研究。其数据模型类似于三元组模式，但进行了一点泛化。把三元组写成&lt;strong&gt;谓语（主语，客体）&lt;/strong&gt;，而不是**（主语，谓语，客体）**。&lt;/p&gt;
&lt;p&gt;我们尝试用 Datalog 来表示之前的查询，代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;within_recursive(Location, Name) :- name(Location, Name). /* Rule 1 */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;within_recursive(Location, Name) :- within(Location, Via), /* Rule 2 */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  within_recursive(Via, Name).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;migrated(Name, BornIn, LivingIn) :- name(Person, Name), /* Rule 3 */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                    born_in(Person, BornLoc),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                    within_recursive(BornLoc, BornIn),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                    lives_in(Person, LivingLoc),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                    within_recursive(LivingLoc, LivingIn).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;?- migrated(Who, &amp;#39;United States&amp;#39;, &amp;#39;Europe&amp;#39;). /* Who = &amp;#39;Lucy&amp;#39;. */
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;从上面的代码可以看出，&lt;strong&gt;Cypher 和 SPARQL 使用 SELECT 一次完成查询，而 Datalog 则每次查询一部分&lt;/strong&gt;。我们定义了告诉数据库关于新谓语的规则。例如两个新的谓语，&lt;code&gt;within_recursive&lt;/code&gt; 和 &lt;code&gt;migrated&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这些谓语并不是存储在数据库中的三元组，而是从数据或其他规则派生而来。规则可以引用其他规则，就像函数可以调用其他函数或者递归调用自己一样。像这样，&lt;strong&gt;复杂的查询可以通过每次完成一小块而逐步构建&lt;/strong&gt;。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数据密集型应用系统设计 学习笔记（一）：可靠性、可拓展性与可维护性</title>
        <link>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%8F%AF%E6%8B%93%E5%B1%95%E6%80%A7%E4%B8%8E%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7/</link>
        <pubDate>Sun, 10 Jul 2022 00:11:13 +0800</pubDate>
        
        <guid>https://blog.orekilee.top/p/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%8F%AF%E6%8B%93%E5%B1%95%E6%80%A7%E4%B8%8E%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7/</guid>
        <description>&lt;h1 id=&#34;可靠性可拓展性与可维护性&#34;&gt;可靠性、可拓展性与可维护性&lt;/h1&gt;
&lt;p&gt;现如今大多应用程序都是 &lt;strong&gt;数据密集型（data-intensive）&lt;/strong&gt; 的，而非 &lt;strong&gt;计算密集型（compute-intensive）&lt;/strong&gt; 的。因此CPU很少成为这类应用的瓶颈，更大的问题通常来自数据量、数据复杂性、以及数据的变更速度。&lt;/p&gt;
&lt;p&gt;数据密集型应用通常也是基于标准模块构建而成，每个模块负责单一的常用功能。例如，许多应用系统都包含以下模块：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据库（DataBase）&lt;/strong&gt;：用以存储数据，这样之后应用可以再次访问。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缓存（Cache）&lt;/strong&gt;：缓存那些复杂或操作代价昂贵的结果，加快读取速度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;索引（Search Indexe）&lt;/strong&gt;：用户可以按关键字搜索数据井支持以各种方式对数据进行过滤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;流处理（Stream Processing）&lt;/strong&gt;：持续发送消息至另一个进程，处理采用异步方式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;批处理（Batch Processing）&lt;/strong&gt;：定期处理大量的累积数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;认识数据系统&#34;&gt;认识数据系统&lt;/h2&gt;
&lt;p&gt;影响数据系统设计的因素有很多，其中包括相关人员技能和经验水平、历史遗留问题、交付周期、对不同风险因素的容忍度、监管合规等。这些因素往往因时因地而异。本书将专注于对大多数软件系统都极为重要的三个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;可靠性（Reliability）&lt;/strong&gt;：系统在困境（adversity，如硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可伸缩性（Scalability）&lt;/strong&gt;：系统有合理的办法应对规模的增长（如数据量、流量、复杂性等）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可维护性（Maintainability）&lt;/strong&gt;：许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;可靠性&#34;&gt;可靠性&lt;/h2&gt;
&lt;p&gt;人们对于一个东西是否可靠，都有一个直观的想法。人们对可靠软件的典型期望包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序表现出用户所期望的功能。&lt;/li&gt;
&lt;li&gt;允许用户犯错，允许用户以出乎意料的方式使用软件。&lt;/li&gt;
&lt;li&gt;在预期的负载和数据量下，性能满足要求。&lt;/li&gt;
&lt;li&gt;系统能防止未经授权的访问和滥用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果所有这些在一起意味着“正确工作”，那么可以把可靠性粗略理解为&lt;strong&gt;即使出现问题，也能继续正确工作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;尽管比起&lt;strong&gt;阻止错误&lt;/strong&gt;，我们通常更倾向于&lt;strong&gt;容忍错误&lt;/strong&gt;。可以恢复的故障种类有硬件故障、软件错误，人为失误三种。&lt;/p&gt;
&lt;h3 id=&#34;硬件故障&#34;&gt;硬件故障&lt;/h3&gt;
&lt;p&gt;当考虑系统故障时，对于硬件故障总是很容易想到硬盘崩溃，内存故障，电网停电，甚至有人误拔掉了网线。&lt;/p&gt;
&lt;p&gt;那我们如何应对这些问题呢？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;硬件冗余&lt;/strong&gt;：例如对磁盘配置 RAID ，服务器配备双电源，甚至热插拔 CPU，数据中心添加备用电源、发电机等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;软件容错&lt;/strong&gt;：例如当需要重启计算机时为操作系统打安全补丁，可以每次给一个节点打补丁然后重启，而不需要同时下线整个系统。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;软件错误&#34;&gt;软件错误&lt;/h3&gt;
&lt;p&gt;这类错误难以预料，而且因为是跨节点相关的，所以比起不相关的硬件故障往往可能造成更多的系统失效。例子包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于软件错误，导致当输入特定值时应用服务器总是崩溃。例如2012年6月30日的闰秒，由于Linux内核中的一个错误，许多应用同时挂掉。&lt;/li&gt;
&lt;li&gt;失控进程会用尽一些共享资源，包括 CPU、内存、磁盘空间或网络带宽。&lt;/li&gt;
&lt;li&gt;系统依赖的服务变慢，没有响应，或者开始返回错误的响应。&lt;/li&gt;
&lt;li&gt;级联故障，一个组件中的小故障触发另一个组件中的故障，进而触发更多的故障。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然软件中的系统性故障没有速效药，但我们还是有很多小办法，如：包括认真检查依赖的假设条件与系统之间交互 、进行全面的测试、进程隔离，允许进程崩溃并自动重启、反复评估，监控井分析生产环节的行为表现等。&lt;/p&gt;
&lt;h3 id=&#34;人为失误&#34;&gt;人为失误&lt;/h3&gt;
&lt;p&gt;设计和构建软件系统总是由人类完成，也是由人来运维这些系统。即使有时意图是好的，但人却无发做到万无一失。经过统计，运维人员的配置错误是系统下线的首要原因。&lt;/p&gt;
&lt;p&gt;如果我们假定人是不可靠的，那么该如何保证系统的可靠性呢？我们可以尝试以下方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以最小出错的方式来设计系统。&lt;/li&gt;
&lt;li&gt;想办法分离最容易出错的地方、容易引发故障的接口。&lt;/li&gt;
&lt;li&gt;采用充分的测试，如从各单元测试到全系统集成测试以及手动测试。&lt;/li&gt;
&lt;li&gt;当出现人为失失误时，提供快速的恢复机制以尽量减少故障影响。&lt;/li&gt;
&lt;li&gt;设置详细而清晰的监控子系统，包括性能指标和错误率。&lt;/li&gt;
&lt;li&gt;推行管理流程井加以培训 。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;可拓展性&#34;&gt;可拓展性&lt;/h2&gt;
&lt;p&gt;系统今天能可靠运行，并不意味未来也能可靠运行。**降级（degradation）**的一个常见原因是负载增加，例如：系统负载已经从一万个并发用户增长到十万个并发用户，或者从一百万增长到一千万。也许现在处理的数据量级要比过去大得多。&lt;/p&gt;
&lt;h3 id=&#34;负载&#34;&gt;负载&lt;/h3&gt;
&lt;p&gt;负载可以用一些称为**负载参数（load parameters）**的数字来描述。参数的最佳选择取决于系统架构，它可能是每秒向Web服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西。&lt;/p&gt;
&lt;h3 id=&#34;性能&#34;&gt;性能&lt;/h3&gt;
&lt;p&gt;常见的用于描述系统性能的指标如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;吞吐量（throughput）&lt;/strong&gt;：每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间。通常用于评估批处理系统。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;响应时间（response time）&lt;/strong&gt;：即客户端发送请求到接收响应之间的时间。通常用于评估在线系统。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;延迟（latency）&lt;/strong&gt; 和 &lt;strong&gt;响应时间（response time）&lt;/strong&gt; 经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（ &lt;strong&gt;服务时间（service time）&lt;/strong&gt; ）之外，还包括网络延迟和排队延迟。延迟是某个请求等待处理的&lt;strong&gt;持续时长&lt;/strong&gt;，在此期间它处于 &lt;strong&gt;休眠（latent）&lt;/strong&gt; 状态，并等待服务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;应对方法&#34;&gt;应对方法&lt;/h3&gt;
&lt;p&gt;拓展方式分为两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;水平拓展&lt;/strong&gt;：即将负载分布到多个更小的机器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;垂直拓展&lt;/strong&gt;：即升级到更强大的机器。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;跨多台机器分配负载也称为&lt;strong&gt;无共享（shared-nothing）架构&lt;/strong&gt;。可以在单台机器上运行的系统通常更简单，但高端机器可能非常贵，所以非常密集的负载通常无法避免地需要水平伸缩。&lt;/p&gt;
&lt;p&gt;有些系统是&lt;strong&gt;弹性（elastic）&lt;strong&gt;的，这意味着可以在检测到负载增加时自动增加计算资源，而其他系统则是手动伸缩（人工分析容量并决定向系统添加更多的机器）。如果负载&lt;/strong&gt;极难预测（highly unpredictable）&lt;/strong&gt;，则弹性系统可能很有用，但手动伸缩系统更简单，并且意外操作可能会更少。&lt;/p&gt;
&lt;p&gt;跨多台机器部署**无状态服务（stateless services）**非常简单，但将有状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（纵向伸缩），直到伸缩成本或可用性需求迫使其改为分布式。&lt;/p&gt;
&lt;p&gt;扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计。&lt;/p&gt;
&lt;h2 id=&#34;可维护性&#34;&gt;可维护性&lt;/h2&gt;
&lt;p&gt;软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此在设计之初就尽量考虑尽可能减少维护期间的痛苦，从而避免自己的软件系统变成遗留系统。&lt;/strong&gt; 为此，我们将特别关注软件系统的三个设计原则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可运维性（Operability）&lt;/strong&gt;：便于运维团队保持系统平稳运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;简单性（Simplicity）&lt;/strong&gt;：简化系统复杂性，使新工程师能够轻松理解系统。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可演化性（evolvability）&lt;/strong&gt;：后续工程师能够轻松地对系统进行改进，井根据需求变化将其适配到非典型场&lt;/p&gt;
&lt;p&gt;景。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
